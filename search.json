[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Social Statistics II (Exercises)",
    "section": "",
    "text": "Preface\nSyllabus\nHi everyone, I will be uploading the homework questions to this website.\nFeel free to reach out to me with any questions.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Social Statistics II (Exercises)",
    "section": "Resources",
    "text": "Resources\nThese are my personal recommendations for resources to start getting interested with causal inference.\nClass Resources:\n\nThe Effect by NHK (Huntington-Klein 2021)\n\nShort:\n\nResearch questions and estimands (Lundberg et al. 2021)\nIntroduction to DAGs (Rohrer 2018; Cinelli et al. 2022)\nThe Causal Diagrams edX course by Miguel Hernán is pretty good too.\nDon’t interpret “control” or “adjustment” variables (Westreich and Greenland 2013; Keele et al. 2020; Hünermund and Louw 2023).\nThe effects of seemingly immutable characteristics (Sen and Wasow 2016; cf. Holland 1986).\n\nGood to play around with:\n\nCounterfactuals and Causal Inference (Morgan and Winship 2014)\nI’ve been told many times that the first edition is better, so maybe try that one instead.\nCausal Inference: The Mixtape (Cunningham 2021)\nCovers a lot of the same ground as NHK, but has more math. It is also written by an economist.\nRegression and Other Stories (Gelman et al. 2020)\nChapters 18-21\nTheory & Credibility (Ashworth et al. 2021)\n\nLongitudinal Data Analysis\n\nRohrer and Murayama (2023)\n\n\n\nDifference-in-differences: Callaway and Sant’Anna (2021), Goodman-Bacon (2021)\n\nAdvanced Resources:\n\nMostly Harmless Econometrics (Angrist and Pischke 2009)\nCausality: Models, Reasoning and Inference (Pearl 2009)\nCausal Inference: What If (Hernan and Robins 2023)\nThis book gets used a lot in epidemiology.\n\n\n\n\n\n\n\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2009. Mostly Harmless Econometrics. Princeton university press.\n\n\nAshworth, Scott, Christopher R. Berry, and Ethan Bueno de Mesquita. 2021. Theory and Credibility: Integrating Theoretical and Empirical Social Science. Princeton University Press.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021. “Difference-in-Differences with Multiple Time Periods.” Journal of Econometrics 225(2): 200–230.\n\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. 2022. “A Crash Course in Good and Bad Controls.” Sociological Methods & Research 00491241221099552.\n\n\nCunningham, Scott. 2021. Causal Inference. Yale University Press.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with Variation in Treatment Timing.” Journal of Econometrics 225(2): 254277.\n\n\nHernan, Miquel A., and James M. Robins. 2023. Causal Inference: What If. CRC Press.\n\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81(396): 945–60.\n\n\nHünermund, Paul, and Beyers Louw. 2023. “On the Nuisance of Control Variables in Causal Regression Analysis.” Organizational Research Methods 10944281231219274.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to Research Design and Causality. New York: Chapman; Hall/CRC.\n\n\nKeele, Luke, Randolph T. Stevenson, and Felix Elwert. 2020. “The Causal Interpretation of Estimated Associations in Regression Models.” Political Science Research and Methods 8(1): 113.\n\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review 00031224211004187.\n\n\nMorgan, Stephen L., and Christopher Winship. 2014. Counterfactuals and Causal Inference: Methods and Principles for Social Research. 2nd edition. 2nd edition. New York, NY: Cambridge University Press.\n\n\nPearl, Judea. 2009. Causality: Models, Reasoning and Inference. 2nd edition. 2nd edition. Cambridge, U.K. ; New York: Cambridge University Press.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1(1): 2742.\n\n\nRohrer, Julia M., and Kou Murayama. 2023. “These Are Not the Effects You Are Looking for: Causality and the Within-/Between-Persons Distinction in Longitudinal Data Analysis.” Advances in Methods and Practices in Psychological Science 6(1): 25152459221140842.\n\n\nSen, Maya, and Omar Wasow. 2016. “Race as a Bundle of Sticks: Designs That Estimate Effects of Seemingly Immutable Characteristics.” Annual Review of Political Science 19(1): 499–522.\n\n\nWestreich, Daniel, and Sander Greenland. 2013. “The Table 2 Fallacy: Presenting and Interpreting Confounder and Modifier Coefficients.” American Journal of Epidemiology 177(4): 292–98.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "sec01.html",
    "href": "sec01.html",
    "title": "Part 1",
    "section": "",
    "text": "…",
    "crumbs": [
      "Part 1"
    ]
  },
  {
    "objectID": "week01.html",
    "href": "week01.html",
    "title": "1  Week 1",
    "section": "",
    "text": "1.1 Exercise\nWe will be digesting this article more fully in the coming weeks, so don’t worry if you don’t understand everything yet.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week01.html#sec-glossary",
    "href": "week01.html#sec-glossary",
    "title": "1  Week 1",
    "section": "",
    "text": "Start reading What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.\nKeep track of at least 5 terms that are new to you or that perhaps you don’t fully understand yet (e.g., estimand, DAG, potential outcome).\nI will be asking you to build a glossary of terms related to causal inference. I will not grade this yet, but still do your best attempt at defining each of these terms.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week01.html#exercise",
    "href": "week01.html#exercise",
    "title": "1  Week 1",
    "section": "1.2 Exercise",
    "text": "1.2 Exercise\n\n\nPackages\nlibrary(tidyverse)\nlibrary(gt)\n\n\nThe following data frame contains the potential outcomes for 8 individuals.\n\n\nCode\nd &lt;- data.frame(\n  T = c(0, 0, 1, 0, 0, 1, 1, 1),\n  Y0 = c(5, 8, 5, 12, 4, 8, 4, 9),\n  Y1 = c(5, 10, 3, 13, 2, 9, 1, 13), \n  id = LETTERS[1:8]\n)\n\ngt(d, rowname_col = \"id\") # gt is used for fancy printing of tables\n\n\n\n\n\n\n\n\n\n\nT\nY0\nY1\n\n\n\n\nA\n0\n5\n5\n\n\nB\n0\n8\n10\n\n\nC\n1\n5\n3\n\n\nD\n0\n12\n13\n\n\nE\n0\n4\n2\n\n\nF\n1\n8\n9\n\n\nG\n1\n4\n1\n\n\nH\n1\n9\n13\n\n\n\n\n\n\n\n\nThe variable T depicts whether someone got the “treatment” or not.\n\n\n\n\n\n\n\nCreate a new variable called Y that contains the observed outcomes.\nWhat is the Average Treatment Effect (ATE) for this 8 person experiment?\n\n\n\n\nNote. I’m only asking for a simple difference in means; this is also sometimes called the “naive estimator” (or “naive comparison”), which works just fine in simple experimental settings.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week01.html#exercise-1",
    "href": "week01.html#exercise-1",
    "title": "1  Week 1",
    "section": "1.3 Exercise",
    "text": "1.3 Exercise\n\n\n\n\n\n\n\nSimulate a new completely randomized experiment on these 8 people; that is, re sample \\(T\\) at random so that equal numbers get the treatment and the control.\nCreate a new variable called Y that contains the observed outcomes.\nWhat is the Average Treatment Effect (ATE) for this 8 person experiment?\nDo this a couple of times (at least 3) and note the differences.\n\n\n\n\n\n\n\n\n\n\nHint: You can re-sample \\(T\\) very easily using the sample() function.\nFor example:\n\n\nCode\nsample(d$T)\n\n\n[1] 1 0 1 0 0 1 0 1\n\n\n\n\n\n\n\n\n\n\n\nHow do these estimates compare to the “real” ATE?\nWhen I say “the real ATE” I basically mean this:\n\n\nCode\nmean(d$Y1 - d$Y0)\n\n\n[1] 0.125",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week01.html#exercise-2",
    "href": "week01.html#exercise-2",
    "title": "1  Week 1",
    "section": "1.4 Exercise",
    "text": "1.4 Exercise\n\n\n\n\n\n\nObviously, an experiment of 8 people will not give you enough “statistical power.”\n\nAssuming the ATE is \\(0.125\\), how many people would you need to enroll in this experiment to have enough statistical power?\n\n\n\n\n\n\n\n\n\n\nHint: There are a few different ways of giving a reasonable answer to this question. The wording of this problem is ambiguous.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1</span>"
    ]
  },
  {
    "objectID": "week02.html",
    "href": "week02.html",
    "title": "2  Week 2",
    "section": "",
    "text": "2.1 Exercise",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week02.html#exercise",
    "href": "week02.html#exercise",
    "title": "2  Week 2",
    "section": "",
    "text": "Which of the following is the best definition of the term identified as in “this variation has identified the effect we’re interested in”?\n\nWe’ve generated the data by conducting a controlled experiment in which treatment is randomly assigned.\nIn the data generating process, the only reason why we see variation in the outcome variable is because of the treatment variable.\nThe relationship we are looking at in the data actually tests a hypothesis.\nIn the variation we use, there’s no reason we’d see any relationship at all except for the effect we’re interested in.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week02.html#exercise-1",
    "href": "week02.html#exercise-1",
    "title": "2  Week 2",
    "section": "2.2 Exercise",
    "text": "2.2 Exercise\n\n\n\n\n\n\nYou read about a new study with the headline “eating caviar linked to longer lifespan.” The study’s research question is “does eating caviar make you live longer?” In the study’s data, they find that people who eat caviar have, on average, longer lifespans than people who don’t.\n\nWhat are some alternate explanations for this relationship?\nWhat sort of variation would identify the answer to the research question?\nGive one suggestion for how the study authors might isolate variation that would identify the answer to the research question",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week02.html#exercise-2",
    "href": "week02.html#exercise-2",
    "title": "2  Week 2",
    "section": "2.3 Exercise",
    "text": "2.3 Exercise\n\n\n\n\n\n\nFor each of the following news headlines, assume that the underlying data actually only shows a correlation between the two variables mentioned. Give an alternate explanation for the correlation other than the causal relationship implied by the headline.\n\n“As stock market drops, presidential approval ratings decline.”\n“Dates are announced for the downtown summer concert series, driving up sales at downtown restaurants.”\n“Unsanitary? Hospital visits linked to 20% increased risk of disease.”\n“Dress for success! Every CEO follows this office-wear rule.”",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week02.html#exercise-3",
    "href": "week02.html#exercise-3",
    "title": "2  Week 2",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\n\n\n\n\n\n\nWhy is a variable that causes both the “treatment” and “outcome” variables especially concerning for identification? You may want to use the phrase “alternate explanation” in your answer.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week02.html#exercise-4",
    "href": "week02.html#exercise-4",
    "title": "2  Week 2",
    "section": "2.5 Exercise",
    "text": "2.5 Exercise\n\n\n\n\n\n\nShoe company Crikey claims that people who wear their fancy and expensive professional running-shoe Cool Mistrunner brand run 4 to 5% faster than if they wore an average shoe.\n\nIn a few sentences, describe the data-generating process (you will probably leave some things out, that’s okay).\nWhat are possible alternative explanations for this claim, aside from the shoe making the person run faster?\nIn running their study, the researchers accounted for some alternative explanations, including: gender, enthusiasm for running, and whether runners have participated in marathons and/or half marathons. Think of an alternative explanation not on this list. What is the implication of not accounting for this alternative explanation?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2</span>"
    ]
  },
  {
    "objectID": "week03.html",
    "href": "week03.html",
    "title": "3  Week 3",
    "section": "",
    "text": "3.1 Exercise\nIgnorability\nExperiments work because they make the distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator are independent.\nThis is how this idea was introduced in class:\n\\[\n\\begin{align}\nY^0 \\perp T, && Y^1 \\perp T\n\\end{align}\n\\]\nAssume the following table comes from perfectly executed experiment.\n*30% of the population is in group T = 1",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise",
    "href": "week03.html#exercise",
    "title": "3  Week 3",
    "section": "",
    "text": "Table 3.1: Perfect Experiment Example*\n\n\n\n\n\nGroup (\\(T\\))\n\\(E[Y^1]\\)\n\\(E[Y^0]\\)\n\n\n\n\n\\(T = 1\\)\n10,000\n?\n\n\n\\(T = 0\\)\n?\n5,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFill in the missing cells.\nWhat is the ATE?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-1",
    "href": "week03.html#exercise-1",
    "title": "3  Week 3",
    "section": "3.2 Exercise",
    "text": "3.2 Exercise\nGo back to the glossary I asked you to start creating during Week 1.\nMake sure to add the following terms:\n\n\n\n\n\n\n\nDAG.\nPaths.\nDirect effects.\nIndirect effects.\nTotal effects.\nFront door paths.\nBack door paths.\nConfounding.\nCollider.\nOpen Path.\nClosed Path.\n\n\n\n\n\nSee: Section 1.1",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-2",
    "href": "week03.html#exercise-2",
    "title": "3  Week 3",
    "section": "3.3 Exercise",
    "text": "3.3 Exercise\nDrawing DAGs.\nThe following exercises are problems from NHK (Chapter 7).\n\n\n\n\n\n\nDraw a causal diagram for the research question “do long shift hours make doctors give lower-quality care?” that incorporates the following features (and only the following features):\n\nLong shift hours affect both how tired doctors are, and how much experience they have, both of which affect the quality of care\nHow long shifts are is often decided by the hospital the doctor works at. There are plenty of other things about a given hospital that also affect the quality of care, like its funding level, how crowded it is, and so on\nNew policies that reduce shift times may be implemented at the same time (with the timing determined by some unobservable change in policy preferences) as other policies that also attempt to improve the quality of care",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-3",
    "href": "week03.html#exercise-3",
    "title": "3  Week 3",
    "section": "3.4 Exercise",
    "text": "3.4 Exercise\n\n\n\n\n\n\nConsider this research question: Does the funding level of public schools affect student achievement for students in your country?\n\nWhat is the treatment and what is the outcome of interest?\nWrite down a list of relevant variables.\nWhich of the variables in your list in part b are causes of both treatment and outcome?\nWhy might we want to pay extra attention to the variables listed in part c?\nDraw a causal diagram of the variables listed in part b.\nSimplify the diagram from part e.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-4",
    "href": "week03.html#exercise-4",
    "title": "3  Week 3",
    "section": "3.5 Exercise",
    "text": "3.5 Exercise\n\n\n\n\n\n\nHow can a causal diagram be modified so as to avoid cyclic relationships?\nConsider the diagram below. It depicts a cyclical relationship between student achievement and motivation. If students achieve more (i.e., score well on exams), then their motivation goes up, and if their motivation goes up, they achieve more. Change the diagram so that the relationship is not cyclic anymore.\n\\[\n\\text{Student Achievement} \\longleftrightarrow \\text{Motivation}\n\\]\n\n\n\n\n\n\n\n\n\nHint: We didn’t see this in class, but you should be able to figure it out from the readings.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-5",
    "href": "week03.html#exercise-5",
    "title": "3  Week 3",
    "section": "3.6 Exercise",
    "text": "3.6 Exercise\nThe following exercises are problems from NHK (Chapter 8).\n\n\n\n\n\n\nAssuming that a path has no colliders on it, what is the difference between a path being Open and Closed?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-6",
    "href": "week03.html#exercise-6",
    "title": "3  Week 3",
    "section": "3.7 Exercise",
    "text": "3.7 Exercise\n\n\n\n\n\n\nConsider the below generic causal diagram.\n\n\n\n\n\n\nList every path from X to Y.\nWhich of the paths are front-door paths?\nWhich of the paths are open back-door paths?\nWhat variables must be controlled for in order to identify the effect of X on Y? (only list what must be controlled for, not anything that additionally could be controlled for).",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-7",
    "href": "week03.html#exercise-7",
    "title": "3  Week 3",
    "section": "3.8 Exercise",
    "text": "3.8 Exercise\n\n\n\n\n\n\nWhich of the following describes a causal path where all the arrows point away from the treatment?\n\nOpen Path\nClosed Path\nFront Door Path\nBack Door Path",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-8",
    "href": "week03.html#exercise-8",
    "title": "3  Week 3",
    "section": "3.9 Exercise",
    "text": "3.9 Exercise\n\n\n\n\n\n\nConsider the figure below, which depicts the relationship between teaching quality, number of publications (e.g., articles, books), and popularity among scholars and students in a population of professors.\n\n\n\n\n\n\nWhat type of variable is Popularity in one path on this diagram?\nDiscuss what would happen if you controlled for Popularity.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-9",
    "href": "week03.html#exercise-9",
    "title": "3  Week 3",
    "section": "3.10 Exercise",
    "text": "3.10 Exercise\n\n\n\n\n\n\nGo to the app Steve showed us in class.\nhttps://cbdrh.shinyapps.io/daggle/\nSpend some time noodling around with it and upload screenshots with the right answer for three DAGs with 4, 6, and 8 nodes each. Set the complexity to “difficult.”",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-10",
    "href": "week03.html#exercise-10",
    "title": "3  Week 3",
    "section": "3.11 Exercise",
    "text": "3.11 Exercise\nHouse of DAG Simulation.\nI’ve included a little script with a couple of functions meant to illustrate the connection between DAGs and the estimands we saw in class (ATE, ATT, ATC).\nSave it to your project and load it using the source() function.\nYou should see a function called hod_simulation() which creates a dataset that corresponds to the following DAG:\n\n\n\n\n\n\n\\(Y\\): outcome\n\\(T\\): treatment\n\\(U\\): unobserved confounder\n\\(S\\): affects selection into \\(T\\)\n\\(X\\): affects \\(Y\\) directly\n\n\n\nThe hod_simulation() function has the following arguments:\n\nN: Sample Size\nrho: The correlation between \\(S\\) and \\(X\\), it accepts values between -1 and 1.\nBt: this is the treatment effect.\nBx: this is the direct effect of \\(X\\) on \\(Y\\)\n\nNote. There’s bunch of stuff going on under the hood, but we won’t worry about that this week.\nThis is the dataset it creates:\n\n\nCode\nsource(\"hod_simulation_functions.R\")\n\n\nStandard Error ~  0.322 \nPower ~  0.873\n\n\nJoining with `by = join_by(variable)`\n\n\n# A tibble: 4 × 3\n  variable    sd  mean\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 y        5.09  1.50 \n2 t        0.500 0.512\n3 x        1.00  1.07 \n4 s        1.01  1.02 \n\n\nCode\nset.seed(12345) ## include this so that grading is easier for me.\nd &lt;- hod_simulation(N = 1e3, Bt = 2, Bx = 4, rho = 0.8)\n\n\nStandard Error ~  0.405 \nPower ~  0.999\n\n\nJoining with `by = join_by(variable)`\n\n\n# A tibble: 4 × 3\n  variable    sd  mean\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 y        6.75   4.98\n2 t        0.500  0.52\n3 x        1.02   1.00\n4 s        1.01   1.02\n\n\nNote. Ignore the “Standard Error” and “Power” messages.\n\n\nCode\nd\n\n\n# A tibble: 1,000 × 6\n       y0     y1     t      y       x      s\n *  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1  3.03   5.03      1  5.03   1.90   1.84  \n 2  5.20   7.20      1  7.20   0.545  0.699 \n 3 -0.351  1.65      1  1.65  -0.355  0.729 \n 4 -2.76  -0.764     1 -0.764  1.03   1.44  \n 5 -3.79  -1.79      0 -3.79   0.0507 0.335 \n 6 12.9   14.9       0 12.9    2.57   1.71  \n 7  6.70   8.70      0  6.70   1.63   1.56  \n 8  3.68   5.68      0  3.68   1.40   0.694 \n 9 -1.65   0.353     1  0.353  0.307  0.0589\n10 10.8   12.8       0 10.8    1.77   2.14  \n# ℹ 990 more rows\n\n\n\n\n\n\n\n\n\nWithout looking at the results just yet… do you think the naive estimate will be larger or smaller than the “real” estimate ( \\(ATE = 2\\) )?\nCheck your answer. What are the results given by the naive estimator?\nRe-do this but set rho to -0.8 (so that \\(S\\) and \\(X\\) are now negatively correlated).\n\n\n\n\n\n\n\n\n\n\nHint: You can use group_by() and then summarize() to create a table just like Table 3.1.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week03.html#exercise-11",
    "href": "week03.html#exercise-11",
    "title": "3  Week 3",
    "section": "3.12 Exercise",
    "text": "3.12 Exercise\n\n\n\n\n\n\nTake the dataset d created in the previous question and modify it so that the treatment is now randomized (this will destroy the path between \\(S\\) and \\(T\\)).\n\n\n\n\n\n\n\n\n\nHint: You can achieve this using the sample() function on d$t.\nYou will also want to create a new d$y using the ifelse() function (or something similar to that).\n\n\n\n\n\n\n\n\n\n\nWithout looking at the results just yet… do you think the naive estimate will be larger or smaller than the “real” estimate ( \\(ATE = 2\\) )?\nCheck your answer. What are the results given by the naive estimator?\nUse lm() to predict the newly created y from t. What are the coefficient values?\nUse lm() to predict the newly created y from t and x. What are the coefficient values?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3</span>"
    ]
  },
  {
    "objectID": "week04.html",
    "href": "week04.html",
    "title": "4  Week 4",
    "section": "",
    "text": "4.1 Exercise\nColliders\nFor this exercise I am going to ask you to create the following simulated dataset.\nCode\nN &lt;- 1e4\n\nd &lt;- tibble(\n  x = rnorm(N, 0, 1),\n  y = rnorm(N, 0, 1)\n)\nThe relationship between \\(x\\) and \\(y\\) should look something like this:",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise",
    "href": "week04.html#exercise",
    "title": "4  Week 4",
    "section": "",
    "text": "Now I am going to ask you to create an association between \\(x\\) and \\(y\\) via some form of collider bias.\n\\[\nx \\longrightarrow \\underbrace{\\text{z}}_{\\small {\\text{collider}}} \\longleftarrow y\n\\]\nYou are tasked to do this in four different ways, each of them corresponding to one of the plots in Figure 4.1.\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\nFigure 4.1: Conditioning on a Collider\n\n\n\n\n\n\n\n\n\nHint: The first three plots represent a process in which “conditioning on a collider” means that some observations are removed from the d dataset. You can then calculate the slopes simply by doing something like this:\nlm(y ~ x, data = d_filtered)\nThe last plot represents a process in which the association between \\(x\\) and \\(y\\) is created by literally “conditioning on a collider.” Something like this:\nlm(y ~ x + z, data = d)",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-1",
    "href": "week04.html#exercise-1",
    "title": "4  Week 4",
    "section": "4.2 Exercise",
    "text": "4.2 Exercise\nNote. The following exercises are problems from NHK (Chapter 10). If you have issues with some of the terminology used, you should be able to figure it out from reading the book.\nDefine in your own words (i.e., don’t just copy down what’s written in the glossary) each of the following terms:\n\nConditional average treatment effect\nAverage treatment on the treated\nAverage treatment on the untreated",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-2",
    "href": "week04.html#exercise-2",
    "title": "4  Week 4",
    "section": "4.3 Exercise",
    "text": "4.3 Exercise\nProvide an example of a treatment effect that you would expect to be highly heterogeneous, and explain why you think it is likely to be heterogeneous.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-3",
    "href": "week04.html#exercise-3",
    "title": "4  Week 4",
    "section": "4.4 Exercise",
    "text": "4.4 Exercise\nConsider the data in the table below that shows the hypothetical treatment effect of cognitive behavioral therapy on depression for six participants. For the sake of this example, the six participants represent the population of interest.\n\n\n\nCase\nAge\nGender\nEffect\n\n\n\n\nA\n15\nMan\n7\n\n\nB\n40\nWoman\n3\n\n\nC\n30\nWoman\n7\n\n\nD\n20\nNon-binary\n8\n\n\nE\n15\nMan\n7\n\n\nF\n25\nWoman\n4\n\n\n\n\nWhat is the overall average treatment effect for the population?\nWhat is the average treatment effect for Women?\nIf nearly all Non-binary people get treated, and about half of all Women get treated, and we control for the differences between Women and Non-binary people, what kind of treatment effect average will we get, and what can we say about the numerical estimate we’ll get?\nIf we assume that, in the absence of treatment, everyone would have had the same outcome, and also only teenagers (19 or younger) ever receive treatment, and we compare treated people to control people, what kind of treatment effect average will we get, and what can we say about the numerical estimate we’ll get?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-4",
    "href": "week04.html#exercise-4",
    "title": "4  Week 4",
    "section": "4.5 Exercise",
    "text": "4.5 Exercise\nGive an example where the average treatment effect on the treated would be more useful to consider than the overall average treatment effect, and explain why.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-5",
    "href": "week04.html#exercise-5",
    "title": "4  Week 4",
    "section": "4.6 Exercise",
    "text": "4.6 Exercise\nWhich of the following describes the average treatment effect of assigning treatment, whether or not treatment is actually received?\n\nLocal average treatment effect\nAverage treatment on the treated\nIntent-to-treat\nVariance-weighted average treatment effect",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-6",
    "href": "week04.html#exercise-6",
    "title": "4  Week 4",
    "section": "4.7 Exercise",
    "text": "4.7 Exercise\nSuppose you are conducting an experiment to see whether pricing cookies at $1.99 versus $2 affects the decision to purchase the cookies. The population of interest is all adults in the United States. You recruit people from your university to participate and randomize them to either see cookies priced as $1.99 or $2, then write down whether they purchased cookies. What kind of average treatment effect can you identify from this experiment?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week04.html#exercise-7",
    "href": "week04.html#exercise-7",
    "title": "4  Week 4",
    "section": "4.8 Exercise",
    "text": "4.8 Exercise\nFor each of the following identification strategies, what kind of treatment effect(s) is most likely to be identified?\n\nA randomized experiment using a representative sample\nTrue randomization within only a certain demographic group\nClosing back door paths connected to variation in treatment\nIsolating the part of the variation in treatment variable that is driven by an exogenous variable\nThe control group is comparable to the treatment group, but treatment effects may be different across these groups",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4</span>"
    ]
  },
  {
    "objectID": "week05.html",
    "href": "week05.html",
    "title": "5  Week 5",
    "section": "",
    "text": "5.1 Instructions\nBoth functions have an argument called newdata, which you can use doing something similar to this toy example:\nCode\nols &lt;- lm(mpg ~ disp + am, data = mtcars)\n\nnew_am0 &lt;- mtcars |&gt; \n  mutate(am = 0)\n\nnew_am1 &lt;- mtcars |&gt; \n  mutate(am = 1)\n\np0 &lt;- predict(ols, newdata = new_am0) ## predictions for am == 0\np1 &lt;- predict(ols, newdata = new_am1) ## predictions for am == 1",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week05.html#instructions",
    "href": "week05.html#instructions",
    "title": "5  Week 5",
    "section": "",
    "text": "This homework has three sections.\nEach exercise has two marginaleffects outputs: (1) the ATE estimate and (2) the ATT/ATU estimates.\nYou will have to reproduce these estimates without using marginaleffects. There are a couple of ways to do this, but you will probably end up using the predict() function (from base R), or the augment() function (from the broom package).\n\n\n\n\n\n\n\n\n\n\n\nBonus\nThe avg_slopes() function has an arguments called hypothesis which lets you estimate a standard error for the difference between the ATT and the ATU (among other things). This shows up in Steve’s code for this week.\nIf you are done early, I suggest you try and calculate one of these standard errors without avg_slopes (e.g., using a bootstrap).",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week05.html#linear-regression",
    "href": "week05.html#linear-regression",
    "title": "5  Week 5",
    "section": "5.2 Linear Regression",
    "text": "5.2 Linear Regression\nWe will use this data.\n\n\nCode\nd &lt;- gss2022 |&gt; \n  select(tvhours, degree, madeg, padeg) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L)) |&gt;\n  select(tvhours, college, parcol) |&gt; \n  drop_na()\n\n\n\n5.2.1 Exercise\nAdditive link function, no interactions\n\n\nCode\nmod1 &lt;- lm(tvhours ~ college + parcol, data = d)\n\n# ATE estimate\navg_slopes(mod1, variables = \"college\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0      -0.796     0.151     -5.27 1.35e-7    22.8    -1.09    -0.500\n\n\nANSWER GOES HERE\n\n\nCode\n# ATT/ATU estimate\navg_slopes(\n  model = mod1, \n  variables = \"college\",\n  by = \"college\" # separately by treatment group\n) |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   -0.796     0.151     -5.27 1.35e-7    22.8    -1.09\n2 college mean(1)…       1   -0.796     0.151     -5.27 1.35e-7    22.8    -1.09\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.2.2 Exercise\nAdditive link function, with interactions\n\n\nCode\nmod2 &lt;- lm(tvhours ~ college * parcol, data = d)\n\n# ATE estimate\navg_slopes(mod2, variables = \"college\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0      -0.803     0.152     -5.29 1.20e-7    23.0    -1.10    -0.506\n\n\nANSWER GOES HERE\n\n\nCode\n# ATT/ATU estimate\navg_slopes(\n  model = mod2, \n  variables = \"college\",\n  by = \"college\" # separately by treatment group\n) |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   -0.821     0.160     -5.14 2.70e-7    21.8    -1.13\n2 college mean(1)…       1   -0.772     0.159     -4.87 1.13e-6    19.8    -1.08\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week05.html#poisson-regression",
    "href": "week05.html#poisson-regression",
    "title": "5  Week 5",
    "section": "5.3 Poisson Regression",
    "text": "5.3 Poisson Regression\nWe will use this data.\n\n\nCode\nd &lt;- gss2022 |&gt;\n  filter(wrkstat == 1) |&gt; # full time workers\n  select(realrinc, degree, madeg, padeg, sex, age) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L),\n         female = if_else(sex == 2, 1L, 0L),\n         realrinc = floor(realrinc)) |&gt;             # integer\n  select(realrinc, college, parcol, female, age) |&gt; \n  drop_na()\n\n\n\n5.3.1 Exercise\nUsing the log-counts, no interactions\n\n\nCode\nqp1 &lt;- glm(realrinc ~ college + (parcol + female + age + I(age^2)), \n           data = d,\n           family = \"quasipoisson\")\n\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0       0.599    0.0510      11.7 7.45e-32    103.    0.499\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"link\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0    0.599    0.0510      11.7 7.45e-32    103.    0.499\n2 colle… mean(1)…       1    0.599    0.0510      11.7 7.45e-32    103.    0.499\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.3.2 Exercise\nNon-linear response, no interactions\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0      21237.     1831.      11.6 4.18e-31    101.   17649.\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"response\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0   20636.     1861.      11.1 1.41e-28    92.5   16988.\n2 colle… mean(1)…       1   21977.     1816.      12.1 1.05e-33   110.    18417.\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\n\n\n5.3.3 Exercise\nUsing the log-counts, with interactions\n\n\nCode\nqp2 &lt;- glm(realrinc ~ college * (parcol + female + age + I(age^2)), \n           data = d,\n           family = \"quasipoisson\")\n\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0       0.580    0.0543      10.7 1.20e-26    86.1    0.474\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"link\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0    0.567    0.0571      9.94 2.77e-23    74.9    0.455\n2 colle… mean(1)…       1    0.596    0.0600      9.94 2.87e-23    74.9    0.479\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.3.4 Exercise\nNon-linear response, with interactions\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0      21190.     1817.      11.7 1.99e-31    102.   17629.\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"response\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0   20196.     1937.      10.4 1.90e-25    82.1   16400.\n2 colle… mean(1)…       1   22411.     1963.      11.4 3.51e-30    97.8   18563.\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week05.html#logistic-regression",
    "href": "week05.html#logistic-regression",
    "title": "5  Week 5",
    "section": "5.4 Logistic Regression",
    "text": "5.4 Logistic Regression\nWe will use this data.\n\n\nCode\nd &lt;- gss2022 |&gt;\n  select(abany, degree, madeg, padeg, sex, age) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L),\n         female = if_else(sex == 2, 1L, 0L),\n         abany = if_else(abany == 1, 1L, 0L)) |&gt;\n  select(abany, college, parcol, female, age) |&gt; \n  drop_na()\n\n\n\n5.4.1 Exercise\nUsing log-odds, no interactions\n\n\nCode\nlr1 &lt;- glm(abany ~ college + (parcol + female + age + I(age^2)),\n          data = d,\n          family = binomial)\n\n# ATE estimate\navg_slopes(lr1,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.438     0.146      3.00 0.00273    8.52    0.151     0.724\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(lr1,\n           variables = \"college\",\n           by = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.438     0.146      3.00 0.00273    8.52    0.151\n2 college mean(1)…       1    0.438     0.146      3.00 0.00273    8.52    0.151\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.4.2 Exercise\nUsing non-linear response (aka probabilities), no interactions\n\n\nCode\n# ATE estimate\navg_slopes(lr1,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.102    0.0337      3.02 0.00249    8.65   0.0359     0.168\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(lr1,\n           variables = \"college\",\n           by = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   0.104     0.0341      3.04 0.00235    8.73   0.0369\n2 college mean(1)…       1   0.0989    0.0330      2.99 0.00275    8.51   0.0342\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.4.3 Exercise\nUsing log-odds, with interactions\n\n\nCode\nlr2 &lt;- glm(abany ~ college * (parcol + female + age + I(age^2)),\n          data = d,\n          family = binomial)\n\n# ATE estimate\navg_slopes(lr2,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.453     0.149      3.04 0.00239    8.71    0.161     0.745\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(lr2,\n           variables = \"college\",\n           by = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.450     0.159      2.83 0.00460    7.76    0.139\n2 college mean(1)…       1    0.458     0.161      2.85 0.00435    7.84    0.143\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE\n\n\n5.4.4 Exercise\nUsing non-linear response (aka probabilities), with interactions\n\n\nCode\n# ATE estimate\navg_slopes(lr2,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.103    0.0338      3.05 0.00228    8.78   0.0369     0.169\n\n\nANSWER GOES HERE\n\n\nCode\navg_slopes(lr2,\n           variables = \"college\",\n           by = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.104    0.0363      2.87 0.00407    7.94   0.0332\n2 college mean(1)…       1    0.101    0.0353      2.87 0.00415    7.91   0.0320\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nANSWER GOES HERE",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5</span>"
    ]
  },
  {
    "objectID": "week06.html",
    "href": "week06.html",
    "title": "6  Week 6",
    "section": "",
    "text": "6.1 Regression\nNote. There where two exercises here about simulation and omitted variable bias which you can now find in the solutions. It’s a story about how I used simulations to realize I was being misled by information contained in a famous textbook.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 6</span>"
    ]
  },
  {
    "objectID": "week06.html#balance-and-overlap",
    "href": "week06.html#balance-and-overlap",
    "title": "6  Week 6",
    "section": "6.2 Balance and Overlap",
    "text": "6.2 Balance and Overlap\nBalance\nThe sort of bias that we get from confounding can be interpreted more precisely as imbalance in the potential outcomes across treatment groups. This is the sort of imbalance is unlikely with randomization, but it’s almost guaranteed in observational studies.\nIn other words, imbalance occurs if the distributions of confounders differ for the treatment and control groups.\nOverlap\nFigure 6.1 shows what lack of complete overlap (with respect to \\(x\\)) might look like:\n\n\n\n\n\n\n\n\n\n\n\n(a) Two distributions with no overlap\n\n\n\n\n\n\n\n\n\n\n\n(b) Two distributions with partial overlap\n\n\n\n\n\n\n\n\n\n\n\n(c) The range of one distribution is a subset of the range of the other.\n\n\n\n\n\n\n\nFigure 6.1: Lack of complete overlap in distributions across treatment and control groups. Dashed lines indicate distributions for the control group; solid lines indicate distributions for the treatment group.\n\n\n\nLack of complete overlap or “common support” creates problems because in this setting we have treatment or control observations for which we have no empirical counterfactuals. Thus, knowledge about treatment effects is inherently limited in regions of non-overlap. Any causal inference in Figure 6.1 (a) would rely on modeling assumptions instead of having direct support from the data. In Figure 6.1 (c) causal inference is possible for the full treatment group but only for a subset of the control group.\nNote. This is the exact same thing we talked about when thinking about the potential outcomes for a cervical cancer vaccine in a population for men and women.\n\n6.2.1 Exercise\nLooking for imbalance.\nLoad the cattaneo2.dta data that Steve showed us in class.\n\n\nCode\nd &lt;- haven::read_dta(\"data/cattaneo2.dta\")\n\nd &lt;- d |&gt;  \n  haven::zap_labels() |&gt;             \n  select(bweight, lbweight, mbsmoke, mmarried, mage, medu, fbaby, alcohol, mrace, nprenatal)\n\nglimpse(d)\n\n\nRows: 4,642\nColumns: 10\n$ bweight   &lt;dbl&gt; 3459, 3260, 3572, 2948, 2410, 3147, 3799, 3629, 2835, 3880, …\n$ lbweight  &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ mbsmoke   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ mmarried  &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ mage      &lt;dbl&gt; 24, 20, 22, 26, 20, 27, 27, 24, 21, 30, 26, 20, 34, 21, 23, …\n$ medu      &lt;dbl&gt; 14, 10, 9, 12, 12, 12, 12, 12, 12, 15, 12, 12, 14, 8, 12, 12…\n$ fbaby     &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ alcohol   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ mrace     &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ nprenatal &lt;dbl&gt; 10, 6, 10, 10, 12, 9, 16, 11, 20, 9, 14, 5, 13, 8, 4, 10, 13…\n\n\nWe can start checking for imbalance for several covariates by examining their absolute standardized difference in means—i.e., a balance plot. I’ve included a graph that shows the absolute standardized difference in means values for a set of confounding covariates that might predict both mbsmoke and birth weight.\n\n\n\n\n\n\n\n\n\n\n\nYou’re job is to reproduce something close to this figure.\nWhat do you think are the most important covariates you need to adjust for in terms of the potential biases in the treatment effect?\n\n\n\n\n\n\n\n\n\nI used geom_segment(), but you can just use geom_point().\nAn open question is exactly which “standard deviation” to use. I used the standard deviations of the treated group, but you are not required to use that one. This means that your final plot doesn’t have to reproduce",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 6</span>"
    ]
  },
  {
    "objectID": "week06.html#matching",
    "href": "week06.html#matching",
    "title": "6  Week 6",
    "section": "6.3 Matching",
    "text": "6.3 Matching\nThis question is copied from NHK’s exercises. To answer this question you need to read sections 14.1 and 14.2 of The Effect.\n\n6.3.1 Exercise\n\nYou want to know whether practicing cursive improves your penmanship (on a 1-10 scale). You find that, among people who don’t practice cursive, average penmanship is 5, 10 people are left-handed, 2 are ambidextrous, and 88 are right-handed. Among people who do practice cursive, 6 are left-handed with average penmanship 7, 4 are ambidextrous with average penmanship 4, and 90 are right-handed with average penmanship 6.\n\nYou want to create a set of weights that will make the treated group match the control group on handedness. Follow the process in section 14.2, paying attention to why certain numbers are going in certain positions. What weights will be given to the left, ambidextrous, and right-handed people in the control group?\nWhat weights will be given to the left, ambidextrous, and right-handed people in the treated group?\nUse the weights from part b to calculate the proportion of left-handed people in the treated group, as well as the proportion of ambidextrous people and the proportion of right-handed people. If you don’t get 10%, 2%, and 88% (or very close with some rounding error), your weights are wrong, try again.\nWhat is the weighted average penmanship score in the treated group?\nWhat is the effect of practicing cursive that we would estimate using this data?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 6</span>"
    ]
  },
  {
    "objectID": "week07.html",
    "href": "week07.html",
    "title": "7  Week 7",
    "section": "",
    "text": "7.1 Matching and Weighting\nNote. The following exercises where adapted from last year’s class.\nFor these exercises, we are going to use one of the versions of the “Lalonde data,” which is used in almost every paper on matching.1 This is data on a job training program (the treatment) that was intended to raise future earnings (the outcome).\nYou can load the data by typing the following:\nCode\nload(\"data/exercise_data.Rdata\")\nThis will bring two objects into the global environment: d_exper, which is the experimental subset of the data and d, which comprises the treated cases and a sample of observational controls from the PSID. The treatment is treat and the outcome is re78, which is income in $1000s. We are going to use the experimental subset to set an experimental benchmark and then see how close we can get to this benchmark using various matching and weighting methods.\nThe rest of the variables are as follows:\nBefore starting the exercises, you may want to consider a few things that will make your life easier:\nYou can get by without doing these steps but they avoid extra typing down the road.\nYou will begin by looking at the experimental data (d_exper). After that, you will conduct various forms of matching and weighting on the observational data (d). For each exercise after the first four, your basic workflow will be:",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week07.html#matching-and-weighting",
    "href": "week07.html#matching-and-weighting",
    "title": "7  Week 7",
    "section": "",
    "text": "Variable\nDescription\n\n\n\n\nage\nAge in years\n\n\neduc\nYears of education\n\n\nblack\n1 = Black; 0 otherwise\n\n\nhisp\n1 = Hispanic; 0 otherwise\n\n\nmarried\n1 = married; 0 otherwise\n\n\nnodegr\n1 = no degree; 0 otherwise\n\n\nre74\n1974 income in $1000s\n\n\nre75\n1975 income in $1000s\n\n\nu74\n1 = no ’74 income; 0 otherwise\n\n\nu75\n1 = no ’75 income; 0 otherwise\n\n\n\n\n\nadd a factor version of the treatment to the data frame for easy plotting\ncreate formula objects that contain the propensity score (or matching) models with and without quadratic terms\n\n\n\n\nMatch or weight, as directed\nCheck balance (overall, if applicable and by covariate) using graphical and numeric means\nEstimate the ATT\n\n\n7.1.1 Exercise\nUse the experimental data to estimate the effect of the job training treatment. How much does it appear to affect 1978 income? Now look at the observational data (for all exercises from now on). How large is the raw difference in 1978 income between the treatment group and the PSID comparison group?\n\n\n7.1.2 Exercise\nTry to estimate the effect of the treatment using regression. What does regression say the effect of the program is?\n\n\n7.1.3 Exercise\nBegin by exact matching on all the dummy variables. How many treated cases cannot be matched? What is the (FS)ATT estimate?\n\n\n7.1.4 Exercise\nUse the observational data to estimate each case’s propensity to receive treatment using glm(). Use a logistic regression with quadratic terms for age, education, 1974 income, and 1975 income. Spend a few moments thinking about what this model says. Look at the density plots of the p-score for treated and untreated groups.\n\n\n7.1.5 Exercise\nEstimate propensity scores and ATT weights using weightit(). Ignore the warning you get. We’ll discuss that more in class. Estimate the ATT. Check for covariate balance.\n\n\n7.1.6 Exercise\nNow do the same as above using “entropy balancing.” Confirm that you’ve achieved balance on the means and the variances of the covariates. Estimate the ATT.\n\n\n\n\n\n\nTip\n\n\n\nDon’t worry (for now) if you don’t understand what this is; simply change the method argument to \"ebal\", we will cover this in class.\n\n\nCode\nOUTPUT &lt;- weightit(FORMULA, \n                   data = d,\n                   method = \"ebal\",\n                   moments = 3,\n                   estimand = \"ATT\")\n\n\n\n\n\n\n7.1.7 Bonus\nImplement a bootstrap of your preferred estimate. What is the bootstrapped standard error?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week07.html#footnotes",
    "href": "week07.html#footnotes",
    "title": "7  Week 7",
    "section": "",
    "text": "Lalonde, R. (1986). “Evaluating the econometric evaluations of training programs with experimental data.” American Economic Review 76: 604-620.↩︎",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 7</span>"
    ]
  },
  {
    "objectID": "week08.html",
    "href": "week08.html",
    "title": "8  Week 8",
    "section": "",
    "text": "8.1 Evaluating a child care program\nThis dataset is taken from Gelman et al. (2020). The dataset contains measurements on the development of nearly 4500 children born in the 1980s.\nNote. We should all be grateful for Noah Greifer’s WeightIt package. You should skim this website to get a sense of how the R code for this kind of analysis used to look like in the old days!\nThe outcome variable will be ppvtr.36 (which simply means “test score at age 3”).1\nHere is the data dictionary:\nCode\ndict_url &lt;- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Childcare/data/datadict.txt\"\n\nread_file(dict_url) |&gt; \n  writeLines()\n\n\nData Dictionary for Child Care example\n\nThe IHDP intervention was implemented in the 1980’s and targeted low\nbirth weight (less than 2500 grams), pre-term children.  They were\nrecruited at the time of birth.  It provided high quality child care\nand other services in their first 3 years of life.  The comparison\ngroup was pulled from a survey conducted during the same time period\ncalled the National Survey of Longitudinal Youth.  At the time of the\nintervention many of the original survey participants (first recruited\nin 1979) had children. We have data from those children and their\nmothers for an overlapping set of variables (below) as the IHDP\nchildren.\n\nThe intervention for low-birth-weight children is described by\n- Brooks-Gunn, J., Liaw, F. R., and Klebanov, P. K. (1992). Effects of\n  early intervention on cognitive function of low birth weight preterm\n  infants. Journal of Pediatrics 120, 350–359.\n- Hill, J. L., Brooks-Gunn, J., and Waldfogel, J. (2003). Sustained\n  effects of high participation in an early intervention for\n  low-birth-weight premature infants. Developmental Psychology 39,\n  730–744.\n\nData columns\n\n\"momage\"   \nmom age at time of birth\n\n\"b.marr\"   \nindicator for whether mom was married at birth\n\n\"momed\"    \nmother’s education level at the time she gave birth\n\n\"work.dur\" \nindicator for whether mom worked in the year before she gave birth\n\n\"prenatal\" \nindicator for whether mom received prenatal care\n\n\"cig\"     \n indicator for whether mom smoked cigarettes while pregnant\n\n\"booze\"    \nindicator for whether mom drank alcohol while pregnant\n\n\"sex\"      \nindicator for whether child was born male or female\n\n\"first\"    \nindicator for whether child was the first born for the mother\n\n\"bw\"       \nchild’s birth weight\n\n\"bwg\"      \nindicator for whether child was born low birth weight\n\n\"preterm\" \nnumber of weeks preterm child was born\n\n\"black\", \"hispanic\", \"white\"    \nindicators for child’s race/ethnicity\n\n\"lths\", \"hs\", \"ltcoll\", \"college\"  \nindicators for mother’s education at time of birth\n\n\"dayskidh\" \nnumber of days child was in the hospital after being born\n\n\"st5\", \"st9\", \"st12\", \"st25\", \"st36\", \"st42\", \"st48\", \"st53\"    \nindicator for state where household resides \n\n\"st99\"  \nindicator for whether family  was living in state served by the ihdp\n\n\"income\"   \nfamily income one year after the child was born\n\n\"treat\"   \nindicator for whether family was allowed to receive IHDP services (1 = yes) \n\n\"ppvtr.36\"\nIQ measured at age 36 months\nAnd here is the data:\nCode\nvar_names &lt;- c(\"momage\", \"b.marr\", \"momed\", \"work.dur\", \"prenatal\", \"cig\", \"booze\", \"sex\", \"first\", \"bw\", \"bwg\", \"preterm\", \"black\", \"hispanic\", \"white\", \"lths\", \"hs\", \"ltcoll\", \"college\", \"dayskidh\", \"st5\", \"st9\", \"st12\", \"st25\", \"st36\", \"st42\", \"st48\", \"st53\", \"st99\", \"income\", \"treat\", \"ppvtr.36\")\n\nurl &lt;- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Childcare/data/cc2.csv\"\n\nd &lt;- read_csv(url) |&gt; \n  select(all_of(var_names)) |&gt; \n  mutate(across(matches(\"st\\\\d{2}\"), as.integer))\n\nglimpse(d)\n\n\nRows: 4,381\nColumns: 32\n$ momage   &lt;dbl&gt; 33, 22, 13, 25, 19, 19, 26, 20, 23, 28, 32, 23, 29, 18, 25, 1…\n$ b.marr   &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1…\n$ momed    &lt;dbl&gt; 4, 1, 1, 4, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 4, 1, 1, 1, 2, 1, 3…\n$ work.dur &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1…\n$ prenatal &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ cig      &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1…\n$ booze    &lt;dbl&gt; 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ sex      &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1…\n$ first    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1…\n$ bw       &lt;dbl&gt; 1559, 2240, 1900, 1550, 2270, 1550, 2330, 2410, 1776, 2140, 2…\n$ bwg      &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0…\n$ preterm  &lt;dbl&gt; 10, 3, 6, 8, 5, 4, 9, 3, 6, 5, 5, 7, 6, 10, 8, 6, 7, 6, 6, 6,…\n$ black    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0…\n$ hispanic &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ white    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1…\n$ lths     &lt;dbl&gt; 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0…\n$ hs       &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ ltcoll   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ college  &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ dayskidh &lt;dbl&gt; 31, 4, 9, 50, 4, 13, 8, 6, 30, 2, 3, 27, 13, 24, 71, 1, 6, 4,…\n$ st5      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ st9      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st12     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st25     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st36     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st42     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st48     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st53     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ st99     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ income   &lt;dbl&gt; 42500.0000, 5000.0000, 12500.0000, 42500.0000, 5000.0000, 125…\n$ treat    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ ppvtr.36 &lt;dbl&gt; 111.00000, 81.00000, 92.00000, 103.00000, 81.00000, 94.00000,…",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week08.html#evaluating-a-child-care-program",
    "href": "week08.html#evaluating-a-child-care-program",
    "title": "8  Week 8",
    "section": "",
    "text": "A subset of 290 of these children received special services in the first few years of life, including high-quality child care (five full days a week) in the second and third years of life as part of a formal intervention, the Infant Health and Development Program (IHDP). These children were targeted because they were born prematurely, had low birth weight (less than or equal to 2500 grams), and lived in the eight cities where the intervention took place. Children in the sample who did not receive the intervention exhibited a more representative range of birth timing and birth weight.\nWe want to evaluate the impact of this intervention on the children’s subsequent cognitive outcomes by comparing the outcomes for children in the intervention group to the outcomes in a comparison group of 4091 children who did not participate in the program. The outcome of interest is test score at age 3; this test is similar to an IQ measure, so we simplistically refer to these scores as IQ scores from now on.\npp. 394-5\n\n\n\n\n\n\n\n\n8.1.1 Exercise\nGelman et al. (2020) say: We excluded the most severely low-birth-weight children (those at or below 1500 grams) from the sample because they are so different from the comparison sample.\n\n\n\n\n\n\nNote\n\n\n\nIn your own words.\n\nWhy did they decide to exclude these children? What problem could we encounter by not omitting them?\nWould you have excluded them from the dataset?2 Why?\n\n\n\n\n\n8.1.2 Exercise\n\n\n\n\n\n\nNote\n\n\n\nLook at the variables.\nWhich ones are you planning to use for covariate balancing? Justify your answer, but keep it short!\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote.\nDepending on what you end up doing you might need to reconsider this answer.\n\n\n\n\n8.1.3 Exercise\nNote. This exercise should take most of your time. Basically, you have to re-do the kind of analysis we did for last week’s homework and at the beginning of this week with Steve (here).\n\n\n\n\n\n\nNote\n\n\n\nUse the WeightIt package and try to achieve balance before estimating the ATT for the effect of this child care program.\nYou will have to do this three separate times, using the following:\n\nPropensity Scores\nCBPS\nEntropy Balancing\n\n\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week08.html#footnotes",
    "href": "week08.html#footnotes",
    "title": "8  Week 8",
    "section": "",
    "text": "It’s not an IQ test, wtf.↩︎\nI wouldn’t!↩︎",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 8</span>"
    ]
  },
  {
    "objectID": "week09.html",
    "href": "week09.html",
    "title": "9  Week 9",
    "section": "",
    "text": "9.1 End of an Era\nThis homework is relatively straightforward, but it might take some time.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Week 9</span>"
    ]
  },
  {
    "objectID": "week09.html#end-of-an-era",
    "href": "week09.html#end-of-an-era",
    "title": "9  Week 9",
    "section": "",
    "text": "9.1.1 Exercise\nLoad the GSS dataset for 2022 and choose one outcome variable and one “treatment” variable. They can be any two variables you want and the treatment can be either binary or continuous, it shouldn’t matter.\n\n\nCode\nlibrary(gssr)\ngss2022 &lt;- gss_get_yr(2022)\n\n\nWhat is the “naive” estimate for the effect of \\(T\\) on \\(Y\\)?\n\n\n9.1.2 Exercise\nSome theory.\nThink very hard about the list of possible confounding variables that might affect this estimate.\n\nDraw a DAG.\nWhat is your estimand (ATE, ATT, ATU)?\n\n\n\n9.1.3 Exercise\nSelect the appropriate covariates in the GSS that allow for causal identification.\nBe very careful when selecting these variables and make a note for any transformation you decide is adequate—e.g., coding a covariate to be binary.\nAre there any variables missing from the DAG you drew earlier?\n\n\n9.1.4 Exercise\nUse regression to get the effect of \\(T\\) on \\(Y\\).\nNote. Remember that it’s relatively straightforward to get the ATT using the marginaleffects package.\n\n\n9.1.5 Exercise\nWeighting.\nSpend some time trying to achieve covariate balancing. You should at least show a “Love plot.”\nNote. Use any method you think is appropriate (e.g., propensity scores, CBPS, entropy balancing).\nWhat is the effect of \\(T\\) on \\(Y\\)?\n\n\n9.1.6 Exercise\nDouble Robustness.\nCombining weighting and regression, what is the effect of \\(T\\) on \\(Y\\)?\n\n\n9.1.7 Exercise\nWrite 3-5 paragraphs explaining your research question, the methods you used, and the answer you came up with.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Week 9</span>"
    ]
  },
  {
    "objectID": "week10.html",
    "href": "week10.html",
    "title": "10  Week 10",
    "section": "",
    "text": "10.1 Exercise\nReshaping data.\nTake a look at the gapminder dataset contained in the gapminder pakacage.\nThe following chunk of code uses the pivot_wider() function to turn this dataset into wider form.\nCode\ngap_wide &lt;- gapminder::gapminder |&gt; \n  select(continent, country, year, lifeExp, gdpPercap) |&gt; \n  pivot_wider(\n    names_from = year, \n    values_from = c(lifeExp, gdpPercap), \n    names_sep = \"\"\n  )\n\ngap_wide\n\n\n# A tibble: 142 × 26\n   continent country lifeExp1952 lifeExp1957 lifeExp1962 lifeExp1967 lifeExp1972\n   &lt;fct&gt;     &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 Asia      Afghan…        28.8        30.3        32.0        34.0        36.1\n 2 Europe    Albania        55.2        59.3        64.8        66.2        67.7\n 3 Africa    Algeria        43.1        45.7        48.3        51.4        54.5\n 4 Africa    Angola         30.0        32.0        34          36.0        37.9\n 5 Americas  Argent…        62.5        64.4        65.1        65.6        67.1\n 6 Oceania   Austra…        69.1        70.3        70.9        71.1        71.9\n 7 Europe    Austria        66.8        67.5        69.5        70.1        70.6\n 8 Asia      Bahrain        50.9        53.8        56.9        59.9        63.3\n 9 Asia      Bangla…        37.5        39.3        41.2        43.5        45.3\n10 Europe    Belgium        68          69.2        70.2        70.9        71.4\n# ℹ 132 more rows\n# ℹ 19 more variables: lifeExp1977 &lt;dbl&gt;, lifeExp1982 &lt;dbl&gt;, lifeExp1987 &lt;dbl&gt;,\n#   lifeExp1992 &lt;dbl&gt;, lifeExp1997 &lt;dbl&gt;, lifeExp2002 &lt;dbl&gt;, lifeExp2007 &lt;dbl&gt;,\n#   gdpPercap1952 &lt;dbl&gt;, gdpPercap1957 &lt;dbl&gt;, gdpPercap1962 &lt;dbl&gt;,\n#   gdpPercap1967 &lt;dbl&gt;, gdpPercap1972 &lt;dbl&gt;, gdpPercap1977 &lt;dbl&gt;,\n#   gdpPercap1982 &lt;dbl&gt;, gdpPercap1987 &lt;dbl&gt;, gdpPercap1992 &lt;dbl&gt;,\n#   gdpPercap1997 &lt;dbl&gt;, gdpPercap2002 &lt;dbl&gt;, gdpPercap2007 &lt;dbl&gt;",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Week 10</span>"
    ]
  },
  {
    "objectID": "week10.html#exercise",
    "href": "week10.html#exercise",
    "title": "10  Week 10",
    "section": "",
    "text": "Exercise:\n\nUse the panelr package to turn the dataset back to its original long form and save it as gap_long.\nUse the panelr package to turn the gap_long into gap_wide, essentially replicating what I did earlier with pivot_wider()\n\n\n\n\n\n\n\n\n\n\nHint: The functions you are looking for are called long_panel() and widen_panel().",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Week 10</span>"
    ]
  },
  {
    "objectID": "week10.html#exercise-1",
    "href": "week10.html#exercise-1",
    "title": "10  Week 10",
    "section": "10.2 Exercise",
    "text": "10.2 Exercise\n\n\n\n\n\n\nSlide 33 contains a very simple visualization made using the line_plot() function.\nTry your best to make a similar graph for the gapminder dataset, with year on the x-axis and lifeExp on the y-axis for a random subset of 10 countries.\nUse ggplot2, do not use line_plot()",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Week 10</span>"
    ]
  },
  {
    "objectID": "week10.html#exercise-2",
    "href": "week10.html#exercise-2",
    "title": "10  Week 10",
    "section": "10.3 Exercise",
    "text": "10.3 Exercise\nICC\n\n\n\n\n\n\nSteve introduced the measurement of “intra class correlation” (ICC) in class.\nWhat is the ICC for lifeExp, pop, and gdpPercap in the gapminder dataset?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Week 10</span>"
    ]
  },
  {
    "objectID": "week10.html#exercise-3",
    "href": "week10.html#exercise-3",
    "title": "10  Week 10",
    "section": "10.4 Exercise",
    "text": "10.4 Exercise\n\n\n\n\n\n\nUse the WageData from the panelr package. You don’t need to make a panel_data version of WageData for this analysis, but you can if you want. We will use it later. Estimate the following mixed models using lmer() with maximum likelihood (REML = FALSE):\n\nLog wage as a function of college and linear time\nAs #1, plus a random slope on time\nAs #2, but with time as a quadratic\n\nYou may get some warning messages. The correct specifications of these models fit well, but you can use lme4::allFit() if you really want to make sure that you’re getting trustworthy results.\nOnce you have estimated the models, compare their BIC values using BIC(). Select the best model (here, the one with the lowest BIC) then do the following:\n\nReport the estimated effect of college on log wages given the data and model. You can get this using tidy(), summary(), or any other function you prefer.\nUse ggpredict() |&gt; plot() (or another approach if you like) to plot predictions for a sample of 9 individuals over time.\n\n\n\nCode\ndata(\"WageData\", package = \"panelr\")\n\nWageData &lt;- WageData |&gt; \n  mutate(\n    college = if_else(ed &gt;= 16, 1L, 0L),  # college variable\n    t0 = t - 1                            # start time at 0\n  )\n\n\nThe model output that comes from the lmer() looks very different from the ones produced by lm() and glm(). Take note of anything you don’t understand in the output and be ready to ask questions in class about the things you don’t understand.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Week 10</span>"
    ]
  },
  {
    "objectID": "week11.html",
    "href": "week11.html",
    "title": "11  Week 11",
    "section": "",
    "text": "11.1 Exercise",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise",
    "href": "week11.html#exercise",
    "title": "11  Week 11",
    "section": "",
    "text": "In the Event Studies chapter we estimated the effect of something that occurs at a specific time by just comparing before-event to after-event, without really using a control group. What assumption is made by no-control-group event studies that we don’t have to make with difference-in-differences?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-1",
    "href": "week11.html#exercise-1",
    "title": "11  Week 11",
    "section": "11.2 Exercise",
    "text": "11.2 Exercise\n\nWhich of the following potential back doors is controlled for by comparing the treated group to a control group?\n\nThe treated group may be following a trend, unique to the group, that would make the outcome change from before-treatment to after-treatment anyway\nThere may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway\nThere may be differences in typical outcome levels between the treated group and the untreated group\nThe decision to treat the treated group, rather than some other group, may be based on factors that are related to the outcome",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-2",
    "href": "week11.html#exercise-2",
    "title": "11  Week 11",
    "section": "11.3 Exercise",
    "text": "11.3 Exercise\n\nConsider a treatment and control group. Looking only at the pre-treatment period, they have exactly the same outcomes (zero gap between them in each period).\n\nDespite having exactly the same outcomes pre-treatment, it happens to be the case that parallel trends is violated for these two groups. How is this possible? Explain what it means for parallel trends to be violated in this case, or give an example of how it could be violated.\nIf we estimate the causal effect in this case using difference-in-differences, even though parallel trends is violated, how much would our effect be off by? (note you won’t be able to give a specific number)",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-3",
    "href": "week11.html#exercise-3",
    "title": "11  Week 11",
    "section": "11.4 Exercise",
    "text": "11.4 Exercise\n\nConsider the below graph showing the average outcome for treated and control groups in the lead up to treatment (indicated by the dashed line), and also after treatment\n\n\n\n\n\n\n\n\nBased on the prior trend, does it seem likely that parallel trends holds in this instance?\nIf we estimate difference-in-differences anyway, are we likely to overestimate the actual causal effect, underestimate it, or get it right on average?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-4",
    "href": "week11.html#exercise-4",
    "title": "11  Week 11",
    "section": "11.5 Exercise",
    "text": "11.5 Exercise\n\nIn mid-2020, during the COVID-19 pandemic, different countries pursued different courses of action. Some locked down fully, imposing harsh penalties to most people for leaving the house outside certain proscribed times. Some were looser and only suggested staying at home, and some had hardly any restrictions at all. You notice that COVID rates tend to spike dramatically in different countries at seemingly-random times, and want to know if certain restrictions helped.\nFrom March through May 2020, US and Canada COVID case rates followed similar trends (US rates were higher, but the trends were similar). You want to look at the effect of COVID restrictions enacted in Canada in late May 2020 on case rates. Is DID, with the US as a control group, a good way to estimate this effect? If not, what concerns would you have about this research design?",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-5",
    "href": "week11.html#exercise-5",
    "title": "11  Week 11",
    "section": "11.6 Exercise",
    "text": "11.6 Exercise\n\nConsider the below table of mean outcomes, and calculate the difference-in-difference effect of treatment. Write out the equation you used to calculate it (i.e. show how the four numbers in the table are combined to get the estimate)\n\n\n\n\n\nBefore\nAfter\n\n\nTreated\n5\n9\n\n\nUntreated\n6\n7.5",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-6",
    "href": "week11.html#exercise-6",
    "title": "11  Week 11",
    "section": "11.7 Exercise",
    "text": "11.7 Exercise\n\nYou are planning to estimate whether voter-protection laws increase voter turnout. You note that, in 2015, a lot of new voter-protection laws were enacted in some provinces but not in others. Conveniently, no new laws were enacted in 2012, 2014, or 2016, so you decide to use 2012 and 2014 as your “before” periods and 2016 as “after”.\n\nWhich of the following best describes what you’d want to regress state-and-year level “voter turnout” measures on?\n\nAn indicator for whether the state is treated, and an indicator for whether the year is 2016.\nA set of fixed effects for state, and a set of fixed effects for year.\nAn indicator for whether the state is treated, a set of fixed effects for year, and an indicator for whether the state is currently treated.\nA set of fixed effects for state, and for year, and an interaction between “is 2016” and “is a treated state”.\nThis design should not be estimated using a regression.\n\nUnless you chose the final option in the previous question, specify which coefficient in that regression would give you the DID estimate.",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-7",
    "href": "week11.html#exercise-7",
    "title": "11  Week 11",
    "section": "11.8 Exercise",
    "text": "11.8 Exercise\nNot from NHK.\nIn your own words, describe what is the “two-way fixed effects difference-in-difference estimator.” What does this model assume about the effect of some treatment over time?\nYou might need to re-read this section:\nhttps://theeffectbook.net/ch-DifferenceinDifference.html#long-term-effects",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-8",
    "href": "week11.html#exercise-8",
    "title": "11  Week 11",
    "section": "11.9 Exercise",
    "text": "11.9 Exercise\n\nConsider the below graph with estimates from a dynamic difference-in-differences model for a treatment that occurs between periods 4 and 5, with 95% confidence intervals shown.\n\n\n\n\n\n\n\n\nWhat about this graph might make us concerned about our identification assumptions?\nIgnoring any concerns we have, what would we say is the effect of treatment on Y in this case? (note the height of the line in period 5 is about 3, in period 6 is about 1, and in period 7 is about .5).",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "week11.html#exercise-9",
    "href": "week11.html#exercise-9",
    "title": "11  Week 11",
    "section": "11.10 Exercise",
    "text": "11.10 Exercise\nThis exercise is also taken directly from NHK.\n\nOne. In this assignment we will be walking through a very simple application of difference-in-differences that comes from Peter Nencka. In particular, it seemed that the beginning of the COVID-19 pandemic led to a brief craze for homemade sourdough bread, as people had to stay home, and stores were out of yeast (sourdough can be made at home using yeast from the air and does not require store-bought yeast). We will be estimating whether COVID lockdowns actually increased interest in sourdough bread,\nWe will be measuring interest in sourdough bread using Google Trends data in the USA. Google Trends tracks the popularity of different search terms over time. We will be comparing the popularity of the search term “sourdough” against the control groups: the search terms “cereal,” “soup,” and “sandwich,” the popularity of which we suspect might not have been meaningfully affected by COVID lockdowns.\n\nThis is the data:\n\n\nCode\nlibrary(tidyverse)\n\nurl &lt;- \"https://raw.githubusercontent.com/NickCH-K/TheEffectAssignments/main/sourdough_trends.csv\"\n\nsr &lt;- read_csv(url) |&gt; \n  select(date, keyword, hits) |&gt; \n  mutate(\n    date = as.Date(date),\n    keyword = factor(keyword)\n  )\n\nglimpse(sr)\n\n\nRows: 856\nColumns: 3\n$ date    &lt;date&gt; 2020-01-01, 2020-01-02, 2020-01-03, 2020-01-04, 2020-01-05, 2…\n$ keyword &lt;fct&gt; sourdough, sourdough, sourdough, sourdough, sourdough, sourdou…\n$ hits    &lt;dbl&gt; 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 4, 3, 2, 2, 2, 2, 3, 4, 3, 4, 2,…\n\n\n\nTwo. Make a line graph with date on the x-axis and hits on the y-axis, with a separate line for each keyword. Also add a vertical line for the “start of the pandemic” which we’ll decide for our purposes is March 15, 2020.\n\nHint. You’ll need to add geom_vline(xintercept = as.Date(\"2020-03-15\")).\n\nThree. Looking at your graph, comment on (a) whether it looks like the lockdown had an effect on the popularity of sourdough, (b) the shape that effect takes (i.e. is it a permanent increase in popularity? Temporary?), (c) whether you might be concerned about any of the control groups we’ve chosen\nFour. Create a “Treated” indicator that’s equal to 1 for sourdough and 0 otherwise (or True/False, either way). Do a test of whether the prior trends (keeping March 15 as the “treatment date”) differ between the treated and control groups, using a linear trend and doing a statistical significance test at the 95% level. Then, if you were concerned about any of the control groups in question 3c, drop any you were concerned about (and keep them dropped for the rest of the assignment) and rerun the test.\n\nNote. NHK refers to this kind of test as a “placebo test.” We are just trying to increase our confidence in the parallel trends assumption.\n\nWrite a line commenting on whether you can reject equal prior trends in your model(s).\nFive. Create a month variable by shifting the date variable back 15 days (so that the treatment day is the first day of the month) and then taking the month of the resulting date. Also create an After variable equal to 1/0 (or True/False) if the date is March 15 or afterwards.\nThen, take a look at the values of month you get and how they line up with date, and subtract a number from month so that the last period just before treatment (Feb 16-Mar 14) is 0. (Also, change the Jan 1-14 month so it’s one less than the Jan 15-Feb 14 month)\n(You can then use -lubridate::days() to subtract days from the date, and lubridate::month() to get the month from the date.)\nThen, use two-way fixed effects to estimate the difference-in-difference estimate of the effect of lockdown on sourdough popularity with keyword and month fixed effects, and standard errors clustered at the keyword level.\n\n\n\n\n\n\n\nLast class we had a little confusion with the p-values reported by the fixest::feols(). We will figure this out next week, so don’t worry too much about them.\n\n\n\n\n\n\n\n\n\nHint: This data-wrangling bit is trickier than it seems. Don’t feel discouraged!\n\n\n\n\n\n\n\n\n\nThe chapter introduces dynamic treatment effects, which where briefly discussed by Steve. One of the reasons fixest is becoming a popular package is because it makes estimating these models very easy, although it introduces a special syntax.\nThis is how we would estimate a difference-in-difference model allowing the effect to differ by month (using month = 0 as a reference period), with standard errors clustered at the keyword level.\n\n\nCode\ndynamic &lt;- feols(\n  hits ~ i(month, Treated, ref = 0) | keyword + month,\n  cluster = \"keyword\",\n  data = sr\n)\n\ncoefplot(dynamic)",
    "crumbs": [
      "Part 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Week 11</span>"
    ]
  },
  {
    "objectID": "solutions01.html",
    "href": "solutions01.html",
    "title": "12  Solutions 1",
    "section": "",
    "text": "12.1 Exercise\nPackages\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Optima\"))\nThe following data frame contains the potential outcomes for 8 individuals.\nCode\nd &lt;- data.frame(\n  T = c(0, 0, 1, 0, 0, 1, 1, 1),\n  Y0 = c(5, 8, 5, 12, 4, 8, 4, 9),\n  Y1 = c(5, 10, 3, 13, 2, 9, 1, 13), \n  id = LETTERS[1:8]\n)\n\nd\n\n\n  T Y0 Y1 id\n1 0  5  5  A\n2 0  8 10  B\n3 1  5  3  C\n4 0 12 13  D\n5 0  4  2  E\n6 1  8  9  F\n7 1  4  1  G\n8 1  9 13  H\nThe variable T depicts whether someone got the “treatment” or not.\nCreate a new variable called Y that contains the observed outcomes.\nCode\nd &lt;- d |&gt; \n  mutate(Y = ifelse(as.logical(T), Y1, Y0))\n\nd\n\n\n  T Y0 Y1 id  Y\n1 0  5  5  A  5\n2 0  8 10  B  8\n3 1  5  3  C  3\n4 0 12 13  D 12\n5 0  4  2  E  4\n6 1  8  9  F  9\n7 1  4  1  G  1\n8 1  9 13  H 13\nWhat is the Average Treatment Effect (ATE) for this 8 person experiment?\nCode\n## ate --- based on \"complete\" data\nd |&gt; \n  mutate(TE = Y1 - Y0) |&gt; \n  summarize(ATE = mean(TE))\n\n\n    ATE\n1 0.125\n\n\nCode\n## ate --- \"naive\" estimate based on observed data\nmean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n\n\n[1] -0.75",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Solutions 1</span>"
    ]
  },
  {
    "objectID": "solutions01.html#exercise-1",
    "href": "solutions01.html#exercise-1",
    "title": "12  Solutions 1",
    "section": "12.2 Exercise",
    "text": "12.2 Exercise\nSimulate a new completely randomized experiment on these 8 people; that is, re sample \\(T\\) at random so that equal numbers get the treatment and the control.\n\n\nCode\nd$T &lt;- sample(d$T)\n\n\nCreate a new variable called Y that contains the observed outcomes.\n\n\nCode\nd &lt;- d |&gt; \n  mutate(Y = ifelse(as.logical(T), Y1, Y0))\n\n\nWhat is the Average Treatment Effect (ATE) for this 8 person experiment?\n\n\nCode\n## naive estimate\nmean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n\n\n[1] 0.25\n\n\nDo this a couple of times (at least 3) and note the differences.\nI will do this a couple of hundred times.\n\n\nCode\nout &lt;- replicate(1e3, {\n  d$T &lt;- sample(d$T)\n  d$Y &lt;- ifelse(as.logical(d$T), d$Y1, d$Y0)\n  mean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n})\n\nsummary(out)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-6.5000 -1.7500  0.0000  0.0355  2.0000  6.7500 \n\n\nHow do these estimates compare to the “real” ATE?\n\n\nCode\ntibble(x = out) |&gt; \n  ggplot(aes(x, y = \"\")) + \n  geom_boxplot() + \n  geom_jitter(height = 1/10, alpha = 1/4) + \n  geom_point(x = 0.125, fill = \"pink\", shape = 21, size = 5) +\n  labs(y = NULL)\n\n\n\n\n\n\n\n\n\nThey are all over the place. But… on average they’re sort of close.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Solutions 1</span>"
    ]
  },
  {
    "objectID": "solutions01.html#exercise-2",
    "href": "solutions01.html#exercise-2",
    "title": "12  Solutions 1",
    "section": "12.3 Exercise",
    "text": "12.3 Exercise\nObviously, an experiment of 8 people will not give you enough “statistical power.”\nAssuming the ATE is \\(0.125\\), how many people would you need to enroll in this experiment to have enough statistical power?\n\n\n\n\n\n\nTip\n\n\n\nHint: There are a few different ways of giving a reasonable answer to this question. The wording of this problem is ambiguous.\n\n\nTo get at questions of statistical power we need to establish two things from the outset: (1) the “effect” we believe exists out there and (2) the desired standard error. For the latter, this usually means choosing a sample size so that the resulting standard error that will allow me to have a false negative rate of at least 80% But this is just a convention.\nSteve’s code already shows how to do this with the built-in t.test and power.t.test functions. He also had to make assumptions about the the distribution of the potential outcomes in the population. We all have to do this, except that sometimes we don’t realize it because the assumptions are hidden away in some kind of Internet sample size calculator.\nThis is how I would have done it.\nStep 1. I will assume that the standard deviation for each potential outcome in the 8 person experiment is the same in the wider population. This is a big assumption, but it’s the one I’ll go with. This is the main difference between what Steve did and what I did (his assumptions about the population variance are hidden in lines 54-56).\n\n\nCode\nsdY0 &lt;- sd(d$Y0)\nsdY0\n\n\n[1] 2.850439\n\n\nCode\nsdY1 &lt;- sd(d$Y1)\nsdY1\n\n\n[1] 4.869732\n\n\nNote. Think about what I just did. I assumed the heterogeneity in treatment effects among those who got the treatment is larger than it is for those who didn’t. Would this make sense in real life? Maybe?\nStep 2. I will assume that half the sample gets a treatment and the other half does not. This allows me to calculate the standard error of the difference in means simply as:\n\\[\n\\text{SE} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} = \\sqrt{\\frac{2(\\sigma_1^2 + \\sigma_2^2)}{n}}\n\\]\n\n\\(\\frac{n}{2} = n_1 = n_2\\)\n\nStep 3. Choose a simple heuristic so that my standard error is good enough.\n\n\n\n\n\n\nWarning\n\n\n\nNote. You might be tempted to use the simple statistical significance heuristic, according to which you need a standard error that is half the size of the effect ( \\(\\text{SE} = 0.0625\\) ). But this is wrong. If this was the case, then you would get a statistically significant ( \\(\\alpha = 0.05\\) ) only half the time. Most people go for 80%\n\n\nCode\nggplot() + \n  xlim(-1/2, 1/2) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0, 0.0625), \n    geom = \"area\", aes(fill = \"null distribution\")\n  ) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0.125, 0.0625), \n    geom = \"area\", aes(fill = \"sampling distribution\"), alpha = 1/4\n  ) + \n  geom_vline(xintercept = qnorm(c(0.025, 0.975), 0, 0.0625), linetype = \"dashed\") + \n  labs(\n    y = \"density\", x = \"ATE\", fill = NULL,\n    caption = \"Note: dashed lines indicate traditional statistical significance break points\",\n    subtitle = \"\\\"Power\\\" with standard error half the size of the effect\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nSo, I will use the simple heuristic that I want my standard error to be a third the size of my effect, so around 0.042.\n\n\nCode\n## sample size with simple algebra\n2*(sdY0^2 + sdY1^2) / 0.042^2 \n\n\n[1] 36098.96\n\n\nBased on this simple sketch, I anticipate that my sample size will have to be huge in order to detect such a small effect.\nHow does this look like?\n\n\nCode\nggplot() + \n  xlim(-1/3, 1/3) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0, 0.042), \n    geom = \"area\", aes(fill = \"null distribution\")\n  ) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0.125, 0.042), \n    geom = \"area\", aes(fill = \"sampling distribution\"), alpha = 1/4\n  ) + \n  geom_vline(xintercept = qnorm(c(0.025, 0.975), 0, 0.042), linetype = \"dashed\") +\n  labs(\n    y = \"density\", x = \"ATE\", fill = NULL,\n    caption = \"Note: dashed lines indicate traditional statistical significance break points\",\n    subtitle = str_glue(\"\\\"Power\\\" with sample size of 36,099\")\n  )\n\n\n\n\n\n\n\n\n\nTo calculate the statistical power we simply calculate the area under the sampling distribution above the desired cutoff point.\n\n\nCode\ncutoff &lt;- qnorm(0.975, mean = 0, sd = 0.042) ## null distribution\npnorm(cutoff, mean = 0.125, sd = 0.042, lower.tail = FALSE)\n\n\n[1] 0.8452392\n\n\nIf you want to get more exact numbers for the traditional 80% power (and this is just another fetishized number), we can use some algebra:\n\\[\n\\begin{align}\n0 + 1.96 \\cdot \\text{SE} &= \\overbrace{0.125}^\\text{ATE} - 0.84 \\cdot \\text{SE} \\\\\n\\text{SE} &=  0.125 / 2.8 \\\\ &\\approx 0.045\n\\end{align}\n\\]\n\n\n\nCode\nqnorm(0.2, mean = 0, sd = 1)\n\n\n[1] -0.8416212\n\n\n\nWhich we can unpack to solve for the sample size:\n\\[\n\\begin{align}\n\\sqrt{\\frac{2(\\sigma^1 + \\sigma^2)}{n}} &= 0.045 \\\\\n2\\times\\frac{\\sigma_1^2 + \\sigma_2^2}{0.045^2} &= n\n\\end{align}\n\\]\nOr you could use more complicated R functions… although I find this to be much easier than algebra.\n\n\nCode\nstat_power &lt;- function(n) {\n  ## this function will use our assumptions about standard deviations \n  ## in the population and output the statistical power that corresponds\n  ## to a specific sample size\n  se &lt;- sqrt(2*(sdY0^2 + sdY1^2) / n)       ## population variance assumption\n  cutoff &lt;- qnorm(0.975, mean = 0, sd = se) ## null distribution cutoff\n  pnorm(cutoff, mean = 0.125, sd = se, lower.tail = FALSE) ## stat power\n}\n\nsample_size &lt;- function(power = 0.8, interval = c(300, 1e6)) {\n  ## this function will find the value of \"n\" for which the output\n  ## of stat_power(n) - \"power\" is zero\n  out &lt;- uniroot(\\(n) stat_power(n) - power, interval = interval)\n  out$root\n}\n\nsample_size(power = 0.8)\n\n\n[1] 31987.55\n\n\nCode\nggplot() + \n  xlim(1e3, 50e3) + \n  geom_function(fun = stat_power) + \n  geom_hline(yintercept = 0.8, linetype = \"dashed\") + \n  geom_vline(xintercept = sample_size(power = 0.8), linetype = \"dashed\") + \n  labs(x = \"Sample Size\", y = \"Statistical Power\")",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Solutions 1</span>"
    ]
  },
  {
    "objectID": "solutions02.html",
    "href": "solutions02.html",
    "title": "13  Solutions 2",
    "section": "",
    "text": "13.1 Exercise\nWhich of the following is the best definition of the term identified as in “this variation has identified the effect we’re interested in”?",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions02.html#exercise",
    "href": "solutions02.html#exercise",
    "title": "13  Solutions 2",
    "section": "",
    "text": "We’ve generated the data by conducting a controlled experiment in which treatment is randomly assigned.\nIn the data generating process, the only reason why we see variation in the outcome variable is because of the treatment variable.\nThis is very convoluted wording, but it’s wrong. The outcome variable can be a function of many other things. What we care about is that there’s no backdoor paths confounding the effect we are interested in.\nThe relationship we are looking at in the data actually tests a hypothesis.\nIn the variation we use, there’s no reason we’d see any relationship at all except for the effect we’re interested in.\nThis is very convoluted wording, but it is correct. It’s closer to the idea of isolating a causal path.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions02.html#exercise-1",
    "href": "solutions02.html#exercise-1",
    "title": "13  Solutions 2",
    "section": "13.2 Exercise",
    "text": "13.2 Exercise\nYou read about a new study with the headline “eating caviar linked to longer lifespan.” The study’s research question is “does eating caviar make you live longer?” In the study’s data, they find that people who eat caviar have, on average, longer lifespans than people who don’t.\n\nWhat are some alternate explanations for this relationship?\nPossible confounders: education, income, …\nWhat sort of variation would identify the answer to the research question?\nWe would need to close the backdoor path between “eating caviar” and longer lifespans. There are a couple of ways to do this, some easier than others. For example, I can’t imagine an experimental set up in which we could randomly assign a special diet to people and then follow them until they die.\nThus, we would look at variation within different levels of income and education.\nGive one suggestion for how the study authors might isolate variation that would identify the answer to the research question\nWe could close the back door path via (1) regression with “adjustment” for all confounders; and (2) matching and weighting on all relevant features of the population.\nBoth approaches ensure we are looking at the variation within mentioned in B.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions02.html#exercise-2",
    "href": "solutions02.html#exercise-2",
    "title": "13  Solutions 2",
    "section": "13.3 Exercise",
    "text": "13.3 Exercise\nFor each of the following news headlines, assume that the underlying data actually only shows a correlation between the two variables mentioned. Give an alternate explanation for the correlation other than the causal relationship implied by the headline.\n\n“As stock market drops, presidential approval ratings decline.”\nPossible answers: economic growth (and contraction), political stability\n“Dates are announced for the downtown summer concert series, driving up sales at downtown restaurants.”\nPossible answers: (summer) weather\n“Unsanitary? Hospital visits linked to 20% increased risk of disease.”\nPossible answers: sickness (i.e., sick people self-select into hospital visits)\n“Dress for success! Every CEO follows this office-wear rule.”\nPossible answers: professional norms (CEOs are more likely to wear fancier clothing), wealth (CEOs have the money to dress up nicely)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions02.html#exercise-3",
    "href": "solutions02.html#exercise-3",
    "title": "13  Solutions 2",
    "section": "13.4 Exercise",
    "text": "13.4 Exercise\nWhy is a variable that causes both the “treatment” and “outcome” variables especially concerning for identification? You may want to use the phrase “alternate explanation” in your answer.\nVariables that cause both treatment and outcome open confounding paths—i.e., it makes researchers unable to separate the variation in the outcome that’s due to the treatment from the variation that’s due to alternative explanations (confounding variables).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions02.html#exercise-4",
    "href": "solutions02.html#exercise-4",
    "title": "13  Solutions 2",
    "section": "13.5 Exercise",
    "text": "13.5 Exercise\nShoe company Crikey claims that people who wear their fancy and expensive professional running-shoe Cool Mistrunner brand run 4 to 5% faster than if they wore an average shoe.\n\nIn a few sentences, describe the data-generating process (you will probably leave some things out, that’s okay).\nThis special shoe will increase your running speed.\n\\(\\text{special shoe} \\to \\text{running speed}\\)\nWhat are possible alternative explanations for this claim, aside from the shoe making the person run faster?\nProfessional runners and hobbyists like to buy sport related articles of clothes, including special shoes. This opens a confounding path.\n\\(\\text{special shoe} \\leftarrow \\text{likes to run} \\to \\text{running speed}\\)\nThere are many more alternative explanations, including ones mentioned in (C).\nIn running their study, the researchers accounted for some alternative explanations, including: gender, enthusiasm for running, and whether runners have participated in marathons and/or half marathons. Think of an alternative explanation not on this list. What is the implication of not accounting for this alternative explanation?\nIt could be that the Cool Mistrunner brand targets younger sports enthusiasts and that younger people run faster than older people. Maybe?",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Solutions 2</span>"
    ]
  },
  {
    "objectID": "solutions03.html",
    "href": "solutions03.html",
    "title": "14  Solutions 3",
    "section": "",
    "text": "14.1 Exercise\nThe missing cells are like this because of the ignorability assumption in a perfectly executed experiment.\nATE: 5,000",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise",
    "href": "solutions03.html#exercise",
    "title": "14  Solutions 3",
    "section": "",
    "text": "Group (\\(T\\))\n\\(E[Y^1]\\)\n\\(E[Y^0]\\)\n\n\n\n\n\\(T = 1\\)\n10,000\n5,000\n\n\n\\(T = 0\\)\n10,000\n5,000",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-1",
    "href": "solutions03.html#exercise-1",
    "title": "14  Solutions 3",
    "section": "14.2 Exercise",
    "text": "14.2 Exercise\nDraw a causal diagram for the research question “do long shift hours make doctors give lower-quality care?” that incorporates the following features (and only the following features):\n\nLong shift hours affect both how tired doctors are, and how much experience they have, both of which affect the quality of care\nHow long shifts are is often decided by the hospital the doctor works at. There are plenty of other things about a given hospital that also affect the quality of care, like its funding level, how crowded it is, and so on\nNew policies that reduce shift times may be implemented at the same time (with the timing determined by some unobservable change in policy preferences) as other policies that also attempt to improve the quality of care",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-2",
    "href": "solutions03.html#exercise-2",
    "title": "14  Solutions 3",
    "section": "14.3 Exercise",
    "text": "14.3 Exercise\nConsider this research question: Does the funding level of public schools affect student achievement for students in your country?\n\nWhat is the treatment and what is the outcome of interest?\nOutcome: student achievement. Treatment: funding level.\nWrite down a list of relevant variables.\nRelevant variables: government budget, student SES, class size, staff salary, other social welfare policies.\nWhich of the variables in your list in part b are causes of both treatment and outcome?\nGovernment budget\nWhy might we want to pay extra attention to the variables listed in part c?\nBecause they are confounders\nDraw a causal diagram of the variables listed in part b.\n\nSimplify the diagram from part e.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-3",
    "href": "solutions03.html#exercise-3",
    "title": "14  Solutions 3",
    "section": "14.4 Exercise",
    "text": "14.4 Exercise\nHow can a causal diagram be modified so as to avoid cyclic relationships?\nConsider the diagram below. It depicts a cyclical relationship between student achievement and motivation. If students achieve more (i.e., score well on exams), then their motivation goes up, and if their motivation goes up, they achieve more. Change the diagram so that the relationship is not cyclic anymore.\n\\[\n\\text{Student Achievement} \\longleftrightarrow \\text{Motivation}\n\\]\nPossible answer:",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-4",
    "href": "solutions03.html#exercise-4",
    "title": "14  Solutions 3",
    "section": "14.5 Exercise",
    "text": "14.5 Exercise\nAssuming that a path has no colliders on it, what is the difference between a path being Open and Closed?\nAt least one of the variables in the path has been adjusted for—i.e., variation is removed or “controlled” for.\nNote. Remember that you’ll always sound smarter if you say “adjusted” instead of “controlled” in the context of regression with observational data.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-5",
    "href": "solutions03.html#exercise-5",
    "title": "14  Solutions 3",
    "section": "14.6 Exercise",
    "text": "14.6 Exercise\nConsider the below generic causal diagram.\n\n\n\n\n\n\nList every path from X to Y.\n\\[\n\\begin{align}\n&1. &&X \\to A \\to Y, \\\\\n&2. &&X \\leftarrow B \\to Y, \\\\\n&3. &&X \\leftarrow B \\leftarrow D \\to Y, \\\\\n&4. &&X \\to C \\leftarrow D \\to Y, \\\\\n&5. &&X \\to C \\leftarrow D \\to B \\to Y\n\\end{align}\n\\]\nWhich of the paths are front-door paths?\n1\nWhich of the paths are open back-door paths?\n2 and 3\nWhat variables must be controlled for in order to identify the effect of X on Y? (only list what must be controlled for, not anything that additionally could be controlled for).\n\\(B\\)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-6",
    "href": "solutions03.html#exercise-6",
    "title": "14  Solutions 3",
    "section": "14.7 Exercise",
    "text": "14.7 Exercise\nWhich of the following describes a causal path where all the arrows point away from the treatment?\n\nOpen Path\nClosed Path\nFront Door Path (this one)\nBack Door Path",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-7",
    "href": "solutions03.html#exercise-7",
    "title": "14  Solutions 3",
    "section": "14.8 Exercise",
    "text": "14.8 Exercise\nConsider the figure below, which depicts the relationship between teaching quality, number of publications (e.g., articles, books), and popularity among scholars and students in a population of professors.\n\n\n\n\n\n\nWhat type of variable is Popularity in one path on this diagram?\nDiscuss what would happen if you controlled for Popularity.\n\nPopularity is a collider variable. If we “control” (remove variation) for Popularity we will artificially create a negative association between Teaching Quality and Number of Publications",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-8",
    "href": "solutions03.html#exercise-8",
    "title": "14  Solutions 3",
    "section": "14.9 Exercise",
    "text": "14.9 Exercise\nGo to the app Steve showed us in class.\nhttps://cbdrh.shinyapps.io/daggle/\nSpend some time noodling around with it and upload screenshots with the right answer for three DAGs with 4, 6, and 8 nodes each. Set the complexity to “difficult.”\nGrading based is conditional on screenshots.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-9",
    "href": "solutions03.html#exercise-9",
    "title": "14  Solutions 3",
    "section": "14.10 Exercise",
    "text": "14.10 Exercise\nHouse of DAG Simulation.\nI’ve included a little script with a couple of functions meant to illustrate the connection between DAGs and the estimands we saw in class (ATE, ATT, ATC).\nSave it to your project and load it using the source() function.\nYou should see a function called hod_simulation() which creates a dataset that corresponds to the following DAG:\n\n\n\n\n\n\n\\(Y\\): outcome\n\\(T\\): treatment\n\\(U\\): unobserved confounder\n\\(S\\): affects selection into \\(T\\)\n\\(X\\): affects \\(Y\\) directly\n\n\n\nThe hod_simulation() function has the following arguments:\n\nN: Sample Size\nrho: The correlation between \\(S\\) and \\(X\\), it accepts values between -1 and 1.\nBt: this is the treatment effect.\nBx: this is the direct effect of \\(X\\) on \\(Y\\)\n\nThis is the dataset it creates:\n\n\nCode\nsource(\"hod_simulation_functions.R\")\n\n\nStandard Error ~  0.322 \nPower ~  0.873# A tibble: 4 × 3\n  variable    sd  mean\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 y        5.23  1.49 \n2 t        0.500 0.503\n3 x        1.03  0.979\n4 s        0.990 1.00 \n\n\nCode\nset.seed(12345) ## include this so that grading is easier for me.\nd &lt;- hod_simulation(N = 1e3, Bt = 2, Bx = 4, rho = 0.8)\n\n\nStandard Error ~  0.405 \nPower ~  0.999# A tibble: 4 × 3\n  variable    sd  mean\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 y        6.75   4.98\n2 t        0.500  0.52\n3 x        1.02   1.00\n4 s        1.01   1.02\n\n\nNote. Ignore the “Standard Error” and “Power” messages.\n\n\nCode\nglimpse(d)\n\n\nRows: 1,000\nColumns: 6\n$ y0 &lt;dbl&gt; 3.0258462, 5.2008689, -0.3510375, -2.7643240, -3.7947830, 12.879242…\n$ y1 &lt;dbl&gt; 5.0258462, 7.2008689, 1.6489625, -0.7643240, -1.7947830, 14.8792426…\n$ t  &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1…\n$ y  &lt;dbl&gt; 5.0258462, 7.2008689, 1.6489625, -0.7643240, -3.7947830, 12.8792426…\n$ x  &lt;dbl&gt; 1.89642215, 0.54549787, -0.35506814, 1.03476207, 0.05065330, 2.5734…\n$ s  &lt;dbl&gt; 1.84099574, 0.69942604, 0.72890759, 1.44006399, 0.33470650, 1.70875…\n\n\nWithout looking at the results just yet… do you think the naive estimate will be larger or smaller than the “real” estimate ( \\(ATE = 2\\) )?\nThe results should be larger because people who get the treatment should also a higher \\(X\\), and the effect of \\(X\\) is positive.\nCheck your answer. What are the results given by the naive estimator?\n\n\nCode\nd |&gt; \n  group_by(t) |&gt; \n  summarize(across(c(y0, y1), mean))\n\n\n# A tibble: 2 × 3\n      t    y0    y1\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0  2.00  4.00\n2     1  5.72  7.72\n\n\nCode\nmean(d$y[d$t == 1]) - mean(d$y[d$t == 0])\n\n\n[1] 5.718145\n\n\nRe-do this but set rho to -0.8 (so that \\(S\\) and \\(X\\) are now negatively correlated).\n\n\nCode\nset.seed(12345)\nd &lt;- hod_simulation(N = 1e3, Bt = 2, Bx = 4, rho = -0.8)\n\n\nStandard Error ~  0.405 \nPower ~  0.999\n\n\nJoining with `by = join_by(variable)`\n\n\n# A tibble: 4 × 3\n  variable    sd  mean\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 y        5.96  4.88 \n2 t        0.500 0.512\n3 x        0.995 0.983\n4 s        0.984 1.02 \n\n\nCode\nd |&gt; \n  group_by(t) |&gt; \n  summarize(across(c(y0, y1), mean))\n\n\n# A tibble: 2 × 3\n      t    y0    y1\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0  5.92  7.92\n2     1  1.88  3.88\n\n\nCode\nmean(d$y[d$t == 1]) - mean(d$y[d$t == 0])\n\n\n[1] -2.043275\n\n\nNote. You should have been able to figure out that the “naive estimator” (difference between groups) was going to be biased in the opposite side (i.e., smaller or even negative).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions03.html#exercise-10",
    "href": "solutions03.html#exercise-10",
    "title": "14  Solutions 3",
    "section": "14.11 Exercise",
    "text": "14.11 Exercise\nTake the dataset d created in the previous question and modify it so that the treatment is now randomized (this will destroy the path between \\(S\\) and \\(T\\)).\n\n\nCode\nd$t &lt;- sample(d$t)\nd$y &lt;- ifelse(as.logical(d$t), d$y1, d$y0)\n\n\nWithout looking at the results just yet… do you think the naive estimate will be larger or smaller than the “real” estimate ( \\(ATE = 2\\) )?\nThe answers should be roughly the same as the “real” estimate because we have effectively destroyed the backdoor path via the randomization of the treatment. But there’s still margin for sampling error, so we should also look at the standard error.\nCheck your answer. What are the results given by the naive estimator?\n\n\nCode\nmean(d$y[d$t == 1]) - mean(d$y[d$t == 0])\n\n\n[1] 1.929149\n\n\nUse lm() to predict the newly created y from t. What are the coefficient values?\n\n\nCode\nlm(y ~ t, data = d) |&gt; \n  broom::tidy(conf.int = TRUE) ## 95% confidence interval\n\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     3.89     0.281     13.8  6.95e-40     3.34      4.44\n2 t               1.93     0.393      4.91 1.08e- 6     1.16      2.70\n\n\nUse lm() to predict the newly created y from t and x. What are the coefficient values?\n\n\nCode\nlm(y ~ t + x, data = d) |&gt; \n  broom::tidy(conf.int = TRUE) ## 95% confidence interval\n\n\n# A tibble: 3 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -0.0981     0.262    -0.374 7.08e-  1   -0.612     0.416\n2 t             1.99       0.301     6.62  5.87e- 11    1.40      2.58 \n3 x             4.02       0.151    26.6   1.76e-118    3.73      4.32 \n\n\nNote that in both of these cases the estimate was correctly “identified” (from a causal inference perspective) but the second answer is closer to the “truth.” Look at the standard errors, they are smaller!",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Solutions 3</span>"
    ]
  },
  {
    "objectID": "solutions04.html",
    "href": "solutions04.html",
    "title": "15  Solutions 4",
    "section": "",
    "text": "15.1 Exercise\nColliders\nFor this exercise I am going to ask you to create the following simulated dataset.\nCode\nN &lt;- 1e3\n\nd &lt;- tibble(\n  x = rnorm(N, 0, 1),\n  y = rnorm(N, 0, 1)\n)\nThe relationship between \\(x\\) and \\(y\\) should look something like this:\nCode\nd |&gt; \n  ggplot(aes(x, y)) + \n  geom_point(shape = 21, fill = \"grey90\") +\n  geom_ribbon(\n    stat = \"smooth\", method = \"lm\", color = \"black\", \n    alpha = 1/4, linetype = \"dashed\", linewidth = 1/2\n  ) +\n  geom_smooth(method = \"lm\", show.legend = FALSE, color = \"black\", linewidth = 1/2) +\n  coord_fixed(ratio = 1)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\nNow I am going to ask you to create an association between \\(x\\) and \\(y\\) via some form of collider bias.\n\\[\nx \\longrightarrow \\underbrace{\\text{z}}_{\\small {\\text{collider}}} \\longleftarrow y\n\\]\nYou are tasked to do this in four different ways.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise",
    "href": "solutions04.html#exercise",
    "title": "15  Solutions 4",
    "section": "",
    "text": "15.1.1 Panel 1\n\n\nCode\nd &lt;- d |&gt; mutate(z = x &lt;= 0 & y &lt;= 0)\nd &lt;- d |&gt; mutate(z = ifelse(as.logical(z), \"yes\", \"no\"))\n\nd |&gt; \n  filter(z == \"no\") |&gt; \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_point(\n    data = d |&gt; filter(z == \"yes\"),\n    color = \"grey90\", alpha = 1/2\n  ) +\n  geom_ribbon(\n    stat = \"smooth\", method = \"lm\", color = \"black\", \n    alpha = 1/4, linetype = \"dashed\", linewidth = 1/2\n  ) +\n  geom_smooth(method = \"lm\", show.legend = FALSE, color = \"red\", linewidth = 1/2) +\n  coord_fixed(ratio = 1) +\n  geom_abline(intercept = 0, slope = -1)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# ggsave(\"images/collider1.png\", device = \"png\", dpi = \"print\", width = 5, height = 5)\n\n\n\n\n15.1.2 Panel 2\n\n\nCode\nd &lt;- d |&gt; \n  mutate(z = x + y &lt;= 0) |&gt; \n  mutate(z = ifelse(as.logical(z), \"yes\", \"no\"))\n\nd |&gt; \n  filter(z == \"no\") |&gt; \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_point(\n    data = d |&gt; filter(z == \"yes\"),\n    color = \"grey90\", alpha = 1/2\n  ) +\n  geom_ribbon(\n    stat = \"smooth\", method = \"lm\", color = \"black\", \n    alpha = 1/4, linetype = \"dashed\", linewidth = 1/2\n  ) +\n  geom_smooth(method = \"lm\", show.legend = FALSE, color = \"red\", linewidth = 1/2) +\n  coord_fixed(ratio = 1) +\n  geom_abline(intercept = 0, slope = -1)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n# ggsave(\"images/collider2.png\", device = \"png\", dpi = \"print\", width = 5, height = 5)\n\n\n\n\n15.1.3 Panel 3\n\n\nCode\nd &lt;- d |&gt; \n  mutate(z = (x + y &gt;= -1.5) & (x + y &lt;= 1.5)) |&gt; \n  mutate(z = ifelse(as.logical(z), \"yes\", \"no\"))\n\nd |&gt; \n  filter(z == \"yes\") |&gt; \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_point(\n    data = d |&gt; filter(z == \"no\"),\n    color = \"grey90\", alpha = 1/2\n  ) +\n  geom_ribbon(\n    stat = \"smooth\", method = \"lm\", color = \"black\", \n    alpha = 1/4, linetype = \"dashed\", linewidth = 1/2\n  ) +\n  geom_smooth(method = \"lm\", show.legend = FALSE, color = \"red\", linewidth = 1/2) +\n  coord_fixed(ratio = 1) +\n  geom_abline(intercept = c(-1.5, 1.5), slope = -1)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCode\n## ggsave(\"images/collider3.png\", device = \"png\", dpi = \"print\", width = 5, height = 5)\n\n\n\n\n15.1.4 Panel 4\n\n\nCode\nd &lt;- d |&gt; \n  mutate(p = plogis(2*x + 2*y)) |&gt; \n  mutate(z = rbinom(N, 1, p)) |&gt; \n  mutate(z = ifelse(as.logical(z), \"yes\", \"no\"))\n\nd |&gt; \n  ggplot(aes(x, y, fill = z)) + \n  geom_point(alpha = 3/4, shape = 21) + \n  geom_ribbon(\n    stat = \"smooth\", method = \"lm\", color = \"black\", \n    alpha = 1/4, linetype = \"dashed\", linewidth = 1/2, \n    show.legend = FALSE\n  ) +\n  geom_smooth(method = \"lm\", show.legend = FALSE, color = \"black\", linewidth = 1/2) +\n  coord_fixed(ratio = 1) +\n  scale_fill_manual(values = c(\"grey90\", \"black\")) +\n  guides(fill = guide_legend(override.aes = list(size = 3, alpha = 1))) +\n  theme(legend.position = c(.9, .9), legend.background = element_blank())\n\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-1",
    "href": "solutions04.html#exercise-1",
    "title": "15  Solutions 4",
    "section": "15.2 Exercise",
    "text": "15.2 Exercise\nConditional average treatment effect\nThe average treatment effect across all units that have certain values of \\(X\\)—i.e., we are conditioning on \\(X\\).\nAverage treatment on the treated\nThe average treatment effect among those who actually received the treatment. The effect of taking away the treatment.\n\\[\n\\text{ATT} = \\operatorname{E} \\big[ Y^1 - Y^0 \\mid T =1 \\big] = \\operatorname{E} \\big[ Y^1  \\mid T =1 \\big] - \\underbrace{\\operatorname{E} \\big[Y^0 \\mid T =1 \\big]}_\\text{unobservable}\n\\]\nAverage treatment on the untreated\nThe average treatment effect among those who did not actually receive the treatment. The effect of adding treatment.\n\\[\n\\text{ATT} = \\operatorname{E} \\big[ Y^1 - Y^0 \\mid T = 0 \\big] = \\underbrace{\\operatorname{E} \\big[ Y^1  \\mid T = 0 \\big]}_\\text{unobservable} - \\operatorname{E} \\big[Y^0 \\mid T = 0 \\big]\n\\]",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-2",
    "href": "solutions04.html#exercise-2",
    "title": "15  Solutions 4",
    "section": "15.3 Exercise",
    "text": "15.3 Exercise\nProvide an example of a treatment effect that you would expect to be highly heterogeneous, and explain why you think it is likely to be heterogeneous.\n\nThe effect of money on happiness. The effect of earnings on happiness will vary (aka interact) across a wide range of things (e.g., neighborhood, job, and many, many others).\nThe effects of political cues on environmental behavior. We would expect that this effect is heterogeneous, as complying with these cues depends on one’s political awareness and motivation to comply.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-3",
    "href": "solutions04.html#exercise-3",
    "title": "15  Solutions 4",
    "section": "15.4 Exercise",
    "text": "15.4 Exercise\nConsider the data in the table below that shows the hypothetical treatment effect of cognitive behavioral therapy on depression for six participants. For the sake of this example, the six participants represent the population of interest.\n\n\n\nCase\nAge\nGender\nEffect\n\n\n\n\nA\n15\nMan\n7\n\n\nB\n40\nWoman\n3\n\n\nC\n30\nWoman\n7\n\n\nD\n20\nNon-binary\n8\n\n\nE\n15\nMan\n7\n\n\nF\n25\nWoman\n4\n\n\n\nWhat is the overall average treatment effect for the population?\n\n\nCode\nmean(c(7, 3, 7, 8, 7, 4))\n\n\n[1] 6\n\n\nWhat is the average treatment effect for Women?\n\n\nCode\nmean(c(3, 7, 4))\n\n\n[1] 4.666667\n\n\nIf nearly all Non-binary people get treated, and about half of all Women get treated, and we control for the differences between Women and Non-binary people, what kind of treatment effect average will we get, and what can we say about the numerical estimate we’ll get?\nNHK refers to variance-weighted ATE in the context of regression!\nIf we assume that, in the absence of treatment, everyone would have had the same outcome, and also only teenagers (19 or younger) ever receive treatment, and we compare treated people to control people, what kind of treatment effect average will we get, and what can we say about the numerical estimate we’ll get?\nWe could get a conditional ATE",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-4",
    "href": "solutions04.html#exercise-4",
    "title": "15  Solutions 4",
    "section": "15.5 Exercise",
    "text": "15.5 Exercise\nGive an example where the average treatment effect on the treated would be more useful to consider than the overall average treatment effect, and explain why.\nJob training program. Typically people who don’t need it, don’t receive it. And we would never think about giving these to people who don’t need it. So, there’s no sense in estimating the ATE—e.g., what’s the point of estimating a millionaire’s counterfactual after said job training program (it’s also probably negative).\nIf we have reason to believe that the distribution of treatment effects is heterogenous, then we might think twice before trying to estimate the ATE. For example, if job trainings help poor people but hurt rich people, why would we use the ATE and average across both groups???",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-5",
    "href": "solutions04.html#exercise-5",
    "title": "15  Solutions 4",
    "section": "15.6 Exercise",
    "text": "15.6 Exercise\nWhich of the following describes the average treatment effect of assigning treatment, whether or not treatment is actually received?\n\nLocal average treatment effect\nAverage treatment on the treated\nIntent-to-treat (this one)\nVariance-weighted average treatment effect",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-6",
    "href": "solutions04.html#exercise-6",
    "title": "15  Solutions 4",
    "section": "15.7 Exercise",
    "text": "15.7 Exercise\nSuppose you are conducting an experiment to see whether pricing cookies at $1.99 versus $2 affects the decision to purchase the cookies. The population of interest is all adults in the United States. You recruit people from your university to participate and randomize them to either see cookies priced as $1.99 or $2, then write down whether they purchased cookies. What kind of average treatment effect can you identify from this experiment?\nThis is an ATE, conditional on people attending this particular university.\nNote. NHK will sometimes speak of a CATE.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions04.html#exercise-7",
    "href": "solutions04.html#exercise-7",
    "title": "15  Solutions 4",
    "section": "15.8 Exercise",
    "text": "15.8 Exercise\nFor each of the following identification strategies, what kind of treatment effect(s) is most likely to be identified?\nA randomized experiment using a representative sample\nATE\nTrue randomization within only a certain demographic group\nCATE\nClosing back door paths connected to variation in treatment\nVariance-Weighted ATE—i.e., ATE using Linear Regression.\nIsolating the part of the variation in treatment variable that is driven by an exogenous variable\nLATE (you should have been able to figure this out from the textbook!). It stands from local average treatment effect.\nThe control group is comparable to the treatment group, but treatment effects may be different across these groups\nBoth ATU and ATT, which should allow us to estimate the ATE.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions 4</span>"
    ]
  },
  {
    "objectID": "solutions05.html",
    "href": "solutions05.html",
    "title": "16  Solutions 5",
    "section": "",
    "text": "16.1 Linear Regression\nWe will use this data.\nCode\ndols &lt;- gss2022 |&gt; \n  select(tvhours, degree, madeg, padeg) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L)) |&gt;\n  select(tvhours, college, parcol) |&gt; \n  drop_na()",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solutions 5</span>"
    ]
  },
  {
    "objectID": "solutions05.html#linear-regression",
    "href": "solutions05.html#linear-regression",
    "title": "16  Solutions 5",
    "section": "",
    "text": "16.1.1 Exercise\nAdditive link function, no interactions\n\n\nCode\nmod1 &lt;- lm(tvhours ~ college + parcol, data = dols)\n\n# ATE estimate\navg_slopes(mod1, variables = \"college\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0      -0.796     0.151     -5.27 1.35e-7    22.8    -1.09    -0.500\n\n\nAnswer (using base R):\n\n\nCode\np0 &lt;- predict(mod1, newdata = dols |&gt; mutate(college = 0))\np1 &lt;- predict(mod1, newdata = dols |&gt; mutate(college = 1))\n\nmean(p1 - p0)\n\n\n[1] -0.7957246\n\n\nATT/ATU estimate\n\n\nCode\navg_slopes(\n  model = mod1, \n  variables = \"college\",\n  by = \"college\" # separately by treatment group\n) |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   -0.796     0.151     -5.27 1.35e-7    22.8    -1.09\n2 college mean(1)…       1   -0.796     0.151     -5.27 1.35e-7    22.8    -1.09\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer (using using base R):\nNote. You should be able to know that the answer will be exactly the same because of the model being used.\n\n\nCode\ndols$p0 &lt;- predict(mod1, newdata = dols |&gt; mutate(college = 0))\ndols$p1 &lt;- predict(mod1, newdata = dols |&gt; mutate(college = 1))\n\ndols |&gt; \n  mutate(estimate = p1 - p0) |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(estimate))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0   -0.796\n2       1   -0.796\n\n\n\n\n16.1.2 Exercise\nAdditive link function, with interactions\n\n\nCode\nmod2 &lt;- lm(tvhours ~ college * parcol, data = dols)\n\n# ATE estimate\navg_slopes(mod2, variables = \"college\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0      -0.803     0.152     -5.29 1.20e-7    23.0    -1.10    -0.506\n\n\nAnswer (using matrix algebra):\n\n\nCode\nbeta &lt;- coefficients(mod2) |&gt; as.matrix(ncol = 1) ## ensures this is a column vector\n\nM0 &lt;- model.matrix(tvhours ~ college * parcol, data = dols |&gt; mutate(college = 0))\npred0 &lt;- M0 %*% beta\n\nM1 &lt;- model.matrix(tvhours ~ college * parcol, data = dols |&gt; mutate(college = 1))\npred1 &lt;- M1 %*% beta\n\nmean(pred1 - pred0)\n\n\n[1] -0.8033206\n\n\nATT/ATU estimate\n\n\nCode\navg_slopes(\n  model = mod2, \n  variables = \"college\",\n  by = \"college\" # separately by treatment group\n) |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   -0.821     0.160     -5.14 2.70e-7    21.8    -1.13\n2 college mean(1)…       1   -0.772     0.159     -4.87 1.13e-6    19.8    -1.08\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer (using previous calculations)\n\n\nCode\ndols$p1 &lt;- pred1\ndols$p0 &lt;- pred0\n\ndols |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(p1 - p0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0   -0.821\n2       1   -0.772",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solutions 5</span>"
    ]
  },
  {
    "objectID": "solutions05.html#poisson-regression",
    "href": "solutions05.html#poisson-regression",
    "title": "16  Solutions 5",
    "section": "16.2 Poisson Regression",
    "text": "16.2 Poisson Regression\nWe will use this data.\n\n\nCode\ndqp &lt;- gss2022 |&gt;\n  filter(wrkstat == 1) |&gt; # full time workers\n  select(realrinc, degree, madeg, padeg, sex, age) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L),\n         female = if_else(sex == 2, 1L, 0L),\n         realrinc = floor(realrinc)) |&gt;             # integer\n  select(realrinc, college, parcol, female, age) |&gt; \n  drop_na()\n\n\n\n16.2.1 Exercise\nUsing the log-counts, no interactions\n\n\nCode\nqp1 &lt;- glm(realrinc ~ college + (parcol + female + age + I(age^2)), \n           data = dqp,\n           family = \"quasipoisson\")\n\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0       0.599    0.0510      11.7 7.45e-32    103.    0.499\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\npred0 &lt;- predict(qp1, newdata = mutate(dqp, college = 0), type = \"link\")\npred1 &lt;- predict(qp1, newdata = mutate(dqp, college = 1), type = \"link\")\n\nmean(pred1 - pred0)\n\n\n[1] 0.5994521\n\n\nATU/ATT\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"link\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0    0.599    0.0510      11.7 7.45e-32    103.    0.499\n2 colle… mean(1)…       1    0.599    0.0510      11.7 7.45e-32    103.    0.499\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndqp$pred0 &lt;- pred0\ndqp$pred1 &lt;- pred1\n\ndqp |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0    0.599\n2       1    0.599\n\n\n\n\n16.2.2 Exercise\nNon-linear response, no interactions\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0      21237.     1831.      11.6 4.18e-31    101.   17649.\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\n## use appropriate link function for Poisson\ndqp$pred0 &lt;- exp(pred0)\ndqp$pred1 &lt;- exp(pred1)\n\ndqp |&gt; \n  summarize(ate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n     ate\n   &lt;dbl&gt;\n1 21237.\n\n\nATT/ ATU\n\n\nCode\navg_slopes(qp1,\n           variables = \"college\",\n           type = \"response\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0   20636.     1861.      11.1 1.41e-28    92.5   16988.\n2 colle… mean(1)…       1   21977.     1816.      12.1 1.05e-33   110.    18417.\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndqp |&gt; \n  group_by(college) |&gt; \n  summarize(ate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college    ate\n    &lt;int&gt;  &lt;dbl&gt;\n1       0 20636.\n2       1 21977.\n\n\n\n\n16.2.3 Exercise\nUsing the log-counts, with interactions\n\n\nCode\nqp2 &lt;- glm(realrinc ~ college * (parcol + female + age + I(age^2)), \n           data = dqp,\n           family = \"quasipoisson\")\n\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0       0.580    0.0543      10.7 1.20e-26    86.1    0.474\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndqp$pred0 &lt;- predict(qp2, newdata = mutate(dqp, college = 0), type = \"link\")\ndqp$pred1 &lt;- predict(qp2, newdata = mutate(dqp, college = 1), type = \"link\")\n\ndqp |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1    0.580\n\n\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"link\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0    0.567    0.0571      9.94 2.77e-23    74.9    0.455\n2 colle… mean(1)…       1    0.596    0.0600      9.94 2.87e-23    74.9    0.479\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\n\n\nCode\ndqp |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0    0.567\n2       1    0.596\n\n\n\n\n16.2.4 Exercise\nNon-linear response, with interactions\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term    contrast estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college 1 - 0      21190.     1817.      11.7 1.99e-31    102.   17629.\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndqp$pred0 &lt;- predict(qp2, newdata = mutate(dqp, college = 0), type = \"response\")\ndqp$pred1 &lt;- predict(qp2, newdata = mutate(dqp, college = 1), type = \"response\")\n\ndqp |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1   21190.\n\n\n\n\nCode\navg_slopes(qp2,\n           variables = \"college\",\n           type = \"response\",\n           by = \"college\") |&gt; # separately by treatment group\n  tidy()\n\n\n# A tibble: 2 × 13\n  term   contrast college estimate std.error statistic  p.value s.value conf.low\n  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 colle… mean(1)…       0   20196.     1937.      10.4 1.90e-25    82.1   16400.\n2 colle… mean(1)…       1   22411.     1963.      11.4 3.51e-30    97.8   18563.\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndqp |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0   20196.\n2       1   22411.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solutions 5</span>"
    ]
  },
  {
    "objectID": "solutions05.html#logistic-regression",
    "href": "solutions05.html#logistic-regression",
    "title": "16  Solutions 5",
    "section": "16.3 Logistic Regression",
    "text": "16.3 Logistic Regression\nWe will use this data.\n\n\nCode\ndlr &lt;- gss2022 |&gt;\n  select(abany, degree, madeg, padeg, sex, age) |&gt; \n  mutate(pardeg = pmax(madeg, padeg, na.rm = TRUE),\n         college = if_else(degree &gt;= 3, 1L, 0L),\n         parcol = if_else(pardeg &gt;= 3, 1L, 0L),\n         female = if_else(sex == 2, 1L, 0L),\n         abany = if_else(abany == 1, 1L, 0L)) |&gt;\n  select(abany, college, parcol, female, age) |&gt; \n  drop_na()\n\n\n\n16.3.1 Exercise\nUsing log-odds, no interactions\n\n\nCode\nlr1 &lt;- glm(abany ~ college + (parcol + female + age + I(age^2)),\n          data = dlr,\n          family = binomial)\n\n# ATE estimate\navg_slopes(lr1,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.438     0.146      3.00 0.00273    8.52    0.151     0.724\n\n\nAnswer:\n\n\nCode\ndlr$pred0 &lt;- predict(lr1, newdata = dlr |&gt; mutate(college = 0), type = \"link\")\ndlr$pred1 &lt;- predict(lr1, newdata = dlr |&gt; mutate(college = 1), type = \"link\")\n\ndlr |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1    0.438\n\n\nATT/ATU\n\n\nCode\navg_slopes(lr1,\n           variables = \"college\",\n           by = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.438     0.146      3.00 0.00273    8.52    0.151\n2 college mean(1)…       1    0.438     0.146      3.00 0.00273    8.52    0.151\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\n\n\nCode\ndlr |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0    0.438\n2       1    0.438\n\n\n\n\n16.3.2 Exercise\nUsing non-linear response (aka probabilities), no interactions\n\n\nCode\n# ATE estimate\navg_slopes(lr1,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.102    0.0337      3.02 0.00249    8.65   0.0359     0.168\n\n\nAnswer:\n\n\nCode\ndlr |&gt; \n  mutate(across(starts_with(\"pred\"), plogis)) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1    0.102\n\n\nATT/ATU\n\n\nCode\navg_slopes(lr1,\n           variables = \"college\",\n           by = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0   0.104     0.0341      3.04 0.00235    8.73   0.0369\n2 college mean(1)…       1   0.0989    0.0330      2.99 0.00275    8.51   0.0342\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndlr |&gt; \n  mutate(across(starts_with(\"pred\"), plogis)) |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0   0.104 \n2       1   0.0989\n\n\n\n\n16.3.3 Exercise\nUsing log-odds, with interactions\n\n\nCode\nlr2 &lt;- glm(abany ~ college * (parcol + female + age + I(age^2)),\n          data = dlr,\n          family = binomial)\n\n# ATE estimate\navg_slopes(lr2,\n           variables = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.453     0.149      3.04 0.00239    8.71    0.161     0.745\n\n\nAnswer:\n\n\nCode\ndlr$pred0 &lt;- predict(lr2, newdata = dlr |&gt; mutate(college = 0), type = \"link\")\ndlr$pred1 &lt;- predict(lr2, newdata = dlr |&gt; mutate(college = 1), type = \"link\")\n\ndlr |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1    0.453\n\n\nATT/ATU:\n\n\nCode\navg_slopes(lr2,\n           variables = \"college\",\n           by = \"college\",\n           type = \"link\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.450     0.159      2.83 0.00460    7.76    0.139\n2 college mean(1)…       1    0.458     0.161      2.85 0.00435    7.84    0.143\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndlr |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0    0.450\n2       1    0.458\n\n\n\n\n16.3.4 Exercise\nUsing non-linear response (aka probabilities), with interactions\n\n\nCode\n# ATE estimate\navg_slopes(lr2,\n           variables = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 1 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 coll… 1 - 0       0.103    0.0338      3.05 0.00228    8.78   0.0369     0.169\n\n\nAnswer:\n\n\nCode\ndlr$pred0 &lt;- predict(lr2, newdata = dlr |&gt; mutate(college = 0), type = \"response\")\ndlr$pred1 &lt;- predict(lr2, newdata = dlr |&gt; mutate(college = 1), type = \"response\")\n\ndlr |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 1 × 1\n  estimate\n     &lt;dbl&gt;\n1    0.103\n\n\nATT/ATU\n\n\nCode\navg_slopes(lr2,\n           variables = \"college\",\n           by = \"college\",\n           type = \"response\") |&gt; \n  tidy()\n\n\n# A tibble: 2 × 13\n  term    contrast college estimate std.error statistic p.value s.value conf.low\n  &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 college mean(1)…       0    0.104    0.0363      2.87 0.00407    7.94   0.0332\n2 college mean(1)…       1    0.101    0.0353      2.87 0.00415    7.91   0.0320\n# ℹ 4 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;\n\n\nAnswer:\n\n\nCode\ndlr |&gt; \n  group_by(college) |&gt; \n  summarize(estimate = mean(pred1 - pred0))\n\n\n# A tibble: 2 × 2\n  college estimate\n    &lt;int&gt;    &lt;dbl&gt;\n1       0    0.104\n2       1    0.101",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solutions 5</span>"
    ]
  },
  {
    "objectID": "solutions05.html#bootstrap-standard-errors",
    "href": "solutions05.html#bootstrap-standard-errors",
    "title": "16  Solutions 5",
    "section": "16.4 Bootstrap Standard Errors",
    "text": "16.4 Bootstrap Standard Errors\nSo far, we haven’t calculated the standard errors at all. And yet marginaleffects does this seamlessly.\nHere is a potential bootstrap implementation.\n\n\nCode\nbootstrap_ate &lt;- function(obj, treatment, type = c(\"response\", \"link\"), S = 5e3) {\n  ## Note. This code is inefficient and will only work with \"glm\" objects.  \n  type &lt;- match.arg(type)\n  data &lt;- obj$data\n  \n  ## will only work if \"treatment\" is binary (0, 1)\n  data0 &lt;- mutate(data, {{treatment}} := 0)\n  data1 &lt;- mutate(data, {{treatment}} := 1)\n  \n  out &lt;- replicate(S, {\n    i &lt;- sample(nrow(data), replace = TRUE)\n    nobj &lt;- glm(obj$formula, data = data[i, ], family = obj$family)\n    pred0 &lt;- predict(nobj, newdata = data0[i, ], type = type)\n    pred1 &lt;- predict(nobj, newdata = data1[i, ], type = type)\n    mean(pred1 - pred0)\n  })\n  \n  return(out)\n}\n\n\nLogistic Regression using link function:\n\n\nCode\navg_slopes(lr2, variables = \"college\", type = \"link\")\n\n\n\n    Term Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n college    1 - 0    0.453      0.149 3.04  0.00239 8.7 0.161  0.745\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  link \n\n\nCode\nout &lt;- bootstrap_ate(lr2, treatment = \"college\", type = \"link\")\nc(\"estimate\" = mean(out), \"std. error\" = sd(out))\n\n\n  estimate std. error \n 0.4591273  0.1523844 \n\n\nLogistic Regression using response function:\n\n\nCode\navg_slopes(lr2, variables = \"college\", type = \"response\")\n\n\n\n    Term Contrast Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n college    1 - 0    0.103     0.0338 3.05  0.00228 8.8 0.0369  0.169\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nout &lt;- bootstrap_ate(lr2, college, type = \"response\")\nc(\"estimate\" = mean(out), \"std. error\" = sd(out))\n\n\n  estimate std. error \n0.10255629 0.03285331 \n\n\nPoisson Regression using link function:\n\n\nCode\navg_slopes(qp1, variables = \"college\", type = \"link\")\n\n\n\n    Term Contrast Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n college    1 - 0    0.599      0.051 11.7   &lt;0.001 103.4 0.499  0.699\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  link \n\n\nCode\nout &lt;- bootstrap_ate(qp1, treatment = \"college\", type = \"link\")\nmean(out)\n\n\n[1] 0.6006587\n\n\nCode\nsd(out)\n\n\n[1] 0.05141052\n\n\nPoisson Regression using response function:\n\n\nCode\navg_slopes(qp2, variables = \"college\", type = \"response\")\n\n\n\n    Term Contrast Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n college    1 - 0    21190       1817 11.7   &lt;0.001 102.0 17629  24751\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nout &lt;- bootstrap_ate(qp2, treatment = \"college\", type = \"response\")\nc(\"estimate\" = mean(out), \"std. error\" = sd(out))\n\n\n  estimate std. error \n 21220.161   1901.668 \n\n\n\n16.4.1 Linear Regression\nHere is a function that designed towork with lm objects.\n\n\nCode\nbootstrap_ate_ols &lt;- function(obj, data, treatment, S = 5e3) {\n  \n  ## will only work if \"treatment\" is binary (0, 1)\n  data0 &lt;- mutate(data, {{treatment}} := 0)\n  data1 &lt;- mutate(data, {{treatment}} := 1)\n  \n  out &lt;- replicate(S, {\n    i &lt;- sample(nrow(data), replace = TRUE)\n    nobj &lt;- lm(obj$call$formula, data = data[i, ])\n    pred0 &lt;- predict(nobj, newdata = data0[i, ])\n    pred1 &lt;- predict(nobj, newdata = data1[i, ])\n    mean(pred1 - pred0)\n  })\n  \n  return(out)\n}\n\navg_slopes(mod2, variables = \"college\")\n\n\n\n    Term Contrast Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n college    1 - 0   -0.803      0.152 -5.29   &lt;0.001 23.0  -1.1 -0.506\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nout &lt;- bootstrap_ate_ols(mod2, data = dols, treatment = \"college\")\nmean(out)\n\n\n[1] -0.8038928\n\n\nCode\nsd(out)\n\n\n[1] 0.1299901\n\n\nWait a minute! Something is wrong…\nThe bootstrap standard error is much smaller than the standard error calculated by avg_slopes().\nHowever, if you ask marginaleffects to re-calculate the standard errors using a bootstrap you’ll see that the answers coincide.\n\n\nCode\navg_slopes(mod2, variables = \"college\") |&gt; \n  inferences(method = \"boot\")\n\n\n\n    Term Contrast Estimate Std. Error 2.5 % 97.5 %\n college    1 - 0   -0.803      0.127 -1.04 -0.542\n\nColumns: term, contrast, estimate, std.error, conf.low, conf.high \nType:  response \n\n\nBut there’s still something weird with just accepting this weird fact and moving on.\nWhat is happening?\nRead on if and only if you want to go down a rabbit hole.\nThe reason for this—and I will change this explanation if Steve tells me it’s incorrect—is that the results were similar enough for Logistic and Poisson regression because they have no extra parameter for the variance.\nRecall that we can write down a linear regression as follows:\n\\[\n\\begin{align}\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, && \\varepsilon \\sim \\text{Normal}(0, \\sigma)\n\\end{align}\n\\]\nThis extra \\(\\sigma\\) parameter only exists in normal linear regression.\nI think what is going on in the bootstrap is that the uncertainty about the variance isn’t “propagating” when calculating the ATE. This means that the standard error for the ATE is always going to be underestimated unless we do something about this.\nI am pretty sure the marginaleffects package estimates the standard error for the ATE in a way that takes into account this additional source of uncertainty.\nSo I modified the previous bootstrap function to incorporate some extra noise coming from \\(\\sigma\\). The results are not exactly the same, but they are closer.\n\n\nCode\nbootstrap_ate_ols2 &lt;- function(obj, data, treatment, S = 5e3) {\n  \n  data0 &lt;- mutate(data, {{treatment}} := 0)\n  data1 &lt;- mutate(data, {{treatment}} := 1)\n  \n  out &lt;- replicate(S, {\n    i &lt;- sample(nrow(data), replace = TRUE)\n    nobj &lt;- lm(obj$call$formula, data = data[i, ])\n    \n    pred0 &lt;- predict(nobj, newdata = data0[i, ])\n    pred1 &lt;- predict(nobj, newdata = data1[i, ])\n    \n    ## extra noise:\n    n &lt;- nrow(data)\n    sigma &lt;- sd(nobj$residuals)\n    mean(rnorm(n, pred1, sigma) - rnorm(n, pred0, sigma))\n    \n  })\n  \n  return(out)\n}\n\nout &lt;- bootstrap_ate_ols2(mod2, data = dols, treatment = \"college\")\nmean(out)\n\n\n[1] -0.8032193\n\n\nCode\nsd(out)\n\n\n[1] 0.1612529\n\n\nThis result is better.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solutions 5</span>"
    ]
  },
  {
    "objectID": "solutions06.html",
    "href": "solutions06.html",
    "title": "17  Solutions 6",
    "section": "",
    "text": "17.1 Exercise\nReplicate balance plot.\nCode\nd &lt;- haven::read_dta(\"data/cattaneo2.dta\")\n\nd &lt;- d |&gt;  \n  haven::zap_labels() |&gt;             \n  select(bweight, lbweight, mbsmoke, mmarried, \n         mage, medu, fbaby, alcohol, mrace, nprenatal)\n\nglimpse(d)\n\n\nRows: 4,642\nColumns: 10\n$ bweight   &lt;dbl&gt; 3459, 3260, 3572, 2948, 2410, 3147, 3799, 3629, 2835, 3880, …\n$ lbweight  &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ mbsmoke   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ mmarried  &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ mage      &lt;dbl&gt; 24, 20, 22, 26, 20, 27, 27, 24, 21, 30, 26, 20, 34, 21, 23, …\n$ medu      &lt;dbl&gt; 14, 10, 9, 12, 12, 12, 12, 12, 12, 15, 12, 12, 14, 8, 12, 12…\n$ fbaby     &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ alcohol   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ mrace     &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, …\n$ nprenatal &lt;dbl&gt; 10, 6, 10, 10, 12, 9, 16, 11, 20, 9, 14, 5, 13, 8, 4, 10, 13…\n\n\nCode\nd |&gt; \n  select(!matches(\"weight\")) |&gt; \n  pivot_longer(!mbsmoke, names_to = \"covariate\") |&gt; \n  group_by(mbsmoke, covariate) |&gt; \n  summarize(avg = mean(value), sd = sd(value)) |&gt; \n  pivot_wider(names_from = mbsmoke, values_from = c(avg, sd)) |&gt; \n  mutate(diff = (avg_1 - avg_0) / sd_1) |&gt; \n  mutate(sign = factor(sign(diff), labels = c(\"negative\", \"positive\"))) |&gt; \n  mutate(covariate = fct_reorder(covariate, abs(diff))) |&gt; \n  ggplot(aes(x = diff, y = covariate)) +\n  geom_segment(aes(xend = diff, yend = covariate), x = 0) +\n  geom_point(fill = \"white\", shape = 21) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  coord_cartesian(xlim = c(-0.6, 0.6)) +\n  labs(y = NULL, x = \"Standardized Differences in Means\", \n       title = \"Imbalance in averages of confounding covariates across treatment groups\")\n\n\n`summarise()` has grouped output by 'mbsmoke'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nCode\n# ggsave(\n#   plot = last_plot(),\n#   filename = \"images/imbalance_plot_example.png\", \n#   device = \"png\", \n#   dpi = \"print\", \n#   height = 5, \n#   width = 7\n# )",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Solutions 6</span>"
    ]
  },
  {
    "objectID": "solutions06.html#exercise-1",
    "href": "solutions06.html#exercise-1",
    "title": "17  Solutions 6",
    "section": "17.2 Exercise",
    "text": "17.2 Exercise\nThis question is copied from NHK’s exercises. To answer this question you need to read sections 14.1 and 14.2 of The Effect.\nYou want to know whether practicing cursive improves your penmanship (on a 1-10 scale). You find that, among people who don’t practice cursive, average penmanship is 5, 10 people are left-handed, 2 are ambidextrous, and 88 are right-handed. Among people who do practice cursive, 6 are left-handed with average penmanship 7, 4 are ambidextrous with average penmanship 4, and 90 are right-handed with average penmanship 6.\nYou should probably represent the data in a better format, like this:\n\n\n\n\n\n\n\n\n\nCursive (Treatment)\nNo Cursive (Control)\n\n\n\n\nLeft-handed\nAvg = 7\nN = 6\nAvg = ?\nN = 10\n\n\nRight-handed\nAvg = 6\nN = 90\nAvg = ?\nN = 88\n\n\nAmbidextrous\nAvg = 4\nN = 4\nAvg = ?\nN = 2\n\n\nTotal\nAvg = ?\nN = 100\nAvg = 5\nN = 100\n\n\n\n\n17.2.1 Part A\n\nYou want to create a set of weights that will make the treated group match the control group on handedness. Follow the process in section 14.2, paying attention to why certain numbers are going in certain positions. What weights will be given to the left, ambidextrous, and right-handed people in the control group?\n\nSince you want to make the treated group match the control group, all three weights for the control group are simply 1.\n\n\n17.2.2 Part B\n\nWhat weights will be given to the left, ambidextrous, and right-handed people in the treated group?\n\n\n\n\n\n\n\n\n\n\nCursive (Treatment)\nWeights\n\n\n\n\nLeft-handed\nAvg = 7\nN = 6\n\\[ \\frac{10}{6} \\approx 1.6667 \\]\n\n\nRight-handed\nAvg = 6\nN = 90\n\\[ \\frac{88}{90} \\approx 0.9778 \\]\n\n\nAmbidextrous\nAvg = 4\nN = 4\n\\[ \\frac{2}{4} = 0.5 \\]\n\n\nTotal\nAvg = ?\nN = 100\n\n\n\n\n\n\n17.2.3 Part C\n\nUse the weights from part b to calculate the proportion of left-handed people in the treated group, as well as the proportion of ambidextrous people and the proportion of right-handed people. If you don’t get 10%, 2%, and 88% (or very close with some rounding error), your weights are wrong, try again.\n\n\n\n\n\n\n\n\n\n\n\nCursive (Treatment)\nWeights\nProportion\n\n\n\n\nLeft-handed\nAvg = 7\nN = 6\n\\[ \\frac{10}{6} \\approx 1.6667 \\]\n\\[\n0.1\n\\]\n\n\nRight-handed\nAvg = 6\nN = 90\n\\[ \\frac{88}{90} \\approx 0.9778 \\]\n\\[\n0.88\n\\]\n\n\nAmbidextrous\nAvg = 4\nN = 4\n\\[ \\frac{2}{4} = 0.5 \\]\n\\[\n0.02\n\\]\n\n\nTotal\nAvg = ?\nN = 100\n\nProp = 1\n\n\n\nSource:\n\n\nCode\n(10/6) * (6 / 100) ## LH\n\n\n[1] 0.1\n\n\nCode\n(88/90) * (90/100) ## RH\n\n\n[1] 0.88\n\n\nCode\n(1/2) * (4/100)    ## Am\n\n\n[1] 0.02\n\n\n\n\n17.2.4 Part D\n\nWhat is the weighted average penmanship score in the treated group?\n\n\n\nCode\nw &lt;- c(\"LH\" = (10/6) * (6 / 100), \"RH\" = (88/90) * (90/100) , \"Am\" = (1/2) * (4/100))\nw\n\n\n  LH   RH   Am \n0.10 0.88 0.02 \n\n\nCode\nweighted.mean(c(7, 6, 4), w)\n\n\n[1] 6.06\n\n\n\n\n17.2.5 Part E\n\nWhat is the effect of practicing cursive that we would estimate using this data?\n\n\n\nCode\n## Non-Weighted Effect\nweighted.mean(c(7, 6, 4), c(6, 90, 4) / 100) - 5\n\n\n[1] 0.98\n\n\nCode\n## Weighted Effect\nweighted.mean(c(7, 6, 4), w) - 5\n\n\n[1] 1.06",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Solutions 6</span>"
    ]
  },
  {
    "objectID": "solutions06.html#a-lesson-in-simulation",
    "href": "solutions06.html#a-lesson-in-simulation",
    "title": "17  Solutions 6",
    "section": "17.3 A Lesson in Simulation",
    "text": "17.3 A Lesson in Simulation\nNote. I will upload a fully worked out simulation learning experience when I get the time…\nLast week I was going to have you re-do something I found in Gelman et al. (2020, p. 385) that’s supposed to build intuition about omitted variable bias and then compare it with results from simulations.\n\n\n\n\n\nIt seems simple at first, but it’s also misleading.\nSo, I changed things up a bit and added a simple toy DAG:\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align}\n&(1) &y_i &= \\beta_0 + \\beta_1 x_i + \\beta_2 w_i + \\varepsilon_i,\n&& \\varepsilon_i \\sim \\text{Normal}(0, \\sigma_y^2) \\\\\\\\\n&(2) &x_i &= \\alpha_0 + \\alpha_1 w_i + u_i, && u_i \\sim \\text{Normal}(0, \\sigma_x^2)\n\\\\\\\\ &&&&&w_i \\sim \\text{Normal}(0, \\sigma_w^2)\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nI expressed Equation (2) so that it would make sense to generate data from a simulation.\n\n\nCode\nfork_simulation &lt;- function(N = 1e5, a0 = 1, a1 = 1, b0 = 1, b1 = 1, b2 = 1) {\n  \n  tibble(\n    w = rnorm(N, 0, 20),\n    x = a0 + a1*w + rnorm(N, 0, 2),\n    y = b0 + b1*x + b2*w + rnorm(N, 0, 2)\n  )\n  \n}\n\n\n\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Solutions 6</span>"
    ]
  },
  {
    "objectID": "solutions07.html",
    "href": "solutions07.html",
    "title": "18  Solutions 7",
    "section": "",
    "text": "18.1 Instructions\nData\nCode\nload(\"data/exercise_data.Rdata\")\nFormulas\nCode\ncat_vars &lt;- c(\"black\", \"hisp\", \"married\", \"nodegr\", \"u74\", \"u75\")\nnum_vars &lt;- c(\"age\", \"educ\", \"re74\", \"re75\")\n\n# treatment equation (binary preds only)\nf_cat_only &lt;- reformulate(\n  termlabels = cat_vars, \n  response = \"treat\"\n)\n\nf_cat_only\n\n\ntreat ~ black + hisp + married + nodegr + u74 + u75\n\n\nCode\n# treatment equation (linear specification)\nf_linear &lt;- reformulate(\n  termlabels = c(num_vars, cat_vars), \n  response = \"treat\"\n)\n\nf_linear\n\n\ntreat ~ age + educ + re74 + re75 + black + hisp + married + nodegr + \n    u74 + u75\n\n\nCode\n# treatment equation (quadratics for numeric variables)\nf_quadratic &lt;- reformulate(\n  termlabels = c(cat_vars, num_vars, str_glue(\"I({num_vars}^2)\")),\n  response = \"treat\"\n)\n\nf_quadratic\n\n\ntreat ~ black + hisp + married + nodegr + u74 + u75 + age + educ + \n    re74 + re75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise",
    "href": "solutions07.html#exercise",
    "title": "18  Solutions 7",
    "section": "18.2 Exercise",
    "text": "18.2 Exercise\nUse the experimental data to estimate the effect of the job training treatment. How much does it appear to affect 1978 income? Now look at the observational data (for all exercises from now on). How large is the raw difference in 1978 income between the treatment group and the PSID comparison group?\n\nSince the first part of this question is about the experimental data, we’ll use d_exper (the only time we’ll use it). This will be our “target” interval for the rest of the exercises.\n\n\n\nCode\nnaive_exper &lt;- lm(re78 ~ treat, data = d_exper)\nnaive_obser &lt;- lm(re78 ~ treat, data = d)\n\nmsummary(\n  models = list(\"Experimental\" = naive_exper, \"Observational\" = naive_obser), \n  coef_map = \"treat\",\n  gof_map = c(\"nobs\", \"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Experimental\n      Observational\n    \n  \n  \n    treat\n0.886\n-16.541\n    \n(0.472)\n(0.928)\n    Num.Obs.\n722\n2510\n    RMSE\n6.23\n15.01\n  \n  \n  \n\n\n\n\nAccording to the experimental estimate, people who participated in the job training program earned (on average) 886 dollars more than people who didn’t (with a standard error of 472 dollars).\nAccording to the naive estimate on observational data, people who participated in the job training program earned (on average) 16,541 less dollars (with a standard error of 928 dollars).\n\nIf we took this seriously, we’d think the training program reduced income by over $16,000! This is because there are a lot of differences between the treated and non-treated cases other than treatment assignment in the observational data.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise-1",
    "href": "solutions07.html#exercise-1",
    "title": "18  Solutions 7",
    "section": "18.3 Exercise",
    "text": "18.3 Exercise\nTry to estimate the effect of the treatment using regression. What does regression say the effect of the program is?\n\n\nCode\nregression_formula &lt;- reformulate(\n  termlabels = c(\"treat\", cat_vars, num_vars, str_glue(\"I({num_vars}^2)\")), \n  response = \"re78\"\n)\n\nregression_formula\n\n\nre78 ~ treat + black + hisp + married + nodegr + u74 + u75 + \n    age + educ + re74 + re75 + I(age^2) + I(educ^2) + I(re74^2) + \n    I(re75^2)\n\n\nCode\nreg_mod &lt;- lm(regression_formula, data = d)\n\nmsummary(\n  models = list(Regression = reg_mod, \"Experimental\" = naive_exper), \n  estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n  coef_map = \"treat\",\n  gof_map = c(\"nobs\", \"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Regression\n      Experimental\n    \n  \n  \n    treat\n-1.949 [-3.665, -0.234]\n0.886 [-0.041, 1.813]\n    \n(0.875)\n(0.472)\n    Num.Obs.\n2510\n722\n    RMSE\n10.08\n6.23\n  \n  \n  \n\n\n\n\n\nUndoubtedly we could do somewhat better than this specification. The model estimates that the treatment reduces income between $230 and $3,660. This is not very close to the estimate from the experiment!\n\nNote. Take a look at how I added the 95% confidence intervals in the msummary function. This might come in handy in the future.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise-2",
    "href": "solutions07.html#exercise-2",
    "title": "18  Solutions 7",
    "section": "18.4 Exercise",
    "text": "18.4 Exercise\nBegin by exact matching on all the dummy variables. How many treated cases cannot be matched? What is the (FS)ATT estimate?\n\nExact matching is pretty easy to understand so we start with that. Let’s match on the binary variables and see what we get.\n\nBefore that, however, notice that the six binary variables produce are 64 possible groupings, some of will be empty for both treated and untreated groups (e.g.,, the “missing” observations for which both black and hisp are set to 1).\n\n\nCode\n2^6\n\n\n[1] 64\n\n\nExact matching will drop observations for which there isn’t at least one comparison available\n\n\nCode\ngroupings &lt;- d |&gt; \n  count(across(all_of(c(cat_vars, \"treat\")))) |&gt; \n  pivot_wider(values_from = n, names_from = treat, names_prefix = \"treat\") |&gt; \n  relocate(treat0, treat1)\n\ngroupings |&gt; \n  filter(is.na(treat0) | is.na(treat1)) |&gt; \n  print(n = Inf)\n\n\n# A tibble: 16 × 8\n   treat0 treat1 black  hisp married nodegr   u74   u75\n    &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      8     NA     0     0       0      0     0     1\n 2     NA      2     0     0       0      1     1     0\n 3     27     NA     0     0       1      0     0     1\n 4     22     NA     0     0       1      0     1     0\n 5     14     NA     0     0       1      1     0     1\n 6     35     NA     0     0       1      1     1     1\n 7      1     NA     0     1       0      0     1     0\n 8     NA      1     0     1       0      1     1     0\n 9      2     NA     0     1       1      0     0     1\n10      1     NA     0     1       1      0     1     1\n11      2     NA     0     1       1      1     0     1\n12      2     NA     1     0       0      0     0     1\n13     NA      2     1     0       0      0     1     0\n14      5     NA     1     0       1      0     0     1\n15      2     NA     1     0       1      0     1     0\n16     NA      5     1     0       1      1     1     0\n\n\nIn this particular case, exact matching will make us lose 10 observations from the treated group and 121 observations from the untreated group.\n\n\nCode\ngroupings |&gt; \n  filter(is.na(treat0) | is.na(treat1)) |&gt; \n  summarize(across(c(treat0, treat1), \\(x) sum(x, na.rm = TRUE)))\n\n\n# A tibble: 1 × 2\n  treat0 treat1\n   &lt;int&gt;  &lt;int&gt;\n1    121     10\n\n\nThus, given that we lose 10 of our treatment cases, we are going to be estimating a feasible ATT on this sample (FSATT).\n\n\nCode\nexact_out &lt;- matchit(f_cat_only, data = d, estimand = \"ATT\", method = \"exact\")\nexact_out\n\n\nA matchit object\n - method: Exact matching\n - number of obs.: 2510 (original), 2379 (matched)\n - target estimand: ATT\n - covariates: black, hisp, married, nodegr, u74, u75\n\n\nNote. exact_out$weights gives dropped observations a “weight” of zero; all the other observations get a weight of one.\n\n\nCode\nexact_mod &lt;- lm(re78 ~ treat, data = d, weights = exact_out$weights) \n\nmsummary(\n  models = list(\"Exact Matching\" = exact_mod, \"Experimental\" = naive_exper), \n  coef_map = \"treat\",\n  gof_map = c(\"nobs\", \"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Exact Matching\n      Experimental\n    \n  \n  \n    treat\n-2.386\n0.886\n    \n(0.667)\n(0.472)\n    Num.Obs.\n2379\n722\n    RMSE\n20.13\n6.23\n  \n  \n  \n\n\n\n\nNote. Exact matching can’t “match” on continuous covariates, and this is the reason why our estimate is so far away from the experimental estimate.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise-3",
    "href": "solutions07.html#exercise-3",
    "title": "18  Solutions 7",
    "section": "18.5 Exercise",
    "text": "18.5 Exercise\nUse the observational data to estimate each case’s propensity to receive treatment using glm(). Use a logistic regression with quadratic terms for age, education, 1974 income, and 1975 income. Spend a few moments thinking about what this model says. Look at the density plots of the p-score for treated and untreated groups.\n\n\nCode\nprob_mod &lt;- glm(f_quadratic, data = d, family = \"binomial\")\nd$p &lt;- predict(prob_mod, type = \"response\")\n\n\nNote. weightit() can estimate p-scores for us, but we are not going to do this here.\nDensity Plots:\n\n\nCode\nd |&gt; \n  mutate(treat = as.factor(treat)) |&gt; \n  ggplot(aes(p, fill = treat, color = treat)) +\n  geom_density(aes(p, after_stat(scaled)), alpha = 1/4)  # set max density of each group to 1 with after_stat\n\n\n\n\n\n\n\n\n\nCode\nd |&gt; \n  mutate(treat = as.factor(treat)) |&gt; \n  mutate(log_odds = log(p / (1 - p))) |&gt; \n  ggplot(aes(log_odds, fill = treat, color = treat)) +\n  geom_density(aes(log_odds, after_stat(scaled)), alpha = 1/4) \n\n\n\n\n\n\n\n\n\nThis second graph is easier to read. It shows how different the treatment and control groups are in their pre-treatment characteristics (balance). However, it is worth noting that there’s not a clear lack of common support; the range of both groups is pretty extensive.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise-4",
    "href": "solutions07.html#exercise-4",
    "title": "18  Solutions 7",
    "section": "18.6 Exercise",
    "text": "18.6 Exercise\nEstimate propensity scores and ATT weights using weightit(). Ignore the warning you get. We’ll discuss that more in class. Estimate the ATT. Check for covariate balance.\n\n\nCode\nps_out &lt;- weightit(f_quadratic, data = d, method = \"glm\", estimand = \"ATT\")\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nsummary(ps_out)\n\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                   Max\ntreated   1 ||                             1.0000\ncontrol   0 |---------------------------| 83.9742\n\n- Units with the 5 most extreme weights by group:\n                                                \n            2218    2217    2216    2215    2214\n treated       1       1       1       1       1\n            1485    1484    1478      56    1521\n control 22.7435 22.7435 27.3148 48.3254 83.9742\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       0.000 0.000  -0.000       0\ncontrol      12.211 1.732   3.841       0\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted 2213.       297\nWeighted     14.75     297\n\n\nCode\nps_mod &lt;- lm(re78 ~ treat, data = d, weights = ps_out$weights)\n\nmsummary(\n  models = list(\"Propensity Score Weighting\" = ps_mod, \"Experimental\" = naive_exper), \n  coef_map = \"treat\",\n  gof_map = c(\"nobs\", \"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Propensity Score Weighting\n      Experimental\n    \n  \n  \n    treat\n1.139\n0.886\n    \n(0.268)\n(0.472)\n    Num.Obs.\n2510\n722\n    RMSE\n22.38\n6.23\n  \n  \n  \n\n\n\n\nThis estimate looks much better. It may be a little more positive than the experimental estimate, but it overlaps a good deal with it.\nRemember that the standard errors are underestimated, so we might have to bootstrap the results if we want a reasonable confidence interval.\nNow let’s check for covariate balance.\nNote. You should check for covariate balance BEFORE estimating the ATT.\n\n\nCode\nbal.plot(\n  ps_out,\n  which = \"both\", \n  var.name = \"prop.score\", \n  type = \"density\"\n)\n\n\n\n\n\n\n\n\n\nThe balance looks OK-ish for the propensity scores.\nNow let’s check for the covariates.\n\n\nCode\nlove_plot(ps_out)\n\n\n\n\n\n\n\n\n\nIt’s not that great when we use K-S distance to compare the distributions, isn’t? If this was the early 2000s, we could go ahead and publish the ATT estimated earlier. But we live in the future now…",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#exercise-5",
    "href": "solutions07.html#exercise-5",
    "title": "18  Solutions 7",
    "section": "18.7 Exercise",
    "text": "18.7 Exercise\nNow do the same as above using “entropy balancing.” Confirm that you’ve achieved balance on the means and the variances of the covariates. Then estimate the ATT.\n\n\nCode\nebal_out &lt;- weightit(\n  formula = f_linear, \n  data = d,\n  method = \"ebal\",\n  moments = 3,\n  estimand = \"ATT\",\n  maxit = 1e5\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nsummary(ebal_out)\n\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                    Max\ntreated   1 ||                              1.0000\ncontrol   0 |---------------------------| 226.0306\n\n- Units with the 5 most extreme weights by group:\n                                                  \n            2218    2217    2216     2215     2214\n treated       1       1       1        1        1\n            1485    1484      56     1540     1521\n control 90.1288 90.1288 91.7369 122.8223 226.0306\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       0.000 0.000   0.000       0\ncontrol       7.999 1.725   3.309     147\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted 2213.       297\nWeighted     34.07     297\n\n\nCode\nlove_plot(ebal_out)\n\n\n\n\n\n\n\n\n\nCode\nebal_mod &lt;- lm(re78 ~ treat, data = d, weights = ebal_out$weights)\n\nmsummary(\n  models = list(\"Entropy Balancing\" = ebal_mod, \"Experimental\" = naive_exper), \n  coef_map = \"treat\",\n  gof_map = c(\"nobs\", \"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Entropy Balancing\n      Experimental\n    \n  \n  \n    treat\n0.568\n0.886\n    \n(0.465)\n(0.472)\n    Num.Obs.\n2510\n722\n    RMSE\n21.99\n6.23",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions07.html#bonus",
    "href": "solutions07.html#bonus",
    "title": "18  Solutions 7",
    "section": "18.8 Bonus",
    "text": "18.8 Bonus\n\n\nCode\n## this package will allow you to use the replicate function in \"parallel\"\n## this will make things run much faster, depending on the number of \"cores\" \n## in your computer.\n\nlibrary(future.apply)\nplan(multisession, workers = parallel::detectCores() - 1L)\n\nget_att &lt;- function() {\n  \n  i &lt;- sample(nrow(d), replace = TRUE)\n  ps_out &lt;- weightit(f_quadratic, data = d[i, ], method = \"glm\", estimand = \"ATT\")\n  ps_mod &lt;- lm(re78 ~ treat, data = d[i, ], weights = ps_out$weights)\n  out &lt;- coefficients(ps_mod)\n  \n  return(out[[\"treat\"]])\n  \n}\n\nboot &lt;- future_replicate(1e4, suppressWarnings(get_att()))\n\n## previous standard error\ntidy(ps_mod) |&gt; \n  filter(term == \"treat\")\n\n\n# A tibble: 1 × 5\n  term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 treat     1.14     0.268      4.25 0.0000223\n\n\nCode\n## new standard error\nsd(boot)\n\n\n[1] 0.9432545",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Solutions 7</span>"
    ]
  },
  {
    "objectID": "solutions08.html",
    "href": "solutions08.html",
    "title": "19  Solutions 8",
    "section": "",
    "text": "19.1 Data\nThe outcome variable will be ppvtr.36 (which simply means “test score at age 3”).\nDictionary\nCode\ndict_url &lt;- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Childcare/data/datadict.txt\"\n\nread_file(dict_url) |&gt; \n  writeLines()\n\n\nData Dictionary for Child Care example\n\nThe IHDP intervention was implemented in the 1980’s and targeted low\nbirth weight (less than 2500 grams), pre-term children.  They were\nrecruited at the time of birth.  It provided high quality child care\nand other services in their first 3 years of life.  The comparison\ngroup was pulled from a survey conducted during the same time period\ncalled the National Survey of Longitudinal Youth.  At the time of the\nintervention many of the original survey participants (first recruited\nin 1979) had children. We have data from those children and their\nmothers for an overlapping set of variables (below) as the IHDP\nchildren.\n\nThe intervention for low-birth-weight children is described by\n- Brooks-Gunn, J., Liaw, F. R., and Klebanov, P. K. (1992). Effects of\n  early intervention on cognitive function of low birth weight preterm\n  infants. Journal of Pediatrics 120, 350–359.\n- Hill, J. L., Brooks-Gunn, J., and Waldfogel, J. (2003). Sustained\n  effects of high participation in an early intervention for\n  low-birth-weight premature infants. Developmental Psychology 39,\n  730–744.\n\nData columns\n\n\"momage\"   \nmom age at time of birth\n\n\"b.marr\"   \nindicator for whether mom was married at birth\n\n\"momed\"    \nmother’s education level at the time she gave birth\n\n\"work.dur\" \nindicator for whether mom worked in the year before she gave birth\n\n\"prenatal\" \nindicator for whether mom received prenatal care\n\n\"cig\"     \n indicator for whether mom smoked cigarettes while pregnant\n\n\"booze\"    \nindicator for whether mom drank alcohol while pregnant\n\n\"sex\"      \nindicator for whether child was born male or female\n\n\"first\"    \nindicator for whether child was the first born for the mother\n\n\"bw\"       \nchild’s birth weight\n\n\"bwg\"      \nindicator for whether child was born low birth weight\n\n\"preterm\" \nnumber of weeks preterm child was born\n\n\"black\", \"hispanic\", \"white\"    \nindicators for child’s race/ethnicity\n\n\"lths\", \"hs\", \"ltcoll\", \"college\"  \nindicators for mother’s education at time of birth\n\n\"dayskidh\" \nnumber of days child was in the hospital after being born\n\n\"st5\", \"st9\", \"st12\", \"st25\", \"st36\", \"st42\", \"st48\", \"st53\"    \nindicator for state where household resides \n\n\"st99\"  \nindicator for whether family  was living in state served by the ihdp\n\n\"income\"   \nfamily income one year after the child was born\n\n\"treat\"   \nindicator for whether family was allowed to receive IHDP services (1 = yes) \n\n\"ppvtr.36\"\nIQ measured at age 36 months\nLoading the data\nCode\nvar_names &lt;- c(\"momage\", \"b.marr\", \"momed\", \"work.dur\", \"prenatal\", \"cig\", \"booze\", \"sex\", \"first\", \"bw\", \"bwg\", \"preterm\", \"black\", \"hispanic\", \"white\", \"lths\", \"hs\", \"ltcoll\", \"college\", \"dayskidh\", \"st5\", \"st9\", \"st12\", \"st25\", \"st36\", \"st42\", \"st48\", \"st53\", \"st99\", \"income\", \"treat\", \"ppvtr.36\")\n\nurl &lt;- \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/Childcare/data/cc2.csv\"\n\nd &lt;- read_csv(url) |&gt; \n  select(all_of(var_names)) |&gt; \n  mutate(across(matches(\"st\\\\d{2}\"), as.integer))",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Solutions 8</span>"
    ]
  },
  {
    "objectID": "solutions08.html#exercise",
    "href": "solutions08.html#exercise",
    "title": "19  Solutions 8",
    "section": "19.2 Exercise",
    "text": "19.2 Exercise\nGelman et al. (2020) say: We excluded the most severely low-birth-weight children (those at or below 1500 grams) from the sample because they are so different from the comparison sample.\nWhy did they decide to exclude these children? What problem could we encounter by not omitting them?\nWould you have excluded them from the dataset? Why?\nThis question is hard because I am asking you to imagine what lies to the left of the following plot and to then get inside the author’s heads.\n\n\nCode\nd |&gt; \n  mutate(treat = as.factor(treat) |&gt; fct_rev()) |&gt; \n  ggplot(aes(bw, ppvtr.36, color = treat)) +\n  geom_point(size = 2/3) +\n  geom_vline(xintercept = 1500, linetype = \"dashed\") +\n  scale_color_grey() + \n  xlim(0, max(d$bw)) + \n  labs(x = \"birth weight\", y = \"test score at age 3\") + \n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n\nThe authors decided to exclude these children because they believed they wouldn’t be able to get a credible ATT otherwise. There are some justifications for this decision. For example, it might simply be a case of lack of balance and common support. Lack of balance is a problem that we can solve with weighting, and I think it’s very improbable that there’s a lack of common support. This would mean that they are unnecessarily throwing away information based on what seems to be an arbitrary cut-off point.\nHowever, it might be the case that such extremely low birth-weights are due to confounding circumstances for which there’s no good measurement available (e.g., a genetic disease). If this is the case, then throwing away the observations is probably the right call! Still, the strict weight cutoff should be justified on scientific grounds.\nThe authors would have to provide a more convincing justification.\nNote. The lack of common support in this plot was part of the policy design.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Solutions 8</span>"
    ]
  },
  {
    "objectID": "solutions08.html#exercise-1",
    "href": "solutions08.html#exercise-1",
    "title": "19  Solutions 8",
    "section": "19.3 Exercise",
    "text": "19.3 Exercise\nLooking at the variables, there is at least one variable for which it would be futile to try and achieve balance: st99 is an indicator for whether the family was living in state served by the IHDP. There shouldn’t be any families receiving treatment outside those states.\n\n\nCode\nd |&gt; \n  count(treat, st99) |&gt; \n  complete(treat, st99)\n\n\n# A tibble: 4 × 3\n  treat  st99     n\n  &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1     0     0  1173\n2     0     1  2918\n3     1     0   290\n4     1     1    NA\n\n\nAlso note that this variable is coded weirdly, 1 indicates that there’s no IHDP presence! Other variables like bwg are also coded the opposite of what you would expect.\nI am also skeptical that we can learn much from the other geographical variables. Including them would basically mean that we believe that geography is a confounder beyond what the other variables might tell us. I am sure you can come up with reasons for which this might be true, but I am skeptical. Furthermore, there are a lot of them and this will cause problems for achieving covariate balance.\nThis is how treatment is distributed across states.\n\n\nCode\nd |&gt; \n  group_by(treat) |&gt; \n  summarize(across(starts_with(\"st\"), sum))\n\n\n# A tibble: 2 × 10\n  treat   st5   st9  st12  st25  st36  st42  st48  st53  st99\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     0    48    85   191    62   225   148   354    60  2918\n2     1    40    39    29    33    34    42    33    40     0\n\n\nI also see no reason to use bwg when we already have a more informative bw variable.\nFinally, it seems to me that momed and lths, hs, ltcoll, college contain the same information.\n\n\nCode\nd |&gt; count(momed, lths, hs, ltcoll, college)\n\n\n# A tibble: 4 × 6\n  momed  lths    hs ltcoll college     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n1     1     1     0      0       0  1358\n2     2     0     1      0       0  1820\n3     3     0     0      1       0   837\n4     4     0     0      0       1   366\n\n\nYup, we must exclude momed too!\nI will also exclude sex with the hopes that this is not relevant for the test scores of a 3 year old.\nNote. I noticed this earlier, but I decided it was better to try and achieve balance on log(income) instead of income. There are some observations in the untreated group that have zero income, so I will delete these.\n\n\nCode\nd &lt;- d |&gt; \n  filter(income &gt; 0)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Solutions 8</span>"
    ]
  },
  {
    "objectID": "solutions08.html#exercise-2",
    "href": "solutions08.html#exercise-2",
    "title": "19  Solutions 8",
    "section": "19.4 Exercise",
    "text": "19.4 Exercise\nThe first thing I did was to identify which variables were categorical and which were continuous. You can figure this out any number of ways, but I usually use skimr::skim(d).\nI then used these to build formulas like we did in class.\n\n\nCode\nnum_vars &lt;- c(\"dayskidh\", \"income\", \"preterm\", \"momage\", \"bw\")\nst_vars &lt;- c(\"st5\", \"st9\", \"st12\", \"st25\", \"st36\", \"st42\", \"st48\", \"st53\")\nbin_vars &lt;- c(\"b.marr\", \"prenatal\", \"cig\", \"booze\", \"first\", \n              \"black\", \"hispanic\", \"white\", \"lths\", \"hs\", \"ltcoll\", \"college\")\n\nf_linear &lt;- reformulate(\n  response = \"treat\",\n  termlabels = c(num_vars, st_vars, bin_vars)\n)\n\nf_quadratic &lt;- reformulate(\n  response = \"treat\",\n  termlabels = c(num_vars, st_vars, bin_vars, \"I(momage^2)\", \"I(prenatal^2)\")\n)\n\n\nFrom here on there is a lot of trial-and-error. I’ve included a bunch of stuff that normally wouldn’t go here, but I just want you see for yourselves\n\n19.4.1 First try, with st variables\n\n\nCode\npsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"glm\", \n  estimand = \"ATT\"\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nsummary(psw)\n\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                  Max\ntreated   1  ||                            1.000\ncontrol   0 |---------------------------| 31.302\n\n- Units with the 5 most extreme weights by group:\n                                            \n             6       5       4      3      2\n treated     1       1       1      1      1\n          3490    1074    2659   1363   2454\n control 9.208 14.8333 20.5699 26.957 31.302\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       0.000 0.000  -0.000       0\ncontrol      20.916 1.943   5.533    2809\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted 3864.       276\nWeighted      8.81     276\n\n\nFurthermore, it’s all very much out of balance.\n\n\nCode\nlove_plot(psw)\n\n\nWarning: Large mean differences detected; you may not be using standardized\nmean differences for continuous variables.\n\n\n\n\n\n\n\n\n\nI will try CBPS now.\n\n\nCode\ncbpsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"CBPS\", \n  estimand = \"ATT\"\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nlove_plot(cbpsw)\n\n\n\n\n\n\n\n\n\nWell, that didn’t work either…\nI’ll try the non over identified version of CBPS.\n\n\nCode\ncbpsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"CBPS\", \n  estimand = \"ATT\",\n  over = FALSE\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nlove_plot(cbpsw)\n\n\nWarning: Large mean differences detected; you may not be using standardized\nmean differences for continuous variables.\n\n\n\n\n\n\n\n\n\nStill no good…\nI will give entropy balancing one chance, but I highly doubt it will work.\n\n\nCode\nebalw &lt;- weightit(\n  formula = f_linear, \n  data = d, \n  method = \"ebal\", \n  estimand = \"ATT\",\n  moments = 3\n)\n\n\nWarning: The estimated weights do not balance the covariates, indicating the\noptimization arrived at a degenerate solution. Try decreasing the number of\nvariables supplied to the optimization.\n\n\nWarning: All weights are `NA` or 0 in treatment group \"0\".\n\n\nCode\nsummary(ebalw)\n\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                 Max\ntreated   1                              ||   1\ncontrol   0   ||                              0\n\n- Units with the 5 most extreme weights by group:\n                             \n           5   4   3   2    1\n treated   1   1   1   1    1\n         280 279 278 277 2106\n control   0   0   0   0    0\n\n- Weight statistics:\n\n        Coef of Var MAD Entropy # Zeros\ntreated           0   0       0       0\ncontrol                       0    3864\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted    3864     276\nWeighted               276\n\n\nHahaha, zero people in the (effective) control group.\nY’all, I think it’s time to rebuild the formulas and exclude the st* variables.\n\n\n19.4.2 Second try\n\n\nCode\nnum_vars &lt;- c(\"dayskidh\", \"income\", \"preterm\", \"momage\", \"bw\")\nbin_vars &lt;- c(\"b.marr\", \"work.dur\", \"prenatal\", \"cig\", \"booze\", \"first\", \n              \"black\", \"hispanic\", \"white\", \"lths\", \"hs\", \"ltcoll\", \"college\")\n\nf_linear &lt;- reformulate(\n  response = \"treat\",\n  termlabels = c(num_vars, bin_vars)\n)\n\nf_quadratic &lt;- reformulate(\n  response = \"treat\",\n  termlabels = c(num_vars, bin_vars, \"I(momage^2)\")\n)\n\npsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"glm\", \n  estimand = \"ATT\"\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nlove_plot(psw)\n\n\n\n\n\n\n\n\n\nCode\ncbpsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"CBPS\", \n  estimand = \"ATT\",\n  over = TRUE\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nlove_plot(cbpsw)\n\n\n\n\n\n\n\n\n\nCode\ncbpsw &lt;- weightit(\n  formula = f_quadratic, \n  data = d, \n  method = \"CBPS\", \n  estimand = \"ATT\",\n  over = FALSE\n)\n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nlove_plot(cbpsw)\n\n\n\n\n\n\n\n\n\nCode\nebalw &lt;- weightit(\n  formula = f_linear, \n  data = d, \n  method = \"ebal\", \n  estimand = \"ATT\",\n  moments = 2\n)\n\n\nWarning: The estimated weights do not balance the covariates, indicating the\noptimization arrived at a degenerate solution. Try decreasing the number of\nvariables supplied to the optimization.\n\n\nWarning: All weights are `NA` or 0 in treatment group \"0\".\n\n\nCode\nlove_plot(ebalw)\n\n\nError in `cobalt::love.plot()`:\n! All weights are zero when treat is \"0\".\n\n\nOk, so this didn’t work either.\n\n\n19.4.3 Last try\nAfter some further trial and error, I realized that there are three variables particularly hard to balance: cig and booze.\nHere I drop these variables and hope for the best. I also dropped education variables except for college and modified momage.\n\n\nCode\nebalw &lt;- weightit(\n  formula = treat ~ log(income) + first + black + hispanic + white + college + \n    bw + b.marr + work.dur + prenatal + I(momage &lt; 20) + dayskidh + preterm,\n  data = d,\n  method = \"ebal\", \n  estimand = \"ATT\",\n  moments = 3,\n  maxit = 1e6\n) \n\n\nWarning: Some extreme weights were generated. Examine them with `summary()` and\nmaybe trim them with `trim()`.\n\n\nCode\nsummary(ebalw)\n\n\n                 Summary of weights\n\n- Weight ranges:\n\n        Min                                    Max\ntreated   1 ||                              1.0000\ncontrol   0 |---------------------------| 229.3099\n\n- Units with the 5 most extreme weights by group:\n                                                   \n               5       4        3        2        1\n treated       1       1        1        1        1\n            2321    2521     1070      770     2632\n control 93.5336 98.7423 157.2057 163.6732 229.3099\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       0.000 0.000   0.000       0\ncontrol       7.955 1.875   3.638    2774\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted 3864.       276\nWeighted     60.13     276\n\n\nCode\nlove_plot(ebalw)\n\n\n\n\n\n\n\n\n\nThese following results are very shaky. I tried closing the backdoor paths on cig and booze using regression (which is not something you were supposed to do). This means that we are using regression to extrapolate over areas where there’s little overlap and/or common support.\n\n\nCode\nfit_e &lt;- lm(ppvtr.36 ~ treat, data = d, weights = ebalw$weights)\nfit_r &lt;- lm(\n  formula = ppvtr.36 ~ treat + dayskidh + income + preterm + momage + bw + b.marr + \n    work.dur + prenatal + cig + booze + first + black + hispanic + \n    white + lths + hs + ltcoll + college + I(momage^2), \n  data = d\n)\n\nfit_double &lt;- lm(\n  formula = ppvtr.36 ~ treat + dayskidh + income + preterm + momage + bw + b.marr + \n    work.dur + prenatal + cig + booze + first + black + hispanic + \n    white + lths + hs + ltcoll + college + I(momage^2), \n  data = d, \n  weights = ebalw$weights\n)\n\nmsummary(\n  models = list(\"Regression\" = fit_r, \"Entropy\" = fit_e, \"Double R.\" = fit_double), \n  coef_map = \"treat\",\n  gof_map = c(\"rmse\")\n)\n\n\n\n\n\n  \n    \n       \n      Regression\n      Entropy\n      Double R.\n    \n  \n  \n    treat\n10.638\n8.226\n2.785\n    \n(1.397)\n(1.357)\n(1.250)\n    RMSE\n16.38\n20.17\n28.48\n  \n  \n  \n\n\n\n\nFrustrating, I know.\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Solutions 8</span>"
    ]
  },
  {
    "objectID": "solutions09.html",
    "href": "solutions09.html",
    "title": "20  Solutions 9",
    "section": "",
    "text": "Graded on an individual basis.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Solutions 9</span>"
    ]
  },
  {
    "objectID": "solutions10.html",
    "href": "solutions10.html",
    "title": "21  Solutions 10",
    "section": "",
    "text": "21.1 Exercise\nThe gapminder dataset is as good as any to practice moving from wide to long format.\nI’m going to show you how to do this with tidyverse and with panelr, the later of which is much more intuitive.\nNote. The gapminder dataset already comes in long format.\ntidyverse\nCode\n## from long to wide\n\nglimpse(gapminder)\n\n\nRows: 1,704\nColumns: 6\n$ country   &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …\n$ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…\n$ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…\n$ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …\n\n\nCode\ngap_wide &lt;- gapminder::gapminder |&gt; \n  pivot_wider(\n    names_from = year, \n    values_from = c(lifeExp, gdpPercap, pop), \n    names_sep = \"\"\n  ) \n\nglimpse(gap_wide)\n\n\nRows: 142\nColumns: 38\n$ country       &lt;fct&gt; \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentin…\n$ continent     &lt;fct&gt; Asia, Europe, Africa, Africa, Americas, Oceania, Europe,…\n$ lifeExp1952   &lt;dbl&gt; 28.801, 55.230, 43.077, 30.015, 62.485, 69.120, 66.800, …\n$ lifeExp1957   &lt;dbl&gt; 30.33200, 59.28000, 45.68500, 31.99900, 64.39900, 70.330…\n$ lifeExp1962   &lt;dbl&gt; 31.99700, 64.82000, 48.30300, 34.00000, 65.14200, 70.930…\n$ lifeExp1967   &lt;dbl&gt; 34.02000, 66.22000, 51.40700, 35.98500, 65.63400, 71.100…\n$ lifeExp1972   &lt;dbl&gt; 36.08800, 67.69000, 54.51800, 37.92800, 67.06500, 71.930…\n$ lifeExp1977   &lt;dbl&gt; 38.43800, 68.93000, 58.01400, 39.48300, 68.48100, 73.490…\n$ lifeExp1982   &lt;dbl&gt; 39.854, 70.420, 61.368, 39.942, 69.942, 74.740, 73.180, …\n$ lifeExp1987   &lt;dbl&gt; 40.822, 72.000, 65.799, 39.906, 70.774, 76.320, 74.940, …\n$ lifeExp1992   &lt;dbl&gt; 41.674, 71.581, 67.744, 40.647, 71.868, 77.560, 76.040, …\n$ lifeExp1997   &lt;dbl&gt; 41.763, 72.950, 69.152, 40.963, 73.275, 78.830, 77.510, …\n$ lifeExp2002   &lt;dbl&gt; 42.129, 75.651, 70.994, 41.003, 74.340, 80.370, 78.980, …\n$ lifeExp2007   &lt;dbl&gt; 43.828, 76.423, 72.301, 42.731, 75.320, 81.235, 79.829, …\n$ gdpPercap1952 &lt;dbl&gt; 779.4453, 1601.0561, 2449.0082, 3520.6103, 5911.3151, 10…\n$ gdpPercap1957 &lt;dbl&gt; 820.8530, 1942.2842, 3013.9760, 3827.9405, 6856.8562, 10…\n$ gdpPercap1962 &lt;dbl&gt; 853.1007, 2312.8890, 2550.8169, 4269.2767, 7133.1660, 12…\n$ gdpPercap1967 &lt;dbl&gt; 836.1971, 2760.1969, 3246.9918, 5522.7764, 8052.9530, 14…\n$ gdpPercap1972 &lt;dbl&gt; 739.9811, 3313.4222, 4182.6638, 5473.2880, 9443.0385, 16…\n$ gdpPercap1977 &lt;dbl&gt; 786.1134, 3533.0039, 4910.4168, 3008.6474, 10079.0267, 1…\n$ gdpPercap1982 &lt;dbl&gt; 978.0114, 3630.8807, 5745.1602, 2756.9537, 8997.8974, 19…\n$ gdpPercap1987 &lt;dbl&gt; 852.3959, 3738.9327, 5681.3585, 2430.2083, 9139.6714, 21…\n$ gdpPercap1992 &lt;dbl&gt; 649.3414, 2497.4379, 5023.2166, 2627.8457, 9308.4187, 23…\n$ gdpPercap1997 &lt;dbl&gt; 635.3414, 3193.0546, 4797.2951, 2277.1409, 10967.2820, 2…\n$ gdpPercap2002 &lt;dbl&gt; 726.7341, 4604.2117, 5288.0404, 2773.2873, 8797.6407, 30…\n$ gdpPercap2007 &lt;dbl&gt; 974.5803, 5937.0295, 6223.3675, 4797.2313, 12779.3796, 3…\n$ pop1952       &lt;int&gt; 8425333, 1282697, 9279525, 4232095, 17876956, 8691212, 6…\n$ pop1957       &lt;int&gt; 9240934, 1476505, 10270856, 4561361, 19610538, 9712569, …\n$ pop1962       &lt;int&gt; 10267083, 1728137, 11000948, 4826015, 21283783, 10794968…\n$ pop1967       &lt;int&gt; 11537966, 1984060, 12760499, 5247469, 22934225, 11872264…\n$ pop1972       &lt;int&gt; 13079460, 2263554, 14760787, 5894858, 24779799, 13177000…\n$ pop1977       &lt;int&gt; 14880372, 2509048, 17152804, 6162675, 26983828, 14074100…\n$ pop1982       &lt;int&gt; 12881816, 2780097, 20033753, 7016384, 29341374, 15184200…\n$ pop1987       &lt;int&gt; 13867957, 3075321, 23254956, 7874230, 31620918, 16257249…\n$ pop1992       &lt;int&gt; 16317921, 3326498, 26298373, 8735988, 33958947, 17481977…\n$ pop1997       &lt;int&gt; 22227415, 3428038, 29072015, 9875024, 36203463, 18565243…\n$ pop2002       &lt;int&gt; 25268405, 3508512, 31287142, 10866106, 38331121, 1954679…\n$ pop2007       &lt;int&gt; 31889923, 3600523, 33333216, 12420476, 40301927, 2043417…\n\n\nCode\n## from wide to long\n\ngap_long &lt;- gap_wide |&gt; \n  pivot_longer(\n    cols = matches(\"\\\\d$\"),                    # good luck\n    names_to = c(\".value\", \"year\"),            # figuring this\n    names_pattern = \"([A-Za-z]*)(\\\\d+)\",       # out!!!\n    names_transform = list(year = as.integer)\n  )  \n\nglimpse(gap_long)\n\n\nRows: 1,704\nColumns: 6\n$ country   &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …\n$ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…\n$ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …\n$ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…\npanelr\nCode\ngap_long_panelr &lt;- gap_wide |&gt; \n  long_panel(\n    id = \"country\",\n    wave = \"year\",\n    begin = 1952,\n    end = 2007\n  )\n\ngap_long_panelr\n\n\n# Panel data:    7,952 × 6\n# Entities:      country [142]\n# Wave variable: year [1952, 1953, 1954, ... (56 waves)]\n   country      year continent lifeExp gdpPercap     pop\n   &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;int&gt;\n 1 Afghanistan  1952 Asia         28.8      779. 8425333\n 2 Afghanistan  1953 Asia         NA         NA       NA\n 3 Afghanistan  1954 Asia         NA         NA       NA\n 4 Afghanistan  1955 Asia         NA         NA       NA\n 5 Afghanistan  1956 Asia         NA         NA       NA\n 6 Afghanistan  1957 Asia         30.3      821. 9240934\n 7 Afghanistan  1958 Asia         NA         NA       NA\n 8 Afghanistan  1959 Asia         NA         NA       NA\n 9 Afghanistan  1960 Asia         NA         NA       NA\n10 Afghanistan  1961 Asia         NA         NA       NA\n# ℹ 7,942 more rows\nNote that panelr has made the missing values explicit, which is something you may want (or not).\nOnce you gap_long_panelr you’ll notice that this object has an extra class called “panel_data.” The widen_panel() function understands this and can make the change to “wide” effortlessly.\nCode\nwiden_panel(gap_long_panelr)\n\n\n# A tibble: 142 × 170\n   country     continent lifeExp_1952 gdpPercap_1952 pop_1952 lifeExp_1953\n   &lt;fct&gt;       &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;    &lt;int&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia              28.8           779.  8425333           NA\n 2 Albania     Europe            55.2          1601.  1282697           NA\n 3 Algeria     Africa            43.1          2449.  9279525           NA\n 4 Angola      Africa            30.0          3521.  4232095           NA\n 5 Argentina   Americas          62.5          5911. 17876956           NA\n 6 Australia   Oceania           69.1         10040.  8691212           NA\n 7 Austria     Europe            66.8          6137.  6927772           NA\n 8 Bahrain     Asia              50.9          9867.   120447           NA\n 9 Bangladesh  Asia              37.5           684. 46886859           NA\n10 Belgium     Europe            68            8343.  8730405           NA\n# ℹ 132 more rows\n# ℹ 164 more variables: gdpPercap_1953 &lt;dbl&gt;, pop_1953 &lt;int&gt;,\n#   lifeExp_1954 &lt;dbl&gt;, gdpPercap_1954 &lt;dbl&gt;, pop_1954 &lt;int&gt;,\n#   lifeExp_1955 &lt;dbl&gt;, gdpPercap_1955 &lt;dbl&gt;, pop_1955 &lt;int&gt;,\n#   lifeExp_1956 &lt;dbl&gt;, gdpPercap_1956 &lt;dbl&gt;, pop_1956 &lt;int&gt;,\n#   lifeExp_1957 &lt;dbl&gt;, gdpPercap_1957 &lt;dbl&gt;, pop_1957 &lt;int&gt;,\n#   lifeExp_1958 &lt;dbl&gt;, gdpPercap_1958 &lt;dbl&gt;, pop_1958 &lt;int&gt;, …\nNote that there’s a lot of columns with missing values. You’ll have to drop them first with drop_na() if you don’t want them.\nCode\ngap_long_panelr |&gt; \n  tidyr::drop_na() |&gt; \n  widen_panel()\n\n\n# A tibble: 142 × 38\n   country     continent lifeExp_1952 gdpPercap_1952 pop_1952 lifeExp_1957\n   &lt;fct&gt;       &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;    &lt;int&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia              28.8           779.  8425333         30.3\n 2 Albania     Europe            55.2          1601.  1282697         59.3\n 3 Algeria     Africa            43.1          2449.  9279525         45.7\n 4 Angola      Africa            30.0          3521.  4232095         32.0\n 5 Argentina   Americas          62.5          5911. 17876956         64.4\n 6 Australia   Oceania           69.1         10040.  8691212         70.3\n 7 Austria     Europe            66.8          6137.  6927772         67.5\n 8 Bahrain     Asia              50.9          9867.   120447         53.8\n 9 Bangladesh  Asia              37.5           684. 46886859         39.3\n10 Belgium     Europe            68            8343.  8730405         69.2\n# ℹ 132 more rows\n# ℹ 32 more variables: gdpPercap_1957 &lt;dbl&gt;, pop_1957 &lt;int&gt;,\n#   lifeExp_1962 &lt;dbl&gt;, gdpPercap_1962 &lt;dbl&gt;, pop_1962 &lt;int&gt;,\n#   lifeExp_1967 &lt;dbl&gt;, gdpPercap_1967 &lt;dbl&gt;, pop_1967 &lt;int&gt;,\n#   lifeExp_1972 &lt;dbl&gt;, gdpPercap_1972 &lt;dbl&gt;, pop_1972 &lt;int&gt;,\n#   lifeExp_1977 &lt;dbl&gt;, gdpPercap_1977 &lt;dbl&gt;, pop_1977 &lt;int&gt;,\n#   lifeExp_1982 &lt;dbl&gt;, gdpPercap_1982 &lt;dbl&gt;, pop_1982 &lt;int&gt;, …",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Solutions 10</span>"
    ]
  },
  {
    "objectID": "solutions10.html#exercise-1",
    "href": "solutions10.html#exercise-1",
    "title": "21  Solutions 10",
    "section": "21.2 Exercise",
    "text": "21.2 Exercise\n\n\n\n\n\n\nSlide 33 contains a very simple visualization made using the line_plot() function.\nTry your best to make a similar graph for the gapminder dataset, with year on the x-axis and lifeExp on the y-axis for a random subset of 10 countries.\nUse ggplot2, do not use line_plot()\n\n\n\nThe trick to answering this question is to first figure out how to select a random subset of countries when the rows of gapminder don’t represent countries but country-years.\n\n\nCode\ncountry_list &lt;- unique(gapminder$country)\n\ngapminder |&gt; \n  filter(country %in% sample(country_list, 10)) |&gt; \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_point(size = 1/2) +\n  geom_line(alpha = 1/2)\n\n\n\n\n\n\n\n\n\nIf you want the lines distinguished by colors, you can do something like this:\n\n\nCode\ngapminder |&gt; \n  filter(country %in% sample(country_list, 10)) |&gt; \n  ggplot(aes(year, lifeExp, color = country)) +\n  geom_point(size = 1/2) +\n  geom_line(alpha = 1/2)\n\n\n\n\n\n\n\n\n\n…or maybe by continent:\n\n\nCode\ngapminder |&gt; \n  filter(country %in% sample(country_list, 10)) |&gt; \n  ggplot(aes(year, lifeExp, color = continent, group = country)) +\n  geom_point(size = 1/2) +\n  geom_line(alpha = 1/2)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Solutions 10</span>"
    ]
  },
  {
    "objectID": "solutions10.html#exercise-2",
    "href": "solutions10.html#exercise-2",
    "title": "21  Solutions 10",
    "section": "21.3 Exercise",
    "text": "21.3 Exercise\nThe ICC is a summary statistic that only makes sense when you have data whose variance can be partitioned in terms of within and between.\nTwo typical situations:\n\nClusters (e.g., “students nested” in classrooms)\nRepeated observations (e.g., observations “nested in” individuals).\n\nPanel data is case of the latter. In class we saw an example of a multilevel model, which extends typical regression models by adding a second error term.\nFor example:\n\\[\n\\text{lwage}_{it} = \\beta_0 + \\beta_1 \\text{college}_i + \\alpha_i + \\epsilon_{it}\n\\]\nHow much of the variance is within and how much is between? We can get a simple answer to this question by examining the intraclass correlation, defined as:\\[\\text{ICC} = \\frac{\\tau^2}{\\tau^2 + \\sigma^2}\\]where \\(\\tau^2\\) is the between-person variance and \\(\\sigma^2\\) is the within-person variance.\n\n\n\n\n\n\nWhat is the ICC for lifeExp, pop, and gdpPercap in the gapminder dataset?\n\n\n\nThere are many ways to do this\nMethod 1 (full manual)\n\n\nCode\n## Steve's code\n\n# BETWEEN VARIANCE\nb_var &lt;- gapminder |&gt;\n  group_by(country) |&gt;                            # do calculations separately for ids\n  summarize(mean_lifeExp = mean(lifeExp)) |&gt;      # get each id's mean [lifeExp]\n  summarize(b_var = var(mean_lifeExp)) |&gt;         # get variance of means\n  as.numeric()                                    # output as a number\n\nb_var\n\n\n[1] 124.2174\n\n\nCode\n# WITHIN VARIANCE\nw_var &lt;- gapminder |&gt;                             \n  group_by(country) |&gt;                            # do calculations separately for ids\n  mutate(dev_lifeExp = lifeExp - mean(lifeExp)) |&gt;# create time devs from each id's mean\n  ungroup() |&gt;                                    # calcs on whole data frame\n  summarize(w_var = var(dev_lifeExp)) |&gt;          # get variance of deviations\n  as.numeric()                                    # output as number\n\nw_var\n\n\n[1] 43.43659\n\n\nCode\n## ICC\nb_var / (b_var + w_var)\n\n\n[1] 0.7409153\n\n\nMethod 2 (using OLS)\n\n\nCode\nols &lt;- lm(lifeExp ~ country, data = gapminder)\n1 - (var(ols$residuals) / var(gapminder$lifeExp))\n\n\n[1] 0.7396694\n\n\nNote. Here I took advantage of the fact that var(gapminder$lifeExp) is the sum of the between and within variance. If you’re curious about this I encourage you to search for “the law of total variance” in probability theory.\nMethod 3 (using lmer)\n\n\nCode\nmlm &lt;- lmer(lifeExp ~ (1 | country), data = gapminder, REML = FALSE)\nperformance::icc(mlm)\n\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.716\n  Unadjusted ICC: 0.716\n\n\nExcuse me! The results are too different… what gives?\nThe numbers differ a bit because lmer() “shrinks” the estimates of the means towards the population mean a bit (in exchange for better “efficiency”). This issue is outside the scope of this homework, but both results are OK!\nIf you want some intuition of what this “shrinkage” business is all about, I recommend squinting at the following graph:\n\n\nCode\npred_ols &lt;- broom::augment(ols, newdata = tibble(country = country_list))\n\ndf &lt;- coefficients(mlm)$country |&gt; \n  rownames_to_column(\"country\") |&gt; \n  full_join(pred_ols)\n\ndf |&gt; \n  rename(lm = \".fitted\", lmer = \"(Intercept)\") |&gt; \n  mutate(diff = abs(lm - lmer)) |&gt; \n  mutate(country = fct_reorder(country, diff)) |&gt; \n  ggplot(aes(y = country)) + \n  geom_point(aes(x = lm, color = \"lm\"), size = 1/2) + \n  geom_point(aes(x = lmer, color = \"lmer\"), size = 1/2) + \n  labs(x = \"average lifeExp\", y = NULL)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Solutions 10</span>"
    ]
  },
  {
    "objectID": "solutions10.html#exercise-3",
    "href": "solutions10.html#exercise-3",
    "title": "21  Solutions 10",
    "section": "21.4 Exercise",
    "text": "21.4 Exercise\nNote. In case you didn’t notice, this exercise was taken straight from Steve’s ldar course materials.\n\n\nCode\ndata(\"WageData\", package = \"panelr\")\n\nWageData &lt;- WageData |&gt; \n  mutate(\n    college = if_else(ed &gt;= 16, 1L, 0L),  # college variable\n    t0 = t - 1                            # start time at 0\n  )\n\nmod1 &lt;- lmer(lwage ~ college + t0 + (1 | id), REML = FALSE, data = WageData)\nmod2 &lt;- lmer(lwage ~ college + t0 + (t0 | id), REML = FALSE, data = WageData)\nmod3 &lt;- lmer(lwage ~ college + t0 + I(t0^2) + (t0 + I(t0^2) | id), REML = FALSE, \n             data = WageData, \n             ## I got this part from Stack Overflow, will update if something's wrong\n             control = lmerControl(optimizer = 'optimx', optCtrl = list(method = 'nlminb')))\n\n\nLoading required namespace: optimx\n\n\nCode\n# compare BICs\nBIC(mod1, mod2, mod3)\n\n\n     df       BIC\nmod1  5 -1574.123\nmod2  7 -1930.822\nmod3 11 -1996.860\n\n\nCode\n# get coef\nsummary(mod3)\n\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: lwage ~ college + t0 + I(t0^2) + (t0 + I(t0^2) | id)\n   Data: WageData\nControl: lmerControl(optimizer = \"optimx\", optCtrl = list(method = \"nlminb\"))\n\n     AIC      BIC   logLik deviance df.resid \n -2066.5  -1996.9   1044.3  -2088.5     4154 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-13.5294  -0.3002   0.0237   0.3372  14.1080 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr       \n id       (Intercept) 1.159e-01 0.34038             \n          t0          5.175e-03 0.07194   0.08      \n          I(t0^2)     8.817e-05 0.00939  -0.19 -0.87\n Residual             1.611e-02 0.12694             \nNumber of obs: 4165, groups:  id, 595\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept)  6.281924   0.017114 367.065\ncollege      0.312154   0.032143   9.712\nt0           0.118664   0.004612  25.729\nI(t0^2)     -0.003622   0.000686  -5.280\n\nCorrelation of Fixed Effects:\n        (Intr) colleg t0    \ncollege -0.515              \nt0      -0.115  0.000       \nI(t0^2)  0.052  0.000 -0.924\n\n\nCode\nggpredict(mod1, terms = c(\"t0 [all]\", \"id [sample = 9]\"), type = \"random\") |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\nCode\nggpredict(mod2, terms = c(\"t0 [all]\", \"id [sample = 9]\"), type = \"random\") |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\nCode\nggpredict(mod3, terms = c(\"t0 [all]\", \"id [sample = 9]\"), type = \"random\") |&gt; \n  plot()",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Solutions 10</span>"
    ]
  },
  {
    "objectID": "solutions11.html",
    "href": "solutions11.html",
    "title": "22  Solutions 11",
    "section": "",
    "text": "22.1 Exercise\nThe assumption is that the pre-treatment outcome is a valid counterfactual for the the post-treatment outcome. In other words, the “event” is the only thing that has had an effect on the outcome—i.e., no time trends.\nThis is not a problem in many everyday situations—e.g., the amount of light in a room before you flick the switch is a perfectly reasonable counterfactual to compare the amount of light you observe after you flick the switch. No control group needed!\nIn most cases, this is a very strong assumption.\nIt basically says the following:\n\\[\nE[Y_{t_1} \\mid Z = 0] = E[Y_{t_2} \\mid Z = 0]\n\\]\nAnd so the treatment effect is a simple pre-post subtraction:\n\\[\n\\begin{align}\n\\text{TE} &= E[Y_{t_2} \\mid Z = 1] - \\underbrace{E[Y_{t_2} \\mid Z = 0]}_{\\text{unobserved}} \\\\\n&= E[Y_{t_2} \\mid Z = 1] - \\underbrace{E[Y_{t_1} \\mid Z = 0]}_{\\text{observed}}\n\\end{align}\n\\]\nWe don’t have to make this assumption with difference-in-differences because we are effectively controlling for time trends in exchange for a weaker assumption—i.e., parallel trends. However, unlike “event studies,” we actually need some untreated group(s) to construct the counterfactual.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise",
    "href": "solutions11.html#exercise",
    "title": "22  Solutions 11",
    "section": "",
    "text": "In the Event Studies chapter we estimated the effect of something that occurs at a specific time by just comparing before-event to after-event, without really using a control group. What assumption is made by no-control-group event studies that we don’t have to make with difference-in-differences?\n\n\n\n\n\n\n\n\\(t\\) means “time” and \\(Z\\) means “treatment”",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-1",
    "href": "solutions11.html#exercise-1",
    "title": "22  Solutions 11",
    "section": "22.2 Exercise",
    "text": "22.2 Exercise\n\nWhich of the following potential back doors is controlled for by comparing the treated group to a control group?\n\nThe treated group may be following a trend, unique to the group, that would make the outcome change from before-treatment to after-treatment anyway\nThere may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway\nThere may be differences in typical outcome levels between the treated group and the untreated group\nThe decision to treat the treated group, rather than some other group, may be based on factors that are related to the outcome\n\n\nAnswer: B, there may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-2",
    "href": "solutions11.html#exercise-2",
    "title": "22  Solutions 11",
    "section": "22.3 Exercise",
    "text": "22.3 Exercise\n\nConsider a treatment and control group. Looking only at the pre-treatment period, they have exactly the same outcomes (zero gap between them in each period).\na. Despite having exactly the same outcomes pre-treatment, it happens to be the case that parallel trends is violated for these two groups. How is this possible? Explain what it means for parallel trends to be violated in this case, or give an example of how it could be violated.\n\nThe fact that pre-treatment outcomes coincide does not guarantee that the parallel trends assumption holds. It could be that the observed outcomes were just the same by coincidence, but that they were always set on different paths.\nFor example, think about the heights of children before and after puberty (the “treatment” can be something like growth hormones). In the absence of “treatment,” do we have reason to believe that they will grow exactly the same even if they share the same baseline?\n\nb. If we estimate the causal effect in this case using difference-in-differences, even though parallel trends is violated, how much would our effect be off by? (note you won’t be able to give a specific number)\n\nThe answer depends on how wrong is the parallel trends assumption. We will be off by the total change minus the treatment effect.\n\nEdit:\nI realize my wording here is a little confusing. My apologies.\nSuppose that the actual causal effect is zero.\nThis means that our diff-in-diff estimate will be equal to the following formula if and only if the parallel trends assumption holds:\n\\[\n0 = \\underbrace{(Y^\\text{treated}_{t = 1} - Y^\\text{treated}_{t = 0})}_{\\Delta Y^\\text{treated}} - \\underbrace{(Y^\\text{untreated}_{t = 1} - Y^\\text{untreated}_{t = 0})}_{\\Delta Y^\\text{untreated}}\n\\]\nThis means that we will overestimate the effect when the change in the treated group is larger than the change in the untreated groups for reasons other than the actual treatment.\n\\[\n\\Delta Y^\\text{untreated} &lt; \\Delta Y^\\text{treated}\n\\]\nAnd we will underestimate the effect when the opposite holds true.\n\\[\n\\Delta Y^\\text{untreated} &gt; \\Delta Y^\\text{treated}\n\\]",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-3",
    "href": "solutions11.html#exercise-3",
    "title": "22  Solutions 11",
    "section": "22.4 Exercise",
    "text": "22.4 Exercise\n\nConsider the below graph showing the average outcome for treated and control groups in the lead up to treatment (indicated by the dashed line), and also after treatment\n\n\n\n\n\n\n\n\nBased on the prior trend, does it seem likely that parallel trends holds in this instance?\n\n\nNo! They are clearly very different.\n\n\nIf we estimate difference-in-differences anyway, are we likely to overestimate the actual causal effect, underestimate it, or get it right on average?\n\n\nUnderestimate!\n\nEdit:\nNote that the slope for the untreated group is steeper than the slope for the treated group. As mentioned in the previous edit, we are likely to underestimate the effect when \\(\\Delta Y^\\text{untreated} &gt; \\Delta Y^\\text{treated}\\) for reasons other than the actual treatment.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-4",
    "href": "solutions11.html#exercise-4",
    "title": "22  Solutions 11",
    "section": "22.5 Exercise",
    "text": "22.5 Exercise\n\nIn mid-2020, during the COVID-19 pandemic, different countries pursued different courses of action. Some locked down fully, imposing harsh penalties to most people for leaving the house outside certain proscribed times. Some were looser and only suggested staying at home, and some had hardly any restrictions at all. You notice that COVID rates tend to spike dramatically in different countries at seemingly-random times, and want to know if certain restrictions helped.\nFrom March through May 2020, US and Canada COVID case rates followed similar trends (US rates were higher, but the trends were similar). You want to look at the effect of COVID restrictions enacted in Canada in late May 2020 on case rates. Is DID, with the US as a control group, a good way to estimate this effect? If not, what concerns would you have about this research design?\n\nNo. There are no reasons to believe that the parallel trends assumption holds for these two countries. For starters, the population size is very different and the spread of COVID seems to be influenced by population density.\nFurthermore, because they are neighboring countries with a lot of traffic between them, we can imagine a lot of spill-over effects.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-5",
    "href": "solutions11.html#exercise-5",
    "title": "22  Solutions 11",
    "section": "22.6 Exercise",
    "text": "22.6 Exercise\n\nConsider the below table of mean outcomes, and calculate the difference-in-difference effect of treatment. Write out the equation you used to calculate it (i.e. show how the four numbers in the table are combined to get the estimate)\n\n\n\n\n\nBefore\nAfter\n\n\nTreated\n5\n9\n\n\nUntreated\n6\n7.5\n\n\n\nIt only takes 4 averages to calculate a simple diff-in-diff estimate.\n\\[\n\\begin{align}\nd^{(1)} &= 9 - 5 = 4, \\\\\\\\\nd^{0} &= 7.5 - 6= 1.5, \\\\\\\\\n\\text{DiD} &= 4 - 1.5 = 2.5\n\\end{align}\n\\]\nHopefully, this should all seem very familiar to the following linear regression:\n\\[\n\\mathbb E[y_{it}] = \\beta_0 + \\beta_1 \\text{treat} + \\beta_2 \\text{post} + \\beta_3 \\text{treat} \\times \\text{post}\n\\]\nIn which we replace the previous table with the following parameter values:\n\n\n\n\n\n\n\n\n\nBefore\nAfter\n\n\nTreated\n\\(\\beta_0 + \\beta_1\\)\n\\(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3\\)\n\n\nUntreated\n\\(\\beta_0\\)\n\\(\\beta_0 + \\beta_2\\)\n\n\n\nThis makes the difference-in-difference estimator to be simply the interaction term ( \\(\\beta_3\\) ) in the context of two time periods and two groups.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-6",
    "href": "solutions11.html#exercise-6",
    "title": "22  Solutions 11",
    "section": "22.7 Exercise",
    "text": "22.7 Exercise\n\nYou are planning to estimate whether voter-protection laws increase voter turnout. You note that, in 2015, a lot of new voter-protection laws were enacted in some provinces but not in others. Conveniently, no new laws were enacted in 2012, 2014, or 2016, so you decide to use 2012 and 2014 as your “before” periods and 2016 as “after”.\n\nWhich of the following best describes what you’d want to regress state-and-year level “voter turnout” measures on?\n\nAn indicator for whether the state is treated, and an indicator for whether the year is 2016.\nA set of fixed effects for state, and a set of fixed effects for year.\nAn indicator for whether the state is treated, a set of fixed effects for year, and an indicator for whether the state is currently treated.\nA set of fixed effects for state, and for year, and an interaction between “is 2016” and “is a treated state”.\nThis design should not be estimated using a regression.\n\nUnless you chose the final option in the previous question, specify which coefficient in that regression would give you the DID estimate.\n\n\nAnswer for Part A: iv.\nThis is the “two-way fixed effects difference-in-difference estimator.”\nAnswer for Part B: The coefficient for the interaction term between “is 2016” and “is a treated state.”",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-7",
    "href": "solutions11.html#exercise-7",
    "title": "22  Solutions 11",
    "section": "22.8 Exercise",
    "text": "22.8 Exercise\n\nIn your own words, describe what is the “two-way fixed effects difference-in-difference estimator.” What does this model assume about the effect of some treatment over time?\n\nWe use TWFE when we have measurements for various time periods and various control groups.\n\\[\ny_{it} =  \\beta \\times \\text{Treated}_{it}  + \\mu_i + \\theta_t + \\epsilon_{it}\n\\]\nHere, \\(\\mu_i\\) is a fixed effect for each group, \\(\\theta\\) is a fixed effect for each time period, and \\(\\beta\\) is the parameter we are interested in estimating. The variable \\(\\text{Treated}\\) is an indicator variable that is 0 when \\(i\\) is the “treated group” and \\(t\\) is “after treatment period” (i.e., it’s an interaction term).\n\n\n\n\n\n\nSee Steve’s slides 90-93 (and slide 97)\n\n\n\nTWFE assumes that the treatment effect is \\(\\beta\\), which means that it’s homogeneous for all units in the treatment group across time (by definition). It also works best when all treated groups (if you have more than one) get treated at the same time.\n\n\n\n\n\n\nSee dynamic treatment effects and staggered difference-in-differences for different approaches to deal with these issues.",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-8",
    "href": "solutions11.html#exercise-8",
    "title": "22  Solutions 11",
    "section": "22.9 Exercise",
    "text": "22.9 Exercise\n\nConsider the below graph with estimates from a dynamic difference-in-differences model for a treatment that occurs between periods 4 and 5, with 95% confidence intervals shown.\n\n\n\n\n\n\n\nWhat about this graph might make us concerned about our identification assumptions?\n\nWe should be concerned about “the effect” at \\(t = 1\\), which indicates that the parallel-trends assumption might not hold. Should we really be concerned about this? Or should we keep calm and carry on? The best answer is “Yes, we should be concerned.”\n\nIgnoring any concerns we have, what would we say is the effect of treatment on Y in this case? (note the height of the line in period 5 is about 3, in period 6 is about 1, and in period 7 is about .5).\n\nWe say that the effect is 3 in the period immediately after the treatment occurs, but that this effect is short-lived (i.e., it is transitory).",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "solutions11.html#exercise-9",
    "href": "solutions11.html#exercise-9",
    "title": "22  Solutions 11",
    "section": "22.10 Exercise",
    "text": "22.10 Exercise\n\n\nPackages and Setup\n## Packages\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(fixest)\n\n## Additional\n\nmsummary &lt;- function(...) {\n  modelsummary::msummary(..., output = \"gt\") |&gt; \n  gt::opt_table_font(font = \"Optima\") |&gt; \n  gt::tab_options(quarto.disable_processing = TRUE)\n}\n\ntheme_set(theme_light(base_family = \"Optima\"))\n\n\nLoad Data\n\n\nCode\nurl &lt;- \"https://raw.githubusercontent.com/NickCH-K/TheEffectAssignments/main/sourdough_trends.csv\"\n\nsr &lt;- read_csv(url) |&gt; \n  select(date, keyword, hits) |&gt; \n  mutate(\n    date = as.Date(date),\n    keyword = factor(keyword)\n  )\n\nglimpse(sr)\n\n\nRows: 856\nColumns: 3\n$ date    &lt;date&gt; 2020-01-01, 2020-01-02, 2020-01-03, 2020-01-04, 2020-01-05, 2…\n$ keyword &lt;fct&gt; sourdough, sourdough, sourdough, sourdough, sourdough, sourdou…\n$ hits    &lt;dbl&gt; 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 4, 3, 2, 2, 2, 2, 3, 4, 3, 4, 2,…\n\n\nLine Graph\n\n\nCode\nsr |&gt; \n  ggplot(aes(date, hits, color = keyword)) + \n  geom_line() + \n  geom_vline(xintercept = as.Date(\"2020-03-15\"), linetype = \"dashed\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\")\n\n\n\n\n\n\n\n\n\nIt looks like the lockdown did have an effect on the popularity of sourdough, although the effect seems to be dynamic (permanent, but certainly decreasing after some initial hype). Also, we should definitely not use soup as a control group.\n\nCreate a “Treated” indicator that’s equal to 1 for sourdough and 0 otherwise (or True/False, either way). Do a test of whether the prior trends (keeping March 15 as the “treatment date”) differ between the treated and control groups, using a linear trend and doing a statistical significance test at the 95% level. Then, if you were concerned about any of the control groups in question 3c, drop any you were concerned about (and keep them dropped for the rest of the assignment) and rerun the test.\n\n\n\nCode\nsr &lt;- sr |&gt; \n  mutate(Treated = ifelse(keyword == \"sourdough\", 1L, 0L)) |&gt; \n  mutate(time = as.numeric(date) - min(as.numeric(date)))\n\nm1 &lt;- lm(\n  hits ~ time*Treated + keyword, \n  data = filter(sr, date &lt; as.Date(\"2020-03-15\"))\n)\n\nmsummary(\n  models = m1, \n  coef_map = \"time:Treated\",\n  gof_map = \"none\", \n  stars = TRUE\n)\n\n\n\n\n\n  \n    \n    \n       \n      (1)\n    \n  \n  \n    time:Treated\n0.134***\n    \n(0.039)\n  \n  \n    \n      + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n  \n  \n\n\n\n\nCode\nsr_sub &lt;- sr |&gt; \n  filter(keyword != \"soup\")\n\nm2 &lt;- lm(\n  hits ~ time*Treated + keyword, \n  data = filter(sr_sub, date &lt; as.Date(\"2020-03-15\"))\n)\n\nmsummary(\n  models = list(m1, m2), \n  coef_map = \"time:Treated\",\n  gof_map = \"none\",\n  stars = TRUE\n)\n\n\n\n\n\n  \n    \n    \n       \n      (1)\n      (2)\n    \n  \n  \n    time:Treated\n0.134***\n-0.023+\n    \n(0.039)\n(0.012)\n  \n  \n    \n      + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n    \n  \n  \n\n\n\n\nSo, by dropping soup from the dataset we have no discernible differences between groups before treatments (although this might different if you have different opinions about statistical significance). I have decided that dropping soup is good enough, but you might have decided to drop additional keywords.\n\nCreate a month variable by shifting the date variable back 15 days (so that the treatment day is the first day of the month) and then taking the month of the resulting date. Also create an After variable equal to 1/0 (or True/False) if the date is March 15 or afterwards.\nThen, take a look at the values of month you get and how they line up with date, and subtract a number from month so that the last period just before treatment (Feb 16-Mar 14) is 0. (Also, change the Jan 1-14 month so it’s one less than the Jan 15-Feb 14 month)\n(You can then use -lubridate::days() to subtract days from the date, and lubridate::month() to get the month from the date.)\n\n\n\nCode\nsr_sub &lt;- sr_sub |&gt; \n  mutate(\n    month = month(date - days(14)) - 2,\n    After = if_else(\n      condition = date &gt;= as.Date(\"2020-03-15\") & Treated == 1L, \n      true = 1L, \n      false = 0L\n      )\n  ) |&gt; \n  mutate(month = if_else(date &lt;= as.Date(\"2020-01-14\"), -2, month)) \n\n\nI’m not gonna lie, that took some noodling around.\n\nThen, use two-way fixed effects to estimate the difference-in-difference estimate of the effect of lockdown on sourdough popularity with keyword and month fixed effects, and standard errors clustered at the keyword level.\n\n\n\nCode\ntwfe &lt;- feols(\n  hits ~ After | keyword + month,\n  cluster = \"keyword\",\n  data = sr_sub\n)\n\nmsummary(twfe, gof_map = \"none\")\n\n\n\n\n\n  \n    \n    \n       \n      (1)\n    \n  \n  \n    After\n8.410\n    \n(0.268)\n  \n  \n  \n\n\n\n\nNote. You could have gone the same point-estimate (different standard error) using OLS:\n\n\nCode\nols &lt;- lm(hits ~ After + factor(month) + keyword, data = sr_sub)\nols$coefficients[[\"After\"]]\n\n\n[1] 8.410135\n\n\n\nThe chapter introduces dynamic treatment effects, which where briefly discussed by Steve. One of the reasons fixest is becoming a popular package is because it makes estimating these models very easy, although it introduces a special syntax.\n\nThis is how we would estimate a difference-in-difference model allowing the effect to differ by month (using month = 0 as a reference period), with standard errors clustered at the keyword level.\n\n\nCode\ndynamic &lt;- feols(\n  hits ~ i(month, Treated, ref = 0) | keyword + month,\n  cluster = \"keyword\",\n  data = sr_sub\n)\n\nmsummary(dynamic)\n\n\n\n\n\n  \n    \n    \n       \n      (1)\n    \n  \n  \n    month = -2 × Treated\n1.493\n    \n(1.301)\n    month = -1 × Treated\n1.288\n    \n(1.224)\n    month = 1 × Treated\n12.546\n    \n(2.580)\n    month = 2 × Treated\n14.224\n    \n(1.457)\n    month = 3 × Treated\n8.981\n    \n(0.673)\n    month = 4 × Treated\n4.424\n    \n(0.148)\n    month = 5 × Treated\n3.651\n    \n(0.216)\n    Num.Obs.\n642\n    R2\n0.922\n    R2 Adj.\n0.920\n    R2 Within\n0.565\n    R2 Within Adj.\n0.560\n    AIC\n2840.3\n    BIC\n2916.2\n    RMSE\n2.15\n    Std.Errors\nby: keyword\n    FE: keyword\nX\n    FE: month\nX\n  \n  \n  \n\n\n\n\nCode\ncoefplot(dynamic)",
    "crumbs": [
      "Solutions",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Solutions 11</span>"
    ]
  },
  {
    "objectID": "sec-summary.html",
    "href": "sec-summary.html",
    "title": "23  Topics",
    "section": "",
    "text": "What is your estimand?\n\nestimands, estimators, estimates\n\nIdentification and causal diagrams\n\nfront doors\nback doors\ncolliders\npost-treatment bias\n\nMultiple regression and adjustment\n\nintepreting effect sizes\nusing marginaleffects\nfunctional form considerations\n\nMatching and weighting\n\nexact matching\npropensity scores (parametric and semi-parametric)\nnearest neighbor matching on the propensity score for ATT\nweighting using propensity scores for ATT and ATE\nweighting using non-propensity methods for ATT and ATE\n\nPanel data concepts\n\nwithin and between variance\nvariance components\nICC calculation\n\nMixed model for time-constant treatments\n\nadvantages over linear regression\nrandom growth curve models\nshrinkage\n\nWithin-subject models\n\nadvantages for estimating counterfactuals\ndisadvantages for generalization\npre-post\ntwo-period difference-in-differences\ntwo-way fixed effects\n\nWithin-between / correlated random effects models\n\nsplitting variables\ncombining strengths of mixed- and within-subject models\ninterpreting within, between, and contextual coefficients",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Topics</span>"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Estimand\nThe parameter or quantity of interest that one aims to estimate in a statistical analysis. It defines what effect or measure is being targeted by the analysis, specifying how it relates to the variables and data involved.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#counterfactual",
    "href": "glossary.html#counterfactual",
    "title": "Glossary",
    "section": "Counterfactual",
    "text": "Counterfactual\nThe counterfactual compares the observed results of something that did happen to the expected results if the treatment had not happened.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#potential-outcomes",
    "href": "glossary.html#potential-outcomes",
    "title": "Glossary",
    "section": "Potential Outcomes",
    "text": "Potential Outcomes\nThe set of all possible outcomes for each individual in a study, under each possible treatment or intervention scenario. These outcomes reflect what could happen to each individual under different conditions.\n\nNote.\nI think it’s better to think of “potential outcomes.”\nFor example, in the case of a binary treatment, the potential outcomes framework involves the following:\n\n\\(T\\) is a treatment variable. The terms “treatment” and “cause” are used interchangeably.\n\\(Y\\) is the outcome we observe.\n\\(Y^0\\) is the the value the outcome would take if \\(T=0\\).\n\\(Y^1\\) is the value the outcome would take if \\(T=1\\).\n\\(Y^0\\) and \\(Y^1\\) are the potential outcomes.\nWe see \\(Y^0\\) or \\(Y^1\\) for the same unit, but never both.\nThis is the fundamental problem of causal inference.\nWhen \\(T=1\\), \\(Y^0\\) is the counterfactual.\nWhen \\(T=0\\), \\(Y^1\\) is the counterfactual.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#theoretical-estimand",
    "href": "glossary.html#theoretical-estimand",
    "title": "Glossary",
    "section": "Theoretical Estimand",
    "text": "Theoretical Estimand\nThis is the actual thing we would like to know in our research question. The two components of the theoretical estimand are the unit-specific quantity and the target population. The theoretical estimand includes both observed and unobserved data (including counterfactuals).",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#empirical-estimand",
    "href": "glossary.html#empirical-estimand",
    "title": "Glossary",
    "section": "Empirical Estimand",
    "text": "Empirical Estimand\nThe empirical estimand is the target of inference that only includes observable data and relies on identification assumptions.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#causal-interaction",
    "href": "glossary.html#causal-interaction",
    "title": "Glossary",
    "section": "Causal Interaction",
    "text": "Causal Interaction\nA causal interaction is the intervention to two variables averaged over one population. In other words, the effect of one variable on the outcome is related to the effect of another.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#baseline-bias",
    "href": "glossary.html#baseline-bias",
    "title": "Glossary",
    "section": "Baseline Bias",
    "text": "Baseline Bias\nWhen the treatment and the control group differ from one another for reasons other than the treatment they receive.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#average-treatment-effect-ate",
    "href": "glossary.html#average-treatment-effect-ate",
    "title": "Glossary",
    "section": "Average Treatment Effect (ATE)",
    "text": "Average Treatment Effect (ATE)\nThe average treatment effect across the population. In other words, this is the effect of switching treatment statuses (e.g., from either treatment to control or from control to treatment).",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#conditional-average-treatment-effect-cate",
    "href": "glossary.html#conditional-average-treatment-effect-cate",
    "title": "Glossary",
    "section": "Conditional Average Treatment Effect (CATE)",
    "text": "Conditional Average Treatment Effect (CATE)\nThe average treatment effect among a specific group as defined by certain control variables covariates.\nFor example, if the control variable covariate is \\(X\\), the CATE can be written as \\(E(Y^1-Y^0 \\mid X = x)\\).\n\nNote.\nThe word “control” has some baggage because it has the connotation that we can somehow manipulate \\(X\\). Here, we’d usually want to condition on variables like “gender” or “race.”",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#average-treatment-effect-on-the-treated-att",
    "href": "glossary.html#average-treatment-effect-on-the-treated-att",
    "title": "Glossary",
    "section": "Average Treatment Effect on the Treated (ATT)",
    "text": "Average Treatment Effect on the Treated (ATT)\nThe average treatment effect, calculated only from the treatment group. To conceptualize the ATT, imagine taking away treatment from those who were treated and measuring the change.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#average-treatment-effect-on-the-untreated-atu",
    "href": "glossary.html#average-treatment-effect-on-the-untreated-atu",
    "title": "Glossary",
    "section": "Average Treatment Effect on the Untreated (ATU)",
    "text": "Average Treatment Effect on the Untreated (ATU)\nThe average treatment effect, calculated only from the untreated group. To conceptualize the ATU, imagine giving the treatment to those who were not treated and measuring the change.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#unit-specific-quantity",
    "href": "glossary.html#unit-specific-quantity",
    "title": "Glossary",
    "section": "Unit-Specific Quantity",
    "text": "Unit-Specific Quantity\nA measurement or outcome that pertains to an individual unit or subject in a study, often used in contexts where the effect of a treatment may vary from one unit to another.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#treatment-effect-heterogeneity",
    "href": "glossary.html#treatment-effect-heterogeneity",
    "title": "Glossary",
    "section": "Treatment Effect Heterogeneity",
    "text": "Treatment Effect Heterogeneity\nWhen a treatment has different effects on a population.\nFor, example, a treatment for cervical cancer will have heterogeneous effects on people with cervixes versus people without cervixes, even if both groups in the population receive identical treatments. This is because people without cervixes will receive no treatment effect from drugs that target an organ they do not have.\n\n\nNote.\nThis is an extreme example. You’d usually want to remove men from design (i.e., not administering the treatment to people without cervixes).\nIn a less extreme example, the treatment for cervical cancer could have varying effects across women belonging to different age groups.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#directed-acyclic-graph-dag",
    "href": "glossary.html#directed-acyclic-graph-dag",
    "title": "Glossary",
    "section": "Directed Acyclic Graph (DAG)",
    "text": "Directed Acyclic Graph (DAG)\nA tool used to depict the data-generating process with nodes to represent the variable and the arrows to represent the causal relationships.\n\nCausal diagrams or DAGs are graphical representations of a data generating process. Everything we draw is hopefully an informed assumption; everything that’s not in the diagram is also an assumption. In other words, DAGs encode identifying assumptions.\nThe idea of a directed acyclical graph (DAG) implies that there are no cycles. If a variable causes itself, it’s near impossible to isolate or identifying the cause of anything. The world is full with feedback loops of all sorts, but we deal with them through the incorporation of time or by isolating one effect through some kind of experimental scenario.\nNote that DAGs are agnostic about functional form. This includes interactions among variables! Some people deal with interactions by drawing arrows toward arrows or by representing interactions explicitly as separate nodes.\nThe nicest thing about DAGs is that they help us spell out the testable implications of our assumptions. For example, if our causal diagram implies that a relationship between variables is zero, we can check for that.\n\n\nUnobserved / Unmeasured Variable\nA variable that may be present in the researcher’s assumptions about how the world works, but that is not addressed or available in the data.\n\nNote.\nIn a DAG, these variables are usually depicted by being enclosed within a circle.\n\n\n\nPath\nA path is simply the steps from one variable to another on a causal diagram.\nFor example, \\(A \\to B \\to C\\) is a path.\n\n\nDirect Effects\nThe effect of only the treatment variable on the outcome variable.\n\n\nIndirect Effects\nThe portion of the change in an outcome that is mediated through one or more intermediate variables, reflecting the causal influence exerted through these mediating variables.\n\n\nTotal Effects\nThe sum of direct and indirect effects.\n\n\nFront-Door Path\nA causal path in which all of the arrows in the causal diagram point from the treatment variable and towards the outcome variable.\n\n\nBack-Door Path\nThe rest of the paths on a causal diagram [connecting treatment to outcome] that are not front-door paths.\n\n\nConfounding Variable\nA variable that affects both the treatment and outcome variables.\nNote: Not adjusting for a confounding variable threatens the causal relationship between the treatment and outcome variables.\n\n\nNote.\nThe expression “threatens the causal relationship” is vague and clunky. A better way to say this is that the causal effect is not identified when we don’t adjust for confounding paths.\nAn even better way to talk about confounding is to realize that “confounding” is a property of paths, it’s NOT a property of variables.\n\n\n\nCollider Variable\nA variable in a DAG that is influenced by two or more other variables. Conditioning on a collider can open a confounding path, inadvertently introducing bias into the analysis.\n\nA variable is a collider in a path iff both arrows point at it.\n\\[\na \\to b \\to c_\\text{ollider} \\leftarrow d \\leftarrow e \\to f\n\\]\nHere, \\(b\\) and \\(c\\) are unrelated unless we remove variation in \\(c\\) (e.g., by including it in a regression).\nWe close paths by removing variation from one variable along the path (i.e., adjusting); but if the variable is a collider, then removing variation will actually open a path that was already closed.\nAn often unacknowledged way of adjusting for colliders is during the sample selection phase. If we have a sample of college students, it means we are adjusting for college attendance.\n\n\n\nOpen Path\nA path on a causal diagram in which there is variation in all variables along the path (and no variation in any colliders on that path).\n\n\nClosed Path\nA path on a causal diagram in which one or more variables has no variation.\nNote: A path is also considered closed if there is a collider variable present on that path.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#regression",
    "href": "glossary.html#regression",
    "title": "Glossary",
    "section": "Regression",
    "text": "Regression\nRegression focuses on estimating the effect of variables on an outcome through a mathematical model, assuming a specific form of relationship.\n\nNote.\nThis is NOT a good definition!!\nIn the usual context of regression, predictive inference relates to comparisons between units. In the context of causal inference, we attempt to make comparisons of different treatments as if applied to the same units.\nIn order to make causal interpretations of regression coefficients we rely very strong assumptions. In short, causal effects can be estimated with regression if the model includes all confounding variables and if the “functional form” is correct.\nTranslating DAGs into Regression\n\n\n\n\n\n\nFigure 24.1: Flow Chart For Constructing Regression Equations [@huntington-klein2021, pp. 199]",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#matching-and-weighting",
    "href": "glossary.html#matching-and-weighting",
    "title": "Glossary",
    "section": "Matching and Weighting",
    "text": "Matching and Weighting\nMatching and weighting seeks to identify the treatment effect by adjusting for selection into treatment by comparing similar treatment and control cases based on certain attributes.\nNote: This is distinct from regression, which adjusts for variables that impact the outcome.\n\nBoth regression and matching/weighting are strategies to close the backdoor path between \\(T\\) and \\(Y\\). Both are conditional on observable covariates. However, matching/weighting provides a way to model treatment selection so that everyone looks the same on the pre-treatment covariates.\nMatching/weighting refers to a set of procedures that modify the original sample in preparation for a statistical analysis. It’s a form of data pre-processing. The goal is to create a sample that looks like it was created from a randomized experiment.\nHere are some benefits of matching/weighting procedures:\n\nThey are less restrictive about functional form than regression. We rely less on parametric assumptions. The intuition is the same as with an experiment: if we can create sufficient overlap and balance between treatment and control groups, then we should get a reasonable estimate of the treatment effect, even if the model used to estimate it is misspecified.\nRegression models on pre-processed data gives us two opportunities to close backdoor paths (i.e., “double robustness”).",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#exact-matching",
    "href": "glossary.html#exact-matching",
    "title": "Glossary",
    "section": "Exact Matching",
    "text": "Exact Matching\nExact matching compares treatment and control cases that have exactly identical characteristics on a certain combination of variables. In this way, treatment cases are matched to control cases that share the exact same distribution of values for the matching variable(s) of interest, making the only difference between them is treatment status.\nThe three assumptions for exact matching are as follows:\n\nSelection of variables-conditional independence assumption.\nOverlap (any individual case has a non-zero probability of treatment).\nStable unit treatment value assumption (SUTVA; treatment status and effect of treatment is independent for each case).\n\n\n\nNote.\nThese assumptions are NOT unique to matching.\nA better discussion of overlap can be found here or in one of the textbooks.\nThis brief discussion from the MatchIt vignette is also useful:\nhttps://kosukeimai.github.io/MatchIt/articles/matching-methods.html#exact-matching-method-exact",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#conditional-independence-assumption-cia",
    "href": "glossary.html#conditional-independence-assumption-cia",
    "title": "Glossary",
    "section": "Conditional Independence Assumption (CIA)",
    "text": "Conditional Independence Assumption (CIA)\nThe conditional independence assumption asserts that two events occur independent of one another (i.e., the two events do not influence one another).\n\nThe CIA (also known as “conditional ignorability” assumption) builds on the more general idea of ignorability.\nExperiments work because they make the distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator are independent.\n\\[\nY^0, Y^1 \\perp T\n\\]\nHere, the \\(\\perp\\) symbol means independent.\nThe CIA is a necessary assumption we make when using both regression and matching/weighting to identify a causal effect.\nInstead of a simple independence assumption that we have for randomized experiments, we now have to rely on a conditional ignorability. Just like in the case of experiments, we want distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator should be independent, conditional on the covariates \\(\\boldsymbol{X}\\) used in the analysis.\n\\[\nY^0, Y^1 \\perp T \\mid \\boldsymbol X\n\\]\nHere, \\(\\boldsymbol{X}\\) is meant to depict a collection of variables that will close the back-door path.\nThis strategy will get more complicated as the vector \\(\\boldsymbol X\\) grows in size.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#region-of-common-support",
    "href": "glossary.html#region-of-common-support",
    "title": "Glossary",
    "section": "Region of Common Support",
    "text": "Region of Common Support\nThis is the assumption that either for distribution of a matching variable (in exact matching) or for distribution of propensity scores (in weighting), there are both treatment and control cases. If there is overlap, this is known as the region of common support. If there is not overlap in the distributions, that is “off support” and makes causal inference a little more tricky.\n\nNote.\nWhat makes it “tricky” is that we don’t have direct support from the data to estimate the relevant counterfactuals—e.g., regression will just extrapolate.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#feasible-estimate-of-treatment-effects",
    "href": "glossary.html#feasible-estimate-of-treatment-effects",
    "title": "Glossary",
    "section": "Feasible Estimate of Treatment Effects",
    "text": "Feasible Estimate of Treatment Effects\nWhen calculating a treatment effect, it is sometimes necessary to drop cases that fall outside of the “region of common support.” Because cases are dropped, the “true” treatment effect cannot be calculated, which leaves us with calculating the “feasible” treatment effect instead.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#propensity-score",
    "href": "glossary.html#propensity-score",
    "title": "Glossary",
    "section": "Propensity Score",
    "text": "Propensity Score\nA subject’s individual probability of receiving treatment. Propensity scores can then be used to match or weight control cases to mimic the treatment group.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#doubly-robust",
    "href": "glossary.html#doubly-robust",
    "title": "Glossary",
    "section": "Doubly-Robust",
    "text": "Doubly-Robust\nUsing “doubly robust” methods refers to using both regression and balancing in an equation simultaneously. Employing doubly robust measures is a way to mitigate biases or confounding variables from influencing the “true” treatment effect of your model.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#inverse-probability-of-treatment-weights-iptw",
    "href": "glossary.html#inverse-probability-of-treatment-weights-iptw",
    "title": "Glossary",
    "section": "Inverse probability of treatment weights (IPTW)",
    "text": "Inverse probability of treatment weights (IPTW)\nThis is the weight that is calculated from the propensity score (which is just the probability of treatment). The idea is to apply a weight to each case that makes the treatment and the control groups balanced on the propensity score and therefore (hopefully) on the individual covariates.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#covariate-balance",
    "href": "glossary.html#covariate-balance",
    "title": "Glossary",
    "section": "Covariate Balance",
    "text": "Covariate Balance\nIn the workflow of propensity score matching and weighting, a key step is to verify if covariates are balanced or imbalanced. Covariate balance is the degree to which the distribution of covariates is similar across levels of treatment.\nNote: The convention we’ve been operating under is that the standardized difference in means between the treatment and control groups for each variable is &lt; 0.1 (1/10th of a standard deviation).",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#kolmogorov-smirnov-distance-ksd",
    "href": "glossary.html#kolmogorov-smirnov-distance-ksd",
    "title": "Glossary",
    "section": "Kolmogorov-Smirnov Distance (KSD)",
    "text": "Kolmogorov-Smirnov Distance (KSD)\nThe KSD is the proportion of non-overlap between two distributions (or, if dealing with cumulative distributions, the maximum distance between two distributions).\nNote: A value of 0 means that the distributions perfectly overlap, while a value of 1 means that the distributions do not overlap at all. The rule of thumb here is that the maximum KSD should be &lt; 0.05.\nNote: When both standard mean differences (SMDs) and KSDs are in their respective acceptable ranges, you can confidently say covariates are balanced.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#entropy-balancing",
    "href": "glossary.html#entropy-balancing",
    "title": "Glossary",
    "section": "Entropy Balancing",
    "text": "Entropy Balancing\nA method of covariate balancing that seeks to balance on mean (like SMDs), variance (like KSDs), and on skewness.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#panel-data",
    "href": "glossary.html#panel-data",
    "title": "Glossary",
    "section": "Panel Data",
    "text": "Panel Data\n\nLong-Form Data\nIn long-form data, each row is a “unit-observation,” meaning that each row is exactly one observation. Thus, if person A is observed four times, her data will be stored in four separate rows.\n\n\nWide-Form Data\nIn wide-form data, each row contains all of the observations for that one specific unit. Thus, if person A is observed four times, her data will be stored in only one row.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#within--vs.-between-subject-variance",
    "href": "glossary.html#within--vs.-between-subject-variance",
    "title": "Glossary",
    "section": "Within- vs. Between-Subject Variance",
    "text": "Within- vs. Between-Subject Variance\nWithin-Subject Variance is the variation that exists within individuals and changes over time. In contrast, Between-Subject Variance exists between individuals and is more or less stable over time.\nFor example, an individual being taller than someone else is considered between-subject variance, as it measures the differences between two different subjects. However, an individual being taller than he was ten years ago is an example of within-subject variance, because it measures the differences between the same subject at two different time periods.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#intra-class-correlation-icc",
    "href": "glossary.html#intra-class-correlation-icc",
    "title": "Glossary",
    "section": "Intra-Class Correlation (ICC)",
    "text": "Intra-Class Correlation (ICC)\nThe ICC is a descriptive statistic that ranges from 0 to 1 and measures the proportion of variance that is between individuals versus within individuals.\nFor example, an ICC of 0.25 indicates that a quarter of the variance exists between individuals, and three-fourths of the variance occurs within individuals.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#mixed-models",
    "href": "glossary.html#mixed-models",
    "title": "Glossary",
    "section": "Mixed Models",
    "text": "Mixed Models\nA mixed model is simply a linear regression with two error terms: level 1 units (observations) and level 2 units (people). Mixed models include a mix of within-subject variance and between-subject variance, weighing one or the other more heavily based on how much of the total variance it contributes.\n\nSo much more to say…\nThis might be useful to keep in mind:",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#fixed-effects-model",
    "href": "glossary.html#fixed-effects-model",
    "title": "Glossary",
    "section": "Fixed-Effects Model",
    "text": "Fixed-Effects Model\nA fixed-effects model is a statistical model that uses waves of observations from the same individual, then calculates the changes for the variables that differ in different waves of observations.\nNote: The fixed-effects model also holds time constant.\n\nPanel data provides the most common use of varying intercepts to estimate causal effects. Here we use repeated observations within the same individuals to adjust for time-constant unobserved confounders. Here, issues of balance and overlap still exist, but they only apply for within-person comparisons.\nIf the purpose of matching/weighting is to get rid of all observable confounders, then the purpose of fixed-effects is to get rid of all time-constant unobserved confounders.\nNote. Fixed Effects are also Mixed Models.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#difference-in-differences",
    "href": "glossary.html#difference-in-differences",
    "title": "Glossary",
    "section": "Difference-in-Differences",
    "text": "Difference-in-Differences\nA simple difference-in-differences test compares the amounts that the treated and control groups change at time 1 and time 2. The equation for calculating a difference-in-differences reads as follows:\n\nDiD = (Treated Time 2 - Treated Time 1) - (Untreated Time 2 - Untreated Time 1)\n\nNote: The DiD calculation relies on the parallel trends assumption.\n\nParallel Trends Assumption\nThe parallel trends assumption assumes that, during the measurement period, the treated and untreated groups would have changed in similar ways if the treated group did not receive treatment.\nNote: The parallel trends assumption cannot be directly tested, but looking at prior trends can be useful for determining if the assumption is likely to be true.\n\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Avenir Next Condensed\"))\n\ntibble(\n  t = c(\"Time 0\", \"Time 1\"),\n  y1 = 1:2,\n  y0 = 0:1,\n  y = c(1, 3)\n) |&gt; \n  pivot_longer(!c(t, y), names_to = \"g\") |&gt; \n  ggplot(aes(t, value, group = g)) + \n  geom_line(linetype = \"dashed\") + \n  geom_vline(xintercept = c(\"Time 0\", \"Time 1\")) +\n  geom_line(aes(t, y)) + \n  geom_segment(x = \"Time 1\", y = 2, yend = 3, xend = \"Time 1\", linewidth = 1.5, \n               color = \"steelblue1\") +\n  labs(y = NULL, x = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        panel.grid = element_blank()) + \n  annotate(\"text\", x = 2.2, y = 2.5, label = latex2exp::TeX(r\"($E[d^1 - d^0]$)\"), family = \"Crimson Text\")\n\n\n\n\n\n\n\n\nFigure 24.2: Parallel Trends\n\n\n\n\n\n\n\n\nTwo-Way Fixed Effects (TWFE)\nThe TWFE model is a way of isolating confounding effects in order to focus only on the within-subject treatment effect. Specifically, the TWFE model holds constant the effect of the individual and also holds constant the effect of time, therefore adjusting for both.\nTwo-Way Fixed Effects Difference-in-Difference Estimator\nThe TWFE difference-in-differences estimator refers to the coefficients learned by a regression model with fixed effects for treatment condition and time period, clustered for treatment condition.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#ordinary-least-squares-ols",
    "href": "glossary.html#ordinary-least-squares-ols",
    "title": "Glossary",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\nA method of estimating the parameters in a linear regression model. OLS chooses the parameters that minimize the sum of the squared differences between the observed values and the values predicted by the model.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#bootstrapping",
    "href": "glossary.html#bootstrapping",
    "title": "Glossary",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nBootstrapping is a statistical technique in which a single data set is sampled and resampled in order to run simulations and pull samples to account for random error.\n\nWe use bootstrapping to calculate standard errors in some cases.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "glossary.html#splines",
    "href": "glossary.html#splines",
    "title": "Glossary",
    "section": "Splines",
    "text": "Splines\nA spline is a flexible kind of model that combines different models [parameters] in order to create the best estimate for the equation [nonlinear regression curves expressed as the sum of many localized pieces].\nNote: The transition from one model into another (i.e., where the data splits) is referred to as a “knot.”\n\nYou don’t need to know this, but here is how this looks like:\n\n\nCode\nlibrary(tidyverse)\n\nN &lt;- 500\nd &lt;- tibble(\n  x = runif(N, 1, 200),\n  y = rnorm(N, mean = 5 + cos(0.05*x), sd = 0.5)\n)\n\nd |&gt; \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, df = 10))\n\n\n\n\n\n\n\n\n\nUnder the hood, the bs() function is partitioning the \\(x\\) variable into 10 separate variables, each of them with their own weight, so that we have something like this:\n\n\nCode\nB &lt;- splines::bs(d$x, df = 10)\nds &lt;- as_tibble(B)\nds$x &lt;- d$x\n\nds |&gt; \n  pivot_longer(!x, names_to = \"b\", values_to = \"w\") |&gt; \n  ggplot(aes(x, w, group = b)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\nEach of these separate variables is then associated with its own coefficient, which we estimate using linear regression.\nThese parameters are very difficult to interpret directly.\n\n\nCode\nols &lt;- lm(y ~ splines::bs(x, df = 10), data = d)\nbroom::tidy(ols)\n\n\n# A tibble: 11 × 5\n   term                      estimate std.error statistic   p.value\n   &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)                 5.89       0.162   36.3    8.85e-141\n 2 splines::bs(x, df = 10)1    0.0203     0.318    0.0637 9.49e-  1\n 3 splines::bs(x, df = 10)2   -0.308      0.240   -1.28   2.01e-  1\n 4 splines::bs(x, df = 10)3   -2.02       0.261   -7.74   5.83e- 14\n 5 splines::bs(x, df = 10)4   -1.91       0.211   -9.03   4.08e- 18\n 6 splines::bs(x, df = 10)5   -0.685      0.218   -3.14   1.78e-  3\n 7 splines::bs(x, df = 10)6    0.509      0.216    2.35   1.89e-  2\n 8 splines::bs(x, df = 10)7   -0.427      0.245   -1.74   8.21e-  2\n 9 splines::bs(x, df = 10)8   -1.58       0.267   -5.92   5.94e-  9\n10 splines::bs(x, df = 10)9   -2.10       0.254   -8.26   1.36e- 15\n11 splines::bs(x, df = 10)10  -1.60       0.249   -6.43   3.10e- 10\n\n\nWe then get the predictions by using the various columns of B instead of using x directly.\nNote. The overlap in the small “hills” shown in the previous figure means that each is in reality a weighted sum.\n\n\nCode\nalpha &lt;- ols$coefficients[1]\ntheta &lt;- ols$coefficients[2:11]\n\nd$pred &lt;- alpha + B %*% theta\n\nd |&gt; \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_line(aes(y = pred), color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\n\nIn a causal inference context, we would want to do this when we have a covariate that interacts with the treatment in ways that are simply not captured by adding a quadratic term. This is one situation in which marginal effects come in handy.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Glossary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. Mostly Harmless\nEconometrics. Princeton university press.\n\n\nAshworth, Scott, Christopher R. Berry, and Ethan Bueno de Mesquita.\n2021. Theory and Credibility: Integrating Theoretical and Empirical\nSocial Science. Princeton University Press.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021. “Difference-in-Differences\nwith Multiple Time Periods.” Journal of Econometrics\n225(2): 200–230.\n\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. 2022. “A Crash Course in Good\nand Bad Controls.” Sociological Methods &\nResearch 00491241221099552.\n\n\nCunningham, Scott. 2021. Causal Inference. Yale University\nPress.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\nGoodman-Bacon, Andrew. 2021. “Difference-in-Differences with\nVariation in Treatment Timing.” Journal of Econometrics\n225(2): 254277.\n\n\nHernan, Miquel A., and James M. Robins. 2023. Causal Inference: What\nIf. CRC Press.\n\n\nHolland, Paul W. 1986. “Statistics and Causal\nInference.” Journal of the American Statistical\nAssociation 81(396): 945–60.\n\n\nHünermund, Paul, and Beyers Louw. 2023. “On the Nuisance of\nControl Variables in Causal Regression Analysis.”\nOrganizational Research Methods 10944281231219274.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction\nto Research Design and Causality. New York: Chapman; Hall/CRC.\n\n\nKeele, Luke, Randolph T. Stevenson, and Felix Elwert. 2020. “The\nCausal Interpretation of Estimated Associations in Regression\nModels.” Political Science Research and Methods 8(1):\n113.\n\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand?\nDefining the Target Quantity Connects Statistical Evidence to\nTheory.” American Sociological Review\n00031224211004187.\n\n\nMorgan, Stephen L., and Christopher Winship. 2014. Counterfactuals\nand Causal Inference: Methods and Principles for Social Research.\n2nd edition. 2nd edition. New York, NY: Cambridge University Press.\n\n\nPearl, Judea. 2009. Causality: Models, Reasoning and Inference.\n2nd edition. 2nd edition. Cambridge, U.K. ; New York: Cambridge\nUniversity Press.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and\nCausation: Graphical Causal Models for Observational Data.”\nAdvances in Methods and Practices in Psychological Science\n1(1): 2742.\n\n\nRohrer, Julia M., and Kou Murayama. 2023. “These Are Not the\nEffects You Are Looking for: Causality and the Within-/Between-Persons\nDistinction in Longitudinal Data Analysis.” Advances in\nMethods and Practices in Psychological Science 6(1):\n25152459221140842.\n\n\nSen, Maya, and Omar Wasow. 2016. “Race as a\nBundle of Sticks: Designs That Estimate Effects of Seemingly Immutable\nCharacteristics.” Annual Review of Political Science\n19(1): 499–522.\n\n\nWestreich, Daniel, and Sander Greenland. 2013. “The Table 2 Fallacy:\nPresenting and Interpreting Confounder and Modifier\nCoefficients.” American Journal of Epidemiology\n177(4): 292–98.",
    "crumbs": [
      "References"
    ]
  }
]