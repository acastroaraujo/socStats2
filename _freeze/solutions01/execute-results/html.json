{
  "hash": "b133013321175f614354e093cf43ad38",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solutions 1\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Exercise\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Packages\"}\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Optima\"))\n```\n:::\n\n\nThe following data frame contains the potential outcomes for 8 individuals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- data.frame(\n  T = c(0, 0, 1, 0, 0, 1, 1, 1),\n  Y0 = c(5, 8, 5, 12, 4, 8, 4, 9),\n  Y1 = c(5, 10, 3, 13, 2, 9, 1, 13), \n  id = LETTERS[1:8]\n)\n\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  T Y0 Y1 id\n1 0  5  5  A\n2 0  8 10  B\n3 1  5  3  C\n4 0 12 13  D\n5 0  4  2  E\n6 1  8  9  F\n7 1  4  1  G\n8 1  9 13  H\n```\n\n\n:::\n:::\n\n\nThe variable `T` depicts whether someone got the \"treatment\" or not.\n\n**Create a new variable called `Y` that contains the observed outcomes.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(Y = ifelse(as.logical(T), Y1, Y0))\n\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  T Y0 Y1 id  Y\n1 0  5  5  A  5\n2 0  8 10  B  8\n3 1  5  3  C  3\n4 0 12 13  D 12\n5 0  4  2  E  4\n6 1  8  9  F  9\n7 1  4  1  G  1\n8 1  9 13  H 13\n```\n\n\n:::\n:::\n\n\n**What is the Average Treatment Effect (ATE) for this 8 person experiment?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## ate --- based on \"complete\" data\nd |> \n  mutate(TE = Y1 - Y0) |> \n  summarize(ATE = mean(TE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    ATE\n1 0.125\n```\n\n\n:::\n\n```{.r .cell-code}\n## ate --- \"naive\" estimate based on observed data\nmean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.75\n```\n\n\n:::\n:::\n\n\n## Exercise\n\n**Simulate a new completely randomized experiment on these 8 people; that is, re sample** $T$ **at random so that equal numbers get the treatment and the control.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$T <- sample(d$T)\n```\n:::\n\n\n**Create a new variable called `Y` that contains the observed outcomes.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |> \n  mutate(Y = ifelse(as.logical(T), Y1, Y0))\n```\n:::\n\n\n**What is the Average Treatment Effect (ATE) for this 8 person experiment?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## naive estimate\nmean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -2.5\n```\n\n\n:::\n:::\n\n\n**Do this a couple of times (at least 3) and note the differences.**\n\n*I will do this a couple of hundred times.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout <- replicate(1e3, {\n  d$T <- sample(d$T)\n  d$Y <- ifelse(as.logical(d$T), d$Y1, d$Y0)\n  mean(d$Y[d$T == 1]) - mean(d$Y[d$T == 0])\n})\n\nsummary(out)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-6.50000 -1.75000  0.00000  0.04275  2.00000  6.75000 \n```\n\n\n:::\n:::\n\n\n**How do these estimates compare to the \"real\" ATE?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = out) |> \n  ggplot(aes(x, y = \"\")) + \n  geom_boxplot() + \n  geom_jitter(height = 1/10, alpha = 1/4) + \n  geom_point(x = 0.125, fill = \"pink\", shape = 21, size = 5) +\n  labs(y = NULL)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in geom_point(x = 0.125, fill = \"pink\", shape = 21, size = 5): All aesthetics have length 1, but the data has 1000 rows.\nâ„¹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](solutions01_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n*They are all over the place. But... on average they're sort of close.*\n\n## Exercise\n\n*Obviously, an experiment of 8 people will not give you enough \"statistical power.\"*\n\n*Assuming the ATE is* $0.125$*, how many people would you need to enroll in this experiment to have enough statistical power?*\n\n::: callout-tip\nHint: There are a few different ways of giving a reasonable answer to this question. The wording of this problem is ambiguous.\n:::\n\nTo get at questions of statistical power we need to establish two things from the outset: (1) the \"effect\" we believe exists out there and (2) the desired standard error. For the latter, this *usually* means choosing a sample size so that *the resulting standard error that will allow me to have a false negative rate of at most 20%.* But this is just a convention.\n\nSteve's [code](https://github.com/vaiseys/soc-stats-2/blob/main/demos/week-02.R) already shows how to do this with the built-in `t.test` and `power.t.test` functions. He also had to make assumptions about the the distribution of the potential outcomes in the population. *We all have to do this*, except that sometimes we don't realize it because the assumptions are hidden away in some kind of Internet sample size calculator.\n\nThis is how I would have done it.\n\nStep 1. I will assume that the *standard deviation* for each potential outcome in the 8 person experiment is the same in the wider population. This is a big assumption, but it's the one I'll go with. This is the main difference between what Steve did and what I did (his assumptions about the population variance are hidden in lines 54-56).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsdY0 <- sd(d$Y0)\nsdY0\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.850439\n```\n\n\n:::\n\n```{.r .cell-code}\nsdY1 <- sd(d$Y1)\nsdY1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.869732\n```\n\n\n:::\n:::\n\n\n*Note. Think about what I just did. I assumed the heterogeneity in treatment effects among those who got the treatment is larger than it is for those who didn't. Would this make sense in real life? Maybe?*\n\nStep 2. I will assume that half the sample gets a treatment and the other half does not. This allows me to calculate the standard error of the difference in means simply as:\n\n$$\n\\text{SE} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} = \\sqrt{\\frac{2(\\sigma_1^2 + \\sigma_2^2)}{n}}\n$$\n\n<aside>$\\frac{n}{2} = n_1 = n_2$</aside>\n\nStep 3. Choose a simple heuristic so that my standard error is good enough.\n\n::: callout-warning\nNote. You might be tempted to use the simple statistical significance heuristic, according to which you need a standard error that is half the size of the effect ( $\\text{SE} = 0.0625$ ). But this is wrong. If this was the case, then you would get a statistically significant ( $\\alpha = 0.05$ ) only *half the time.* Most people go for 80%\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n  xlim(-1/2, 1/2) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0, 0.0625), \n    geom = \"area\", aes(fill = \"null distribution\")\n  ) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0.125, 0.0625), \n    geom = \"area\", aes(fill = \"sampling distribution\"), alpha = 1/4\n  ) + \n  geom_vline(xintercept = qnorm(c(0.025, 0.975), 0, 0.0625), linetype = \"dashed\") + \n  labs(\n    y = \"density\", x = \"ATE\", fill = NULL,\n    caption = \"Note: dashed lines indicate traditional statistical significance break points\",\n    subtitle = \"\\\"Power\\\" with standard error half the size of the effect\"\n  )\n```\n\n::: {.cell-output-display}\n![](solutions01_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\nSo, I will use the simple heuristic that I want my standard error to be a third the size of my effect, so around 0.042.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## sample size with simple algebra\n2*(sdY0^2 + sdY1^2) / 0.042^2 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 36098.96\n```\n\n\n:::\n:::\n\n\nBased on this simple sketch, I anticipate that my sample size will have to be *huge* in order to detect such a small effect.\n\n*How does this look like?*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n  xlim(-1/3, 1/3) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0, 0.042), \n    geom = \"area\", aes(fill = \"null distribution\")\n  ) + \n  stat_function(\n    fun = \\(x) dnorm(x, 0.125, 0.042), \n    geom = \"area\", aes(fill = \"sampling distribution\"), alpha = 1/4\n  ) + \n  geom_vline(xintercept = qnorm(c(0.025, 0.975), 0, 0.042), linetype = \"dashed\") +\n  labs(\n    y = \"density\", x = \"ATE\", fill = NULL,\n    caption = \"Note: dashed lines indicate traditional statistical significance break points\",\n    subtitle = str_glue(\"\\\"Power\\\" with sample size of 36,099\")\n  )\n```\n\n::: {.cell-output-display}\n![](solutions01_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nTo calculate the statistical power we simply calculate the area under the sampling distribution *above* the desired cutoff point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncutoff <- qnorm(0.975, mean = 0, sd = 0.042) ## null distribution\npnorm(cutoff, mean = 0.125, sd = 0.042, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8452392\n```\n\n\n:::\n:::\n\n\nIf you want to get more exact numbers for the traditional 80% power (and this is just another fetishized number), we can use some algebra:\n\n$$\n\\begin{align}\n0 + 1.96 \\cdot \\text{SE} &= \\overbrace{0.125}^\\text{ATE} - 0.84 \\cdot \\text{SE} \\\\\n\\text{SE} &=  0.125 / 2.8 \\\\ &\\approx 0.045\n\\end{align}\n$$\n\n<aside>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(0.2, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8416212\n```\n\n\n:::\n:::\n\n\n</aside>\n\nWhich we can unpack to solve for the sample size:\n\n$$\n\\begin{align}\n\\sqrt{\\frac{2(\\sigma^1 + \\sigma^2)}{n}} &= 0.045 \\\\\n2\\times\\frac{\\sigma_1^2 + \\sigma_2^2}{0.045^2} &= n\n\\end{align}\n$$\n\nOr you could use more complicated R functions... although I find this to be much easier than algebra.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstat_power <- function(n) {\n  ## this function will use our assumptions about standard deviations \n  ## in the population and output the statistical power that corresponds\n  ## to a specific sample size\n  se <- sqrt(2*(sdY0^2 + sdY1^2) / n)       ## population variance assumption\n  cutoff <- qnorm(0.975, mean = 0, sd = se) ## null distribution cutoff\n  pnorm(cutoff, mean = 0.125, sd = se, lower.tail = FALSE) ## stat power\n}\n\nsample_size <- function(power = 0.8, interval = c(300, 1e6)) {\n  ## this function will find the value of \"n\" for which the output\n  ## of stat_power(n) - \"power\" is zero\n  out <- uniroot(\\(n) stat_power(n) - power, interval = interval)\n  out$root\n}\n\nsample_size(power = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 31987.55\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot() + \n  xlim(1e3, 50e3) + \n  geom_function(fun = stat_power) + \n  geom_hline(yintercept = 0.8, linetype = \"dashed\") + \n  geom_vline(xintercept = sample_size(power = 0.8), linetype = \"dashed\") + \n  labs(x = \"Sample Size\", y = \"Statistical Power\") \n```\n\n::: {.cell-output-display}\n![](solutions01_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "solutions01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}