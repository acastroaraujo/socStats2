{
  "hash": "bc196acdcf2d09440e482a4190e68b00",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solutions 3\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n\n## Exercise\n\n*House of DAG Simulation.*\n\nI've included a [little script](https://github.com/acastroaraujo/socStats2/blob/main/hod_simulation_functions.R) with a couple of functions meant to illustrate the connection between DAGs and the estimands we saw in class (ATE, ATT, ATC).\n\nSave it to your project and load it using the `source()` function.\n\nYou should see a function called `hod_simulation()` which creates a dataset that corresponds to the following DAG:\n\n::: grid\n::: g-col-7\n![](images/house-of-dag.png){width=\"100%\"}\n:::\n\n::: g-col-5\n-   $Y$: outcome\n-   $T$: treatment\n-   $U$: unobserved confounder\n-   $S$: affects selection into $T$\n-   $X$: affects $Y$ directly\n:::\n:::\n\nThe `hod_simulation()` function has the following arguments:\n\n-   `N`: Sample Size\n\n-   `rho`: The correlation between $S$ and $X$, it accepts values between -1 and 1.\n\n-   `Bt`: this is the treatment effect.\n\n-   `Bx`: this is the direct effect of $X$ on $Y$\n\n*Note. There's bunch of stuff going on under the hood, but we won't worry about that this week.*\n\nThis is the dataset it creates:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"hod_simulation_functions.R\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error ~  0.322 \nPower ~  0.873\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(variable)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  variable    sd  mean\n  <chr>    <dbl> <dbl>\n1 y        5.36  1.42 \n2 t        0.500 0.515\n3 x        0.986 0.936\n4 s        1.00  0.981\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(12345) ## include this so that grading is easier for me.\nd <- hod_simulation(N = 1e3, Bt = 2, Bx = 4, rho = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error ~  0.405 \nPower ~  0.999\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(variable)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  variable    sd  mean\n  <chr>    <dbl> <dbl>\n1 y        6.75   4.98\n2 t        0.500  0.52\n3 x        1.02   1.00\n4 s        1.01   1.02\n```\n\n\n:::\n:::\n\n\n*Note. Ignore the \"Standard Error\" and \"Power\" messages.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 6\n       y0     y1     t      y       x      s\n *  <dbl>  <dbl> <int>  <dbl>   <dbl>  <dbl>\n 1  3.03   5.03      1  5.03   1.90   1.84  \n 2  5.20   7.20      1  7.20   0.545  0.699 \n 3 -0.351  1.65      1  1.65  -0.355  0.729 \n 4 -2.76  -0.764     1 -0.764  1.03   1.44  \n 5 -3.79  -1.79      0 -3.79   0.0507 0.335 \n 6 12.9   14.9       0 12.9    2.57   1.71  \n 7  6.70   8.70      0  6.70   1.63   1.56  \n 8  3.68   5.68      0  3.68   1.40   0.694 \n 9 -1.65   0.353     1  0.353  0.307  0.0589\n10 10.8   12.8       0 10.8    1.77   2.14  \n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n-   Without looking at the results just yet... do you think the naive estimate will be larger or smaller than the \"real\" estimate ( $ATE = 2$ )?\n\n-   Check your answer. What are the results given by the naive estimator?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd |> \n  group_by(t) |> \n  summarize(y = mean(y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n      t     y\n  <int> <dbl>\n1     0  2.00\n2     1  7.72\n```\n\n\n:::\n\n```{.r .cell-code}\nlm(y ~ t, data = d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ t, data = d)\n\nCoefficients:\n(Intercept)            t  \n      2.002        5.718  \n```\n\n\n:::\n:::\n\n\n-   Re-do this but set `rho` to -0.8 (so that $S$ and $X$ are now negatively correlated).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- hod_simulation(N = 1e5, Bt = 2, Bx = 4, rho = -0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error ~  0.04 \nPower ~  1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(variable)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  variable    sd  mean\n  <chr>    <dbl> <dbl>\n1 y        6.21  5.01 \n2 t        0.500 0.498\n3 x        1.00  1.01 \n4 s        1.00  0.997\n```\n\n\n:::\n\n```{.r .cell-code}\nd |> \n  group_by(t) |> \n  summarize(y = mean(y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n      t     y\n  <int> <dbl>\n1     0  5.82\n2     1  4.19\n```\n\n\n:::\n\n```{.r .cell-code}\nlm(y ~ t, data = d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ t, data = d)\n\nCoefficients:\n(Intercept)            t  \n      5.818       -1.628  \n```\n\n\n:::\n:::\n\n\n## Exercise\n\nTake the dataset `d` created in the previous question and modify it so that the treatment is now randomized (this will destroy the path between $S$ and $T$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$t <- sample(d$t)\n\nd <- d |> \n  mutate(y = ifelse(\n    test = as.logical(t), \n    yes = y1, \n    no = y0\n  )\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ t, data = d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ t, data = d)\n\nCoefficients:\n(Intercept)            t  \n      4.032        1.958  \n```\n\n\n:::\n:::\n\n\n::: callout-tip\nHint: You can achieve this using the `sample()` function on `d$t`.\n\nYou will also want to create a new `d$y` using the `ifelse()` function (or something similar to that).\n:::\n\n-   Without looking at the results just yet... do you think the naive estimate will be larger or smaller than the \"real\" estimate ( $ATE = 2$ )?\n\n-   Check your answer. What are the results given by the naive estimator?\n\n-   Use `lm()` to predict the newly created `y` from `t`. What are the coefficient values?\n\n-   Use `lm()` to predict the newly created `y` from `t` and `x`. What are the coefficient values?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}