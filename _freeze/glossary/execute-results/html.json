{
  "hash": "892df2a567bcc0e2c8f9d71e6257823d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Glossary\"\nnumber-sections: false\n---\n\n\n*Joint Submission.*\n\n*My comments are in the shaded boxes.*\n\n------------------------------------------------------------------------\n\n## Estimand\n\nThe parameter or quantity of interest that one aims to estimate in a statistical analysis. It defines what effect or measure is being targeted by the analysis, specifying how it relates to the variables and data involved.\n\n## Counterfactual\n\nThe counterfactual compares the observed results of something that did happen to the expected results if the treatment *had not* happened.\n\n## Potential Outcomes\n\nThe set of all possible outcomes for each individual in a study, under each possible treatment or intervention scenario. These outcomes reflect what could happen to each individual under different conditions.\n\n::: box-text-custom\nNote.\n\nI think it's better to think of \"potential outcomes.\"\n\nFor example, in the case of a **binary** treatment, the potential outcomes framework involves the following:\n\n-   $T$ is a treatment variable. The terms \"treatment\" and \"cause\" are used interchangeably.\n\n-   $Y$ is the outcome we observe.\n\n-   $Y^0$ is the the value the outcome *would* take if $T=0$.\n\n-   $Y^1$ is the value the outcome *would* take if $T=1$.\n\n-   $Y^0$ and $Y^1$ are the *potential outcomes.*\n\n-   We see $Y^0$ *or* $Y^1$ for the same unit, but never both.\n\n    This is the **fundamental problem of causal inference**.\n\n-   When $T=1$, $Y^0$ is the *counterfactual.*\n\n-   When $T=0$, $Y^1$ is the *counterfactual.*\n:::\n\n## Theoretical Estimand \n\nThis is the actual thing we would like to know in our research question. The two components of the theoretical estimand are the unit-specific quantity and the target population. The theoretical estimand includes both observed and unobserved data (including counterfactuals).\n\n## Empirical Estimand \n\nThe empirical estimand is the target of inference that only includes observable data and relies on identification assumptions.\n\n## Causal Interaction \n\nA causal interaction is the intervention to two variables averaged over one population. In other words, the effect of one variable on the outcome is related to the effect of another.\n\n## Baseline Bias\n\nWhen the treatment and the control group differ from one another for reasons other than the treatment they receive.\n\n## Average Treatment Effect (ATE)\n\nThe average treatment effect across the population. In other words, this is the effect of switching treatment statuses (e.g., from either treatment to control or from control to treatment).\n\n## Conditional Average Treatment Effect (CATE)\n\nThe average treatment effect among a specific group as defined by certain ~~control variables~~ covariates.\n\nFor example, if the ~~control variable~~ covariate is $X$, the CATE can be written as $E(Y^1-Y^0 \\mid X = x)$.\n\n::: box-text-custom\nNote.\n\nThe word \"control\" has some baggage because it has the connotation that we can somehow manipulate $X$. Usually we'd want to include variables like \"gender\" or \"race\" here.\n:::\n\n## Average Treatment Effect on the Treated (ATT) \n\nThe average treatment effect, calculated only from the treatment group. To conceptualize the ATT, imagine *taking away* treatment from those who were treated and measuring the change.\n\n## Average Treatment Effect on the Untreated (ATU) \n\nThe average treatment effect, calculated only from the untreated group. To conceptualize the ATU, imagine *giving* the treatment to those who were not treated and measuring the change.\n\n## Unit-Specific Quantity\n\nA measurement or outcome that pertains to an individual unit or subject in a study, often used in contexts where the effect of a treatment may vary from one unit to another.\n\n## Treatment Effect Heterogeneity \n\nWhen a treatment has different effects on a population.\n\nFor, example, a treatment for cervical cancer will have heterogeneous effects on people with cervixes versus people without cervixes, even if both groups in the population receive identical treatments. This is because people without cervixes will receive no treatment effect from drugs that target an organ they do not have.\n\n------------------------------------------------------------------------\n\n::: box-text-custom\nNote.\n\nThis is an extreme example. You'd usually want to remove men from design (i.e., not administering the treatment to people without cervixes).\n\nIn a less extreme example, the treatment for cervical cancer could have varying effects across women belonging to different age groups.\n:::\n\n## Directed Acyclic Graph (DAG)\n\nA tool used to depict the data-generating process with nodes to represent the variable and the arrows to represent the causal relationships.\n\n::: box-text-custom\nCausal diagrams or DAGs are graphical representations of a **data generating process**. Everything we draw is hopefully an informed assumption; everything that’s not in the diagram is *also* an assumption. In other words, DAGs encode identifying assumptions.\n\nThe idea of a directed acyclical graph (DAG) implies that there are *no cycles.* If a variable causes itself, it’s near impossible to isolate or identifying the cause of anything. The world is full with feedback loops of all sorts, but we deal with them through the incorporation of time or by isolating one effect through some kind of experimental scenario.\n\n*Note that DAGs are agnostic about functional form. This includes interactions among variables! Some people deal with interactions by drawing arrows toward arrows or by representing interactions explicitly as separate nodes.*\n\nThe nicest thing about DAGs is that they help us spell out the **testable implications** of our assumptions. For example, if our causal diagram implies that a relationship between variables is zero, we can check for that.\n:::\n\n### Unobserved / Unmeasured Variable\n\nA variable that may be present in the researcher's assumptions about how the world works, but that is not ~~addressed or~~ available in the data.\n\n::: box-text-custom\nNote.\n\nIn a DAG, these variables are usually depicted by being enclosed within a circle.\n:::\n\n### Path\n\nA path is simply the steps from one variable to another on a causal diagram.\n\nFor example, $A \\to B \\to C$ is a path.\n\n### Direct Effects\n\nThe effect of only the treatment variable on the outcome variable.\n\n### Indirect Effects\n\nThe portion of the change in an outcome that is mediated through one or more intermediate variables, reflecting the causal influence exerted through these mediating variables.\n\n### Total Effects\n\nThe sum of direct and indirect effects.\n\n### Front-Door Path\n\nA causal path in which all of the arrows in the causal diagram point from the treatment variable and towards the outcome variable.\n\n### Back-Door Path\n\nThe rest of the paths on a causal diagram \\[connecting treatment to outcome\\] that are not front-door paths.\n\n### Confounding ~~Variable~~\n\nA variable that affects both the treatment and outcome variables.\n\nNote: Not adjusting for a confounding variable threatens the causal relationship between the treatment and outcome variables.\n\n------------------------------------------------------------------------\n\n::: box-text-custom\nNote.\n\nThe expression \"threatens the causal relationship\" is vague and clunky. A better way to say this is that the causal effect is not **identified** when we don't adjust for confounding paths.\n\nAn even *better* way to talk about confounding is to realize that \"confounding\" is a property of **paths**, it's NOT a property of variables.\n:::\n\n### Collider Variable\n\nA variable in a DAG that is influenced by two or more other variables. Conditioning on a collider can open a confounding path, inadvertently introducing bias into the analysis.\n\n::: box-text-custom\nA variable is a collider in a path *iff* both arrows point at it.\n\n$$\na \\to b \\to c_\\text{ollider} \\leftarrow d \\leftarrow e \\to f\n$$\n\nHere, $b$ and $c$ are unrelated *unless* we remove variation in $c$ (e.g., by including it in a regression).\n\nWe close paths by removing variation from one variable along the path (i.e., adjusting); but if the variable is a collider, then removing variation will actually *open* a path that was already closed.\n\nAn often unacknowledged way of adjusting for colliders is during the sample selection phase. If we have a sample of college students, it means we are adjusting for college attendance.\n:::\n\n### Open Path\n\nA path on a causal diagram in which there is variation in all variables along the path (and no variation in any colliders on that path).\n\n### Closed Path \n\nA path on a causal diagram in which one or more variables has no variation.\n\nNote: A path is also considered closed if there is a collider variable present on that path.\n\n## Regression\n\nRegression focuses on estimating the effect of variables on an outcome through a mathematical model, assuming a specific form of relationship.\n\n::: box-text-custom\nNote.\n\nThis is NOT a good definition!!\n\nIn the usual context of regression, predictive inference relates to comparisons *between* units. In the context of causal inference, we attempt to make comparisons of different treatments *as if applied to the same units.*\n\nIn order to make causal interpretations of regression coefficients we rely very strong assumptions. In short, causal effects can be estimated with regression if the model includes all confounding variables *and* if the \"functional form\" is correct.\n\n**Translating DAGs into Regression**\n\n![Flow Chart For Constructing Regression Equations [@huntington-klein2021, pp. 199]](images/reg-chart.png){#fig-reg-chart alt=\"Flow Chart For Constructing Regression Equations [@huntington-klein2021, pp. 199]\" fig-align=\"center\" width=\"70%\"}\n:::\n\n## Matching and Weighting\n\nMatching and weighting seeks to identify the treatment effect by adjusting for selection into treatment by comparing similar treatment and control cases based on certain attributes.\n\nNote: This is distinct from regression, which adjusts for variables that impact the outcome.\n\n::: box-text-custom\nBoth **regression** and **matching/weighting** are strategies to close the backdoor path between $T$ and $Y$. *Both are conditional on observable covariates.* However, matching/weighting provides a way to model treatment selection so that everyone looks the same on the pre-treatment covariates.\n\n**Matching/weighting** refers to a set of procedures that modify the original sample in preparation for a statistical analysis. It's a form of data pre-processing. The goal is to create a sample that *looks like* it was created from a randomized experiment.\n\nHere are some benefits of matching/weighting procedures:\n\n-   They are *less restrictive* about functional form than regression. We rely less on parametric assumptions. The intuition is the same as with an experiment: if we can create sufficient overlap and balance between treatment and control groups, then we should get a reasonable estimate of the treatment effect, *even if the model used to estimate it is misspecified*.\n-   Regression models on pre-processed data gives us two opportunities to close backdoor paths (i.e., \"double robustness\").\n:::\n\n## Exact Matching\n\nExact matching compares treatment and control cases that have exactly identical characteristics on a certain combination of variables. In this way, treatment cases are matched to control cases that share the exact same distribution of values for the matching variable(s) of interest, making the only difference between them is treatment status.\n\n~~The three assumptions for exact matching are as follows:~~\n\n1.  ~~Selection of variables-conditional independence assumption.~~\n\n2.  ~~Overlap (any individual case has a non-zero probability of treatment).~~\n\n3.  ~~Stable unit treatment value assumption (SUTVA; treatment status and effect of treatment is independent for each case).~~\n\n------------------------------------------------------------------------\n\n::: box-text-custom\nNote.\n\nThese assumptions are NOT unique to matching.\n\nA better discussion of overlap can be found [here](https://acastroaraujo.github.io/socStats2/week06.html#balance-and-overlap) or in one of the textbooks.\n\nThis brief discussion from the `MatchIt` vignette is also useful:\n\n<https://kosukeimai.github.io/MatchIt/articles/matching-methods.html#exact-matching-method-exact>\n:::\n\n## Conditional Independence Assumption (CIA)\n\n~~The conditional independence assumption asserts that two events occur independent of one another (i.e., the two events do not influence one another).~~\n\n::: box-text-custom\nThe CIA (also known as \"conditional ignorability\" assumption) builds on the more general idea of **ignorability**.\n\nExperiments work because they make the distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator are *independent.*\n\n$$\nY^0, Y^1 \\perp T\n$$\n\nHere, the $\\perp$ symbol means independent.\n\nThe CIA is a necessary assumption we make when using both *regression* and *matching/weighting* to identify a causal effect.\n\nInstead of a simple independence assumption that we have for randomized experiments, we now have to rely on a **conditional** ignorability. Just like in the case of experiments, we want distribution of potential outcomes the same across levels of the treatment variable. In other words, the potential outcomes and the treatment indicator *should* be independent, conditional on the covariates $\\boldsymbol{X}$ used in the analysis.\n\n$$\nY^0, Y^1 \\perp T \\mid \\boldsymbol X\n$$\n\nHere, $\\boldsymbol{X}$ is meant to depict a collection of variables that will close the back-door path.\n\nThis strategy will get more complicated as the vector $\\boldsymbol X$ grows in size.\n:::\n\n## Region of Common Support\n\nThis is the assumption that either for distribution of a matching variable (in exact matching) or for distribution of propensity scores (in weighting), there are both treatment and control cases. If there is overlap, this is known as the region of common support. If there is not overlap in the distributions, that is “off support” and makes causal inference a little more tricky.\n\n::: box-text-custom\nNote.\n\nWhat makes it \"tricky\" is that we don't have direct support from the data to estimate the relevant counterfactuals—e.g., regression will just *extrapolate.*\n:::\n\n## Feasible Estimate of Treatment Effects\n\nWhen calculating a treatment effect, it is sometimes necessary to drop cases that fall outside of the \"region of common support.\" Because cases are dropped, the \"true\" treatment effect cannot be calculated, which leaves us with calculating the \"feasible\" treatment effect instead.\n\n## Propensity Score\n\nA subject’s individual probability of receiving treatment. Propensity scores can then be used to match or weight control cases to mimic the treatment group.\n\n## Doubly-Robust\n\nUsing \"doubly robust\" methods refers to using both regression and balancing ~~in an equation~~ simultaneously. Employing doubly robust measures is a way to mitigate biases or confounding variables from influencing the \"true\" treatment effect of your model.\n\n## Inverse probability of treatment weights (IPTW)\n\nThis is the weight that is calculated from the propensity score (which is just the probability of treatment). The idea is to apply a weight to each case that makes the treatment and the control groups balanced on the propensity score and therefore (hopefully) on the individual covariates.\n\n## Covariate Balance\n\nIn the workflow of propensity score matching and weighting, a key step is to verify if covariates are balanced or imbalanced. Covariate balance is the degree to which the distribution of covariates is similar across levels of treatment.\n\nNote: The convention we’ve been operating under is that the standardized difference in means between the treatment and control groups for each variable is \\< 0.1 (1/10th of a standard deviation).\n\n::: box-text-custom\n\n![](images/workflow.png){fig-align=\"center\" width=\"70%\"}\n:::\n\n## Kolmogorov-Smirnov Distance (KSD)\n\nThe KSD is the proportion of non-overlap between two distributions (or, if dealing with cumulative distributions, the maximum distance between two distributions).\n\nNote: A value of 0 means that the distributions perfectly overlap, while a value of 1 means that the distributions do not overlap at all. The rule of thumb here is that the maximum KSD should be \\< 0.05.\n\nNote: When both standard mean differences (SMDs) and KSDs are in their respective acceptable ranges, you can confidently say covariates are balanced.\n\n## Entropy Balancing\n\nA method of covariate balancing that seeks to balance on mean (like SMDs), variance (like KSDs), and on skewness.\n\n## Panel Data\n\n### Long-Form Data\n\nIn long-form data, each row is a \"unit-observation,\" meaning that each row is exactly one observation. Thus, if person A is observed four times, her data will be stored in four separate rows.\n\n### Wide-Form Data \n\nIn wide-form data, each row contains all of the observations for that *one specific* unit. Thus, if person A is observed four times, her data will be stored in only one row.\n\n## Within- vs. Between-Subject Variance\n\nWithin-Subject Variance is the variation that exists within individuals and changes over time. In contrast, Between-Subject Variance exists between individuals and is more or less stable over time.\n\nFor example, an individual being taller than someone else is considered between-subject variance, as it measures the differences between two different subjects. However, an individual being taller than he was ten years ago is an example of within-subject variance, because it measures the differences between *the same subject* at two different time periods.\n\n## Intra-Class Correlation (ICC)\n\nThe ICC is a descriptive statistic that ranges from 0 to 1 and measures the proportion of variance that is between individuals versus within individuals.\n\nFor example, an ICC of 0.25 indicates that a quarter of the variance exists between individuals, and three-fourths of the variance occurs within individuals.\n\n## Mixed Models\n\nA mixed model is simply a linear regression with two error terms: level 1 units (observations) and level 2 units (people). Mixed models include a mix of within-subject variance and between-subject variance, weighing one or the other more heavily based on how much of the total variance it contributes.\n\n::: box-text-custom\nSo much more to say...\n\nThis might be useful to keep in mind:\n\n![](images/two-datasets.png){fig-align=\"center\" width=\"80%\"}\n:::\n\n## Fixed-Effects Model\n\nA fixed-effects model is a statistical model that uses waves of observations from the same individual, then calculates the changes for the variables that differ in different waves of observations.\n\n~~Note: The fixed-effects model also holds time constant.~~\n\n::: box-text-custom\nPanel data provides the most common use of varying intercepts to estimate causal effects. Here we use repeated observations within the same individuals to adjust for time-constant unobserved confounders. Here, issues of balance and overlap still exist, but they only apply for *within-*person comparisons.\n\nIf the purpose of **matching/weighting** is to get rid of all observable confounders, then the purpose of **fixed-effects** is to get rid of all time-constant unobserved confounders.\n\n*Note. Fixed Effects are also Mixed Models.*\n:::\n\n## Difference-in-Differences \n\nA simple difference-in-differences test compares the amounts that the treated and control groups change at time 1 and time 2. The equation for calculating a difference-in-differences reads as follows:\n\n::: {style=\"text-align: center;\"}\nDiD = (Treated Time 2 - Treated Time 1) - (Untreated Time 2 - Untreated Time 1)\n:::\n\nNote: The DiD calculation relies on the parallel trends assumption.\n\n### Parallel Trends Assumption \n\nThe parallel trends assumption assumes that, during the measurement period, the treated and untreated groups would have changed in similar ways if the treated group did not receive treatment.\n\nNote: The parallel trends assumption cannot be directly tested, but looking at prior trends can be useful for determining if the assumption is likely to be true.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Avenir Next Condensed\"))\n\ntibble(\n  t = c(\"Time 0\", \"Time 1\"),\n  y1 = 1:2,\n  y0 = 0:1,\n  y = c(1, 3)\n) |> \n  pivot_longer(!c(t, y), names_to = \"g\") |> \n  ggplot(aes(t, value, group = g)) + \n  geom_line(linetype = \"dashed\") + \n  geom_vline(xintercept = c(\"Time 0\", \"Time 1\")) +\n  geom_line(aes(t, y)) + \n  geom_segment(x = \"Time 1\", y = 2, yend = 3, xend = \"Time 1\", linewidth = 1.5, \n               color = \"steelblue1\") +\n  labs(y = NULL, x = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        panel.grid = element_blank()) + \n  annotate(\"text\", x = 2.2, y = 2.5, label = latex2exp::TeX(r\"($E[d^1 - d^0]$)\"), family = \"Crimson Text\")\n```\n\n::: {.cell-output-display}\n![Parallel Trends](glossary_files/figure-html/fig-parallel-trends-1.png){#fig-parallel-trends width=384}\n:::\n:::\n\n\n### Two-Way Fixed Effects (TWFE) \n\nThe TWFE model is a way of isolating confounding effects in order to focus only on the within-subject treatment effect. Specifically, the TWFE model holds constant the effect of the individual and also holds constant the effect of time, therefore adjusting for both.\n\n**Two-Way Fixed Effects Difference-in-Difference Estimator**\n\nThe TWFE difference-in-differences estimator refers to the coefficients learned by a regression model with fixed effects for treatment condition and time period, clustered for treatment condition.\n\n## Ordinary Least Squares (OLS)\n\nA method of estimating the parameters in a linear regression model. OLS chooses the parameters that minimize the sum of the squared differences between the observed values and the values predicted by the model.\n\n## Bootstrapping \n\nBootstrapping is a statistical technique in which a single data set is sampled and resampled in order to run simulations and pull samples to account for random error.\n\n::: box-text-custom\nWe use bootstrapping to calculate standard errors in some cases.\n:::\n\n## Splines\n\nA spline is a flexible kind of model that combines different ~~models~~ \\[parameters\\] in order to ~~create the best estimate for the equation~~ \\[nonlinear regression curves expressed as the sum of many localized pieces\\].\n\n~~Note: The transition from one model into another (i.e., where the data splits) is referred to as a \"knot.”~~\n\n::: box-text-custom\nYou don't need to know this, but here is how this looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nN <- 500\nd <- tibble(\n  x = runif(N, 1, 200),\n  y = rnorm(N, mean = 5 + cos(0.05*x), sd = 0.5)\n)\n\nd |> \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", formula = y ~ splines::bs(x, df = 10))\n```\n\n::: {.cell-output-display}\n![](glossary_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nUnder the hood, the `bs()` function is partitioning the $x$ variable into 10 separate variables, each of them with their own weight, so that we have something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nB <- splines::bs(d$x, df = 10)\nds <- as_tibble(B)\nds$x <- d$x\n\nds |> \n  pivot_longer(!x, names_to = \"b\", values_to = \"w\") |> \n  ggplot(aes(x, w, group = b)) + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](glossary_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nEach of these separate variables is then associated with its own coefficient, which we estimate using linear regression.\n\nThese parameters are *very difficult* to interpret directly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols <- lm(y ~ splines::bs(x, df = 10), data = d)\nbroom::tidy(ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 5\n   term                      estimate std.error statistic   p.value\n   <chr>                        <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)                  5.87      0.192    30.5   2.13e-115\n 2 splines::bs(x, df = 10)1     0.377     0.380     0.993 3.21e-  1\n 3 splines::bs(x, df = 10)2    -1.03      0.222    -4.66  4.09e-  6\n 4 splines::bs(x, df = 10)3    -1.70      0.259    -6.56  1.38e- 10\n 5 splines::bs(x, df = 10)4    -1.94      0.226    -8.58  1.28e- 16\n 6 splines::bs(x, df = 10)5    -0.178     0.252    -0.706 4.81e-  1\n 7 splines::bs(x, df = 10)6     0.231     0.231     0.998 3.19e-  1\n 8 splines::bs(x, df = 10)7    -0.221     0.244    -0.906 3.66e-  1\n 9 splines::bs(x, df = 10)8    -2.08      0.276    -7.53  2.45e- 13\n10 splines::bs(x, df = 10)9    -1.69      0.290    -5.83  1.01e-  8\n11 splines::bs(x, df = 10)10   -1.61      0.240    -6.68  6.43e- 11\n```\n\n\n:::\n:::\n\n\nWe then the predictions by using the various columns of `B` instead of using `x` directly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha <- ols$coefficients[1]\ntheta <- ols$coefficients[2:11]\n\nd$pred <- alpha + B %*% theta\n\nd |> \n  ggplot(aes(x, y)) + \n  geom_point() + \n  geom_line(aes(y = pred), color = \"red\", linewidth = 1)\n```\n\n::: {.cell-output-display}\n![](glossary_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nIn a causal inference context, we would want to do this when we have a covariate that interacts with the treatment in ways that are simply not captured by adding a quadratic term.\n:::\n",
    "supporting": [
      "glossary_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}